{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "still-dover",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import Input, Conv2D, Lambda, merge, Dense, Flatten,MaxPooling2D\n",
    "from keras.models import Model, Sequential\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD,Adam\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "comprehensive-beast",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 categories found in the dataset\n",
      "X, Y shape (130, 100, 100, 3) (130,) (13, 10)\n"
     ]
    }
   ],
   "source": [
    "base_dir = r'./data/cons/training'\n",
    "train_test_split = 0.7\n",
    "no_of_files_in_each_class = 10\n",
    "\n",
    "#Read all the folders in the directory\n",
    "folder_list = os.listdir(base_dir)\n",
    "print( len(folder_list), \"categories found in the dataset\")\n",
    "\n",
    "#Declare training array\n",
    "cat_list = []\n",
    "x = []\n",
    "y = []\n",
    "y_label = 0\n",
    "\n",
    "#Using just 5 images per category\n",
    "for folder_name in folder_list:\n",
    "    files_list = os.listdir(os.path.join(base_dir, folder_name))\n",
    "    temp=[]\n",
    "    for file_name in files_list[:no_of_files_in_each_class]:\n",
    "        temp.append(len(x))\n",
    "        x.append(np.asarray(Image.open(os.path.join(base_dir, folder_name, file_name)).convert('RGB').resize((100, 100))))\n",
    "        y.append(y_label)\n",
    "    y_label+=1\n",
    "    cat_list.append(temp)\n",
    "\n",
    "cat_list = np.asarray(cat_list)\n",
    "x = np.asarray(x)/255.0\n",
    "y = np.asarray(y)\n",
    "print('X, Y shape',x.shape, y.shape, cat_list.shape)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "numeric-fossil",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 classes for training and 4  classes for testing\n",
      "X&Y shape of training data : (90, 100, 100, 3) and (90,) (9, 10)\n",
      "X&Y shape of testing data : (40, 100, 100, 3) and (40,) (4, 10)\n"
     ]
    }
   ],
   "source": [
    "train_size = int(len(folder_list)*train_test_split)\n",
    "test_size = len(folder_list) - train_size\n",
    "print(train_size, 'classes for training and', test_size, ' classes for testing')\n",
    "\n",
    "train_files = train_size * no_of_files_in_each_class\n",
    "\n",
    "#Training Split\n",
    "x_train = x[:train_files]\n",
    "y_train = y[:train_files]\n",
    "cat_train = cat_list[:train_size]\n",
    "\n",
    "#Validation Split\n",
    "x_val = x[train_files:]\n",
    "y_val = y[train_files:]\n",
    "cat_test = cat_list[train_size:]\n",
    "\n",
    "print('X&Y shape of training data :',x_train.shape, 'and', y_train.shape, cat_train.shape)\n",
    "print('X&Y shape of testing data :' , x_val.shape, 'and', y_val.shape, cat_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "atomic-representation",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_batch(batch_size=64):\n",
    "    \n",
    "    temp_x = x_train\n",
    "    temp_cat_list = cat_train\n",
    "    start=0\n",
    "    end=train_size\n",
    "    batch_x=[]\n",
    "        \n",
    "    batch_y = np.zeros(batch_size)\n",
    "    batch_y[int(batch_size/2):] = 1\n",
    "    np.random.shuffle(batch_y)\n",
    "    \n",
    "    class_list = np.random.randint(start, end, batch_size) \n",
    "    batch_x.append(np.zeros((batch_size, 100, 100, 3)))\n",
    "    batch_x.append(np.zeros((batch_size, 100, 100, 3)))\n",
    "\n",
    "    for i in range(0, batch_size):\n",
    "        batch_x[0][i] = temp_x[np.random.choice(temp_cat_list[class_list[i]])]  \n",
    "        #If train_y has 0 pick from the same class, else pick from any other class\n",
    "        if batch_y[i]==0:\n",
    "            batch_x[1][i] = temp_x[np.random.choice(temp_cat_list[class_list[i]])]\n",
    "\n",
    "        else:\n",
    "            temp_list = np.append(temp_cat_list[:class_list[i]].flatten(), temp_cat_list[class_list[i]+1:].flatten())\n",
    "            batch_x[1][i] = temp_x[np.random.choice(temp_list)]\n",
    "            \n",
    "    return(batch_x, batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bulgarian-processor",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\choij\\anaconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py:27: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"de...)`\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Building a sequential model\n",
    "input_shape=(100, 100, 3)\n",
    "left_input = Input(input_shape)\n",
    "right_input = Input(input_shape)\n",
    "\n",
    "W_init = keras.initializers.RandomNormal(mean = 0.0, stddev = 1e-2)\n",
    "b_init = keras.initializers.RandomNormal(mean = 0.5, stddev = 1e-2)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(64, (10,10), activation='relu', input_shape=input_shape, kernel_initializer=W_init, bias_initializer=b_init, kernel_regularizer=l2(2e-4)),\n",
    "    keras.layers.MaxPooling2D(2, 2),\n",
    "    keras.layers.Conv2D(128, (7,7), activation='relu', kernel_initializer=W_init, bias_initializer=b_init, kernel_regularizer=l2(2e-4)),\n",
    "    keras.layers.MaxPooling2D(2,2),\n",
    "    keras.layers.Conv2D(128, (4,4), activation='relu', kernel_initializer=W_init, bias_initializer=b_init, kernel_regularizer=l2(2e-4)),\n",
    "    keras.layers.MaxPooling2D(2,2),\n",
    "    keras.layers.Conv2D(256, (4,4), activation='relu', kernel_initializer=W_init, bias_initializer=b_init, kernel_regularizer=l2(2e-4)),\n",
    "    keras.layers.MaxPooling2D(2,2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(4096, activation='sigmoid', kernel_initializer=W_init, bias_initializer=b_init)\n",
    "])\n",
    "\n",
    "encoded_l = model(left_input)\n",
    "encoded_r = model(right_input)\n",
    "\n",
    "subtracted = keras.layers.Subtract()([encoded_l, encoded_r])\n",
    "prediction = Dense(1, activation='sigmoid', bias_initializer=b_init)(subtracted)\n",
    "siamese_net = Model(input=[left_input, right_input], output=prediction)\n",
    "\n",
    "optimizer= Adam(learning_rate=0.0006)\n",
    "siamese_net.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "plot_model(siamese_net, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bulgarian-factor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nway_one_shot(model, n_way, n_val):\n",
    "    \n",
    "    temp_x = x_val\n",
    "    temp_cat_list = cat_test\n",
    "    batch_x=[]\n",
    "    x_0_choice=[]\n",
    "    n_correct = 0\n",
    "   \n",
    "    class_list = np.random.randint(train_size+1, len(folder_list)-1, n_val)\n",
    "\n",
    "    for i in class_list:  \n",
    "        j = np.random.choice(cat_list[i])\n",
    "        temp=[]\n",
    "        temp.append(np.zeros((n_way, 100, 100, 3)))\n",
    "        temp.append(np.zeros((n_way, 100, 100, 3)))\n",
    "        for k in range(0, n_way):\n",
    "            temp[0][k] = x[j]\n",
    "            \n",
    "            if k==0:\n",
    "                #print(i, k, j, np.random.choice(cat_list[i]))\n",
    "                temp[1][k] = x[np.random.choice(cat_list[i])]\n",
    "            else:\n",
    "                #print(i, k, j, np.random.choice(np.append(cat_list[:i].flatten(), cat_list[i+1:].flatten())))\n",
    "                temp[1][k] = x[np.random.choice(np.append(cat_list[:i].flatten(), cat_list[i+1:].flatten()))]\n",
    "\n",
    "        result = siamese_net.predict(temp)\n",
    "        result = result.flatten().tolist()\n",
    "        result_index = result.index(min(result))\n",
    "        if result_index == 0:\n",
    "            n_correct = n_correct + 1\n",
    "    print(n_correct, \"correctly classified among\", n_val)\n",
    "    accuracy = (n_correct*100)/n_val\n",
    "    return accuracy\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "environmental-metadata",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 , Loss: 0.7503922\n",
      "Epoch: 2 , Loss: 0.751342\n",
      "Epoch: 3 , Loss: 0.74956083\n",
      "Epoch: 4 , Loss: 0.7481377\n",
      "Epoch: 5 , Loss: 0.74964416\n",
      "Epoch: 6 , Loss: 0.7475433\n",
      "Epoch: 7 , Loss: 0.74806947\n",
      "Epoch: 8 , Loss: 0.7459091\n",
      "Epoch: 9 , Loss: 0.7486526\n",
      "Epoch: 10 , Loss: 0.74333274\n",
      "Epoch: 11 , Loss: 0.74305135\n",
      "Epoch: 12 , Loss: 0.7507272\n",
      "Epoch: 13 , Loss: 0.7437617\n",
      "Epoch: 14 , Loss: 0.736771\n",
      "Epoch: 15 , Loss: 0.74381405\n",
      "Epoch: 16 , Loss: 0.7339327\n",
      "Epoch: 17 , Loss: 0.7260487\n",
      "Epoch: 18 , Loss: 0.7511966\n",
      "Epoch: 19 , Loss: 0.79756784\n",
      "Epoch: 20 , Loss: 0.7360926\n",
      "Epoch: 21 , Loss: 0.7423049\n",
      "Epoch: 22 , Loss: 0.74109524\n",
      "Epoch: 23 , Loss: 0.74129707\n",
      "Epoch: 24 , Loss: 0.73984635\n",
      "Epoch: 25 , Loss: 0.7395073\n",
      "Epoch: 26 , Loss: 0.73909914\n",
      "Epoch: 27 , Loss: 0.73892444\n",
      "Epoch: 28 , Loss: 0.73858136\n",
      "Epoch: 29 , Loss: 0.73857325\n",
      "Epoch: 30 , Loss: 0.7380568\n",
      "Epoch: 31 , Loss: 0.7377904\n",
      "Epoch: 32 , Loss: 0.7375144\n",
      "Epoch: 33 , Loss: 0.7372474\n",
      "Epoch: 34 , Loss: 0.73698485\n",
      "Epoch: 35 , Loss: 0.7367265\n",
      "Epoch: 36 , Loss: 0.7364697\n",
      "Epoch: 37 , Loss: 0.73621523\n",
      "Epoch: 38 , Loss: 0.7359522\n",
      "Epoch: 39 , Loss: 0.7357227\n",
      "Epoch: 40 , Loss: 0.73548293\n",
      "Epoch: 41 , Loss: 0.73523796\n",
      "Epoch: 42 , Loss: 0.73500085\n",
      "Epoch: 43 , Loss: 0.734767\n",
      "Epoch: 44 , Loss: 0.73453593\n",
      "Epoch: 45 , Loss: 0.73430824\n",
      "Epoch: 46 , Loss: 0.7340833\n",
      "Epoch: 47 , Loss: 0.73386115\n",
      "Epoch: 48 , Loss: 0.7336419\n",
      "Epoch: 49 , Loss: 0.73342526\n",
      "Epoch: 50 , Loss: 0.7332116\n",
      "Epoch: 51 , Loss: 0.7330005\n",
      "Epoch: 52 , Loss: 0.7327918\n",
      "Epoch: 53 , Loss: 0.7325856\n",
      "Epoch: 54 , Loss: 0.7323818\n",
      "Epoch: 55 , Loss: 0.73218066\n",
      "Epoch: 56 , Loss: 0.7319825\n",
      "Epoch: 57 , Loss: 0.73178554\n",
      "Epoch: 58 , Loss: 0.7315908\n",
      "Epoch: 59 , Loss: 0.7314056\n",
      "Epoch: 60 , Loss: 0.73121184\n",
      "Epoch: 61 , Loss: 0.7310246\n",
      "Epoch: 62 , Loss: 0.73083717\n",
      "Epoch: 63 , Loss: 0.73065394\n",
      "Epoch: 64 , Loss: 0.7304724\n",
      "Epoch: 65 , Loss: 0.7302932\n",
      "Epoch: 66 , Loss: 0.73011535\n",
      "Epoch: 67 , Loss: 0.72993994\n",
      "Epoch: 68 , Loss: 0.7297658\n",
      "Epoch: 69 , Loss: 0.72959363\n",
      "Epoch: 70 , Loss: 0.72942334\n",
      "Epoch: 71 , Loss: 0.72925454\n",
      "Epoch: 72 , Loss: 0.7290875\n",
      "Epoch: 73 , Loss: 0.72892195\n",
      "Epoch: 74 , Loss: 0.7287581\n",
      "Epoch: 75 , Loss: 0.7285959\n",
      "Epoch: 76 , Loss: 0.7284044\n",
      "Epoch: 77 , Loss: 0.7282744\n",
      "Epoch: 78 , Loss: 0.7281326\n",
      "Epoch: 79 , Loss: 0.72796273\n",
      "Epoch: 80 , Loss: 0.7278084\n",
      "Epoch: 81 , Loss: 0.72765505\n",
      "Epoch: 82 , Loss: 0.7275034\n",
      "Epoch: 83 , Loss: 0.7273532\n",
      "Epoch: 84 , Loss: 0.7272035\n",
      "Epoch: 85 , Loss: 0.72705585\n",
      "Epoch: 86 , Loss: 0.72690916\n",
      "Epoch: 87 , Loss: 0.72676355\n",
      "Epoch: 88 , Loss: 0.72661924\n",
      "Epoch: 89 , Loss: 0.72647613\n",
      "Epoch: 90 , Loss: 0.7263344\n",
      "Epoch: 91 , Loss: 0.72619337\n",
      "Epoch: 92 , Loss: 0.72605383\n",
      "Epoch: 93 , Loss: 0.72591525\n",
      "Epoch: 94 , Loss: 0.72577786\n",
      "Epoch: 95 , Loss: 0.7256418\n",
      "Epoch: 96 , Loss: 0.7255067\n",
      "Epoch: 97 , Loss: 0.7253722\n",
      "Epoch: 98 , Loss: 0.72523934\n",
      "Epoch: 99 , Loss: 0.7251079\n",
      "Epoch: 100 , Loss: 0.72497624\n",
      "Epoch: 101 , Loss: 0.72484565\n",
      "Epoch: 102 , Loss: 0.7247167\n",
      "Epoch: 103 , Loss: 0.72458905\n",
      "Epoch: 104 , Loss: 0.72446686\n",
      "Epoch: 105 , Loss: 0.72433496\n",
      "Epoch: 106 , Loss: 0.7242114\n",
      "Epoch: 107 , Loss: 0.7240861\n",
      "Epoch: 108 , Loss: 0.7239627\n",
      "Epoch: 109 , Loss: 0.723841\n",
      "Epoch: 110 , Loss: 0.7237189\n",
      "Epoch: 111 , Loss: 0.72359747\n",
      "Epoch: 112 , Loss: 0.7234842\n",
      "Epoch: 113 , Loss: 0.723357\n",
      "Epoch: 114 , Loss: 0.7232333\n",
      "Epoch: 115 , Loss: 0.72316486\n",
      "Epoch: 116 , Loss: 0.72301\n",
      "Epoch: 117 , Loss: 0.7228915\n",
      "Epoch: 118 , Loss: 0.72277695\n",
      "Epoch: 119 , Loss: 0.7226662\n",
      "Epoch: 120 , Loss: 0.72255087\n",
      "Epoch: 121 , Loss: 0.72243494\n",
      "Epoch: 122 , Loss: 0.7223282\n",
      "Epoch: 123 , Loss: 0.722206\n",
      "Epoch: 124 , Loss: 0.7221461\n",
      "Epoch: 125 , Loss: 0.7219979\n",
      "Epoch: 126 , Loss: 0.72188914\n",
      "Epoch: 127 , Loss: 0.7217808\n",
      "Epoch: 128 , Loss: 0.72167337\n",
      "Epoch: 129 , Loss: 0.7215672\n",
      "Epoch: 130 , Loss: 0.7214633\n",
      "Epoch: 131 , Loss: 0.7213594\n",
      "Epoch: 132 , Loss: 0.72124714\n",
      "Epoch: 133 , Loss: 0.7211478\n",
      "Epoch: 134 , Loss: 0.7210511\n",
      "Epoch: 135 , Loss: 0.7209352\n",
      "Epoch: 136 , Loss: 0.72084236\n",
      "Epoch: 137 , Loss: 0.7207372\n",
      "Epoch: 138 , Loss: 0.7206344\n",
      "Epoch: 139 , Loss: 0.7205312\n",
      "Epoch: 140 , Loss: 0.720458\n",
      "Epoch: 141 , Loss: 0.72034323\n",
      "Epoch: 142 , Loss: 0.7202785\n",
      "Epoch: 143 , Loss: 0.7201608\n",
      "Epoch: 144 , Loss: 0.7200469\n",
      "Epoch: 145 , Loss: 0.71994704\n",
      "Epoch: 146 , Loss: 0.7198602\n",
      "Epoch: 147 , Loss: 0.7197552\n",
      "Epoch: 148 , Loss: 0.7196662\n",
      "Epoch: 149 , Loss: 0.7195723\n",
      "Epoch: 150 , Loss: 0.7194783\n",
      "Epoch: 151 , Loss: 0.7193821\n",
      "Epoch: 152 , Loss: 0.7192925\n",
      "Epoch: 153 , Loss: 0.7192007\n",
      "Epoch: 154 , Loss: 0.7191073\n",
      "Epoch: 155 , Loss: 0.7190161\n",
      "Epoch: 156 , Loss: 0.71892655\n",
      "Epoch: 157 , Loss: 0.7188349\n",
      "Epoch: 158 , Loss: 0.7187464\n",
      "Epoch: 159 , Loss: 0.7186551\n",
      "Epoch: 160 , Loss: 0.71856815\n",
      "Epoch: 161 , Loss: 0.7184804\n",
      "Epoch: 162 , Loss: 0.71839404\n",
      "Epoch: 163 , Loss: 0.71830416\n",
      "Epoch: 164 , Loss: 0.718219\n",
      "Epoch: 165 , Loss: 0.71813047\n",
      "Epoch: 166 , Loss: 0.71804494\n",
      "Epoch: 167 , Loss: 0.7179611\n",
      "Epoch: 168 , Loss: 0.71787477\n",
      "Epoch: 169 , Loss: 0.7177918\n",
      "Epoch: 170 , Loss: 0.7177049\n",
      "Epoch: 171 , Loss: 0.71761936\n",
      "Epoch: 172 , Loss: 0.7175478\n",
      "Epoch: 173 , Loss: 0.71746176\n",
      "Epoch: 174 , Loss: 0.7173755\n",
      "Epoch: 175 , Loss: 0.717293\n",
      "Epoch: 176 , Loss: 0.7172111\n",
      "Epoch: 177 , Loss: 0.71713084\n",
      "Epoch: 178 , Loss: 0.7170483\n",
      "Epoch: 179 , Loss: 0.7169703\n",
      "Epoch: 180 , Loss: 0.71688956\n",
      "Epoch: 181 , Loss: 0.7168127\n",
      "Epoch: 182 , Loss: 0.7167366\n",
      "Epoch: 183 , Loss: 0.7166501\n",
      "Epoch: 184 , Loss: 0.7165784\n",
      "Epoch: 185 , Loss: 0.7165109\n",
      "Epoch: 186 , Loss: 0.7164219\n",
      "Epoch: 187 , Loss: 0.7163372\n",
      "Epoch: 188 , Loss: 0.71625936\n",
      "Epoch: 189 , Loss: 0.71619195\n",
      "Epoch: 190 , Loss: 0.716126\n",
      "Epoch: 191 , Loss: 0.7160285\n",
      "Epoch: 192 , Loss: 0.7160009\n",
      "Epoch: 193 , Loss: 0.7158814\n",
      "Epoch: 194 , Loss: 0.7158112\n",
      "Epoch: 195 , Loss: 0.71575254\n",
      "Epoch: 196 , Loss: 0.71567446\n",
      "Epoch: 197 , Loss: 0.71559894\n",
      "Epoch: 198 , Loss: 0.7155243\n",
      "Epoch: 199 , Loss: 0.7154478\n",
      "Epoch: 200 , Loss: 0.71538305\n",
      "Epoch: 201 , Loss: 0.7153018\n",
      "Epoch: 202 , Loss: 0.7152322\n",
      "Epoch: 203 , Loss: 0.7151579\n",
      "Epoch: 204 , Loss: 0.71509254\n",
      "Epoch: 205 , Loss: 0.71501434\n",
      "Epoch: 206 , Loss: 0.7149449\n",
      "Epoch: 207 , Loss: 0.71487\n",
      "Epoch: 208 , Loss: 0.71479475\n",
      "Epoch: 209 , Loss: 0.71473634\n",
      "Epoch: 210 , Loss: 0.7146483\n",
      "Epoch: 211 , Loss: 0.7145675\n",
      "Epoch: 212 , Loss: 0.71454746\n",
      "Epoch: 213 , Loss: 0.714463\n",
      "Epoch: 214 , Loss: 0.7144035\n",
      "Epoch: 215 , Loss: 0.7143381\n",
      "Epoch: 216 , Loss: 0.7142576\n",
      "Epoch: 217 , Loss: 0.7142217\n",
      "Epoch: 218 , Loss: 0.71410704\n",
      "Epoch: 219 , Loss: 0.7140918\n",
      "Epoch: 220 , Loss: 0.71398014\n",
      "Epoch: 221 , Loss: 0.71392494\n",
      "Epoch: 222 , Loss: 0.71387124\n",
      "Epoch: 223 , Loss: 0.71378475\n",
      "Epoch: 224 , Loss: 0.7137216\n",
      "Epoch: 225 , Loss: 0.7136004\n",
      "Epoch: 226 , Loss: 0.71358824\n",
      "Epoch: 227 , Loss: 0.7134504\n",
      "Epoch: 228 , Loss: 0.7133568\n",
      "Epoch: 229 , Loss: 0.713167\n",
      "Epoch: 230 , Loss: 0.71298933\n",
      "Epoch: 231 , Loss: 0.7103122\n",
      "Epoch: 232 , Loss: 0.7129296\n",
      "Epoch: 233 , Loss: 0.71673375\n",
      "Epoch: 234 , Loss: 0.7171951\n",
      "Epoch: 235 , Loss: 0.71462977\n",
      "Epoch: 236 , Loss: 0.71313125\n",
      "Epoch: 237 , Loss: 0.7131405\n",
      "Epoch: 238 , Loss: 0.7131163\n",
      "Epoch: 239 , Loss: 0.71323436\n",
      "Epoch: 240 , Loss: 0.71322346\n",
      "Epoch: 241 , Loss: 0.7132795\n",
      "Epoch: 242 , Loss: 0.71332324\n",
      "Epoch: 243 , Loss: 0.7132837\n",
      "Epoch: 244 , Loss: 0.713361\n",
      "Epoch: 245 , Loss: 0.71328187\n",
      "Epoch: 246 , Loss: 0.7132743\n",
      "Epoch: 247 , Loss: 0.7132574\n",
      "Epoch: 248 , Loss: 0.71320033\n",
      "Epoch: 249 , Loss: 0.7131169\n",
      "Epoch: 250 , Loss: 0.71311796\n",
      "=============================================\n",
      "27 correctly classified among 100\n",
      "Accuracy as of 250 epochs: 27.0\n",
      "=============================================\n",
      "Epoch: 251 , Loss: 0.71298254\n",
      "Epoch: 252 , Loss: 0.7129701\n",
      "Epoch: 253 , Loss: 0.7128058\n",
      "Epoch: 254 , Loss: 0.71286654\n",
      "Epoch: 255 , Loss: 0.7126395\n",
      "Epoch: 256 , Loss: 0.71251315\n",
      "Epoch: 257 , Loss: 0.7125156\n",
      "Epoch: 258 , Loss: 0.71251535\n",
      "Epoch: 259 , Loss: 0.7122531\n",
      "Epoch: 260 , Loss: 0.7121982\n",
      "Epoch: 261 , Loss: 0.7120483\n",
      "Epoch: 262 , Loss: 0.7118836\n",
      "Epoch: 263 , Loss: 0.7116211\n",
      "Epoch: 264 , Loss: 0.71195316\n",
      "Epoch: 265 , Loss: 0.71176916\n",
      "Epoch: 266 , Loss: 0.71156496\n",
      "Epoch: 267 , Loss: 0.71152365\n",
      "Epoch: 268 , Loss: 0.71157426\n",
      "Epoch: 269 , Loss: 0.7116105\n",
      "Epoch: 270 , Loss: 0.7114307\n",
      "Epoch: 271 , Loss: 0.71137655\n",
      "Epoch: 272 , Loss: 0.7112848\n",
      "Epoch: 273 , Loss: 0.7112419\n",
      "Epoch: 274 , Loss: 0.71112937\n",
      "Epoch: 275 , Loss: 0.71107715\n",
      "Epoch: 276 , Loss: 0.7108962\n",
      "Epoch: 277 , Loss: 0.71094084\n",
      "Epoch: 278 , Loss: 0.7108837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 279 , Loss: 0.7107962\n",
      "Epoch: 280 , Loss: 0.7107722\n",
      "Epoch: 281 , Loss: 0.7105987\n",
      "Epoch: 282 , Loss: 0.7103814\n",
      "Epoch: 283 , Loss: 0.7101749\n",
      "Epoch: 284 , Loss: 0.710651\n",
      "Epoch: 285 , Loss: 0.71038365\n",
      "Epoch: 286 , Loss: 0.7109938\n",
      "Epoch: 287 , Loss: 0.7100586\n",
      "Epoch: 288 , Loss: 0.7100183\n",
      "Epoch: 289 , Loss: 0.7100787\n",
      "Epoch: 290 , Loss: 0.70986634\n",
      "Epoch: 291 , Loss: 0.71019286\n",
      "Epoch: 292 , Loss: 0.7123488\n",
      "Epoch: 293 , Loss: 0.7089418\n",
      "Epoch: 294 , Loss: 0.70970154\n",
      "Epoch: 295 , Loss: 0.7099095\n",
      "Epoch: 296 , Loss: 0.7104082\n",
      "Epoch: 297 , Loss: 0.70975757\n",
      "Epoch: 298 , Loss: 0.70982355\n",
      "Epoch: 299 , Loss: 0.7218523\n",
      "Epoch: 300 , Loss: 0.7096203\n",
      "Epoch: 301 , Loss: 0.709772\n",
      "Epoch: 302 , Loss: 0.70979637\n",
      "Epoch: 303 , Loss: 0.7100818\n",
      "Epoch: 304 , Loss: 0.7103383\n",
      "Epoch: 305 , Loss: 0.710534\n",
      "Epoch: 306 , Loss: 0.71075404\n",
      "Epoch: 307 , Loss: 0.7109647\n",
      "Epoch: 308 , Loss: 0.711161\n",
      "Epoch: 309 , Loss: 0.71133995\n",
      "Epoch: 310 , Loss: 0.7114986\n",
      "Epoch: 311 , Loss: 0.7116379\n",
      "Epoch: 312 , Loss: 0.7117546\n",
      "Epoch: 313 , Loss: 0.7118504\n",
      "Epoch: 314 , Loss: 0.7119258\n",
      "Epoch: 315 , Loss: 0.7119818\n",
      "Epoch: 316 , Loss: 0.7120194\n",
      "Epoch: 317 , Loss: 0.7120402\n",
      "Epoch: 318 , Loss: 0.7120456\n",
      "Epoch: 319 , Loss: 0.71203667\n",
      "Epoch: 320 , Loss: 0.7120153\n",
      "Epoch: 321 , Loss: 0.7119825\n",
      "Epoch: 322 , Loss: 0.71193975\n",
      "Epoch: 323 , Loss: 0.7118882\n",
      "Epoch: 324 , Loss: 0.71182895\n",
      "Epoch: 325 , Loss: 0.71176296\n",
      "Epoch: 326 , Loss: 0.71169144\n",
      "Epoch: 327 , Loss: 0.71161497\n",
      "Epoch: 328 , Loss: 0.7115345\n",
      "Epoch: 329 , Loss: 0.7114506\n",
      "Epoch: 330 , Loss: 0.71136403\n",
      "Epoch: 331 , Loss: 0.711275\n",
      "Epoch: 332 , Loss: 0.7111844\n",
      "Epoch: 333 , Loss: 0.71109253\n",
      "Epoch: 334 , Loss: 0.7109997\n",
      "Epoch: 335 , Loss: 0.71090627\n",
      "Epoch: 336 , Loss: 0.7108125\n",
      "Epoch: 337 , Loss: 0.7107187\n",
      "Epoch: 338 , Loss: 0.710625\n",
      "Epoch: 339 , Loss: 0.7105317\n",
      "Epoch: 340 , Loss: 0.71043867\n",
      "Epoch: 341 , Loss: 0.71034634\n",
      "Epoch: 342 , Loss: 0.71025467\n",
      "Epoch: 343 , Loss: 0.71016365\n",
      "Epoch: 344 , Loss: 0.71007353\n",
      "Epoch: 345 , Loss: 0.70998436\n",
      "Epoch: 346 , Loss: 0.7098962\n",
      "Epoch: 347 , Loss: 0.7098088\n",
      "Epoch: 348 , Loss: 0.70972246\n",
      "Epoch: 349 , Loss: 0.70963734\n",
      "Epoch: 350 , Loss: 0.709553\n",
      "Epoch: 351 , Loss: 0.7094698\n",
      "Epoch: 352 , Loss: 0.70938754\n",
      "Epoch: 353 , Loss: 0.7093063\n",
      "Epoch: 354 , Loss: 0.709226\n",
      "Epoch: 355 , Loss: 0.70914686\n",
      "Epoch: 356 , Loss: 0.7090686\n",
      "Epoch: 357 , Loss: 0.70899135\n",
      "Epoch: 358 , Loss: 0.70891505\n",
      "Epoch: 359 , Loss: 0.70883965\n",
      "Epoch: 360 , Loss: 0.7087652\n",
      "Epoch: 361 , Loss: 0.70869166\n",
      "Epoch: 362 , Loss: 0.7086189\n",
      "Epoch: 363 , Loss: 0.7085471\n",
      "Epoch: 364 , Loss: 0.7084761\n",
      "Epoch: 365 , Loss: 0.70840573\n",
      "Epoch: 366 , Loss: 0.70833635\n",
      "Epoch: 367 , Loss: 0.7082676\n",
      "Epoch: 368 , Loss: 0.70819974\n",
      "Epoch: 369 , Loss: 0.7081325\n",
      "Epoch: 370 , Loss: 0.7080661\n",
      "Epoch: 371 , Loss: 0.7080003\n",
      "Epoch: 372 , Loss: 0.70793515\n",
      "Epoch: 373 , Loss: 0.70787066\n",
      "Epoch: 374 , Loss: 0.70780677\n",
      "Epoch: 375 , Loss: 0.7077436\n",
      "Epoch: 376 , Loss: 0.70768106\n",
      "Epoch: 377 , Loss: 0.707619\n",
      "Epoch: 378 , Loss: 0.7075576\n",
      "Epoch: 379 , Loss: 0.7074966\n",
      "Epoch: 380 , Loss: 0.7074363\n",
      "Epoch: 381 , Loss: 0.7073763\n",
      "Epoch: 382 , Loss: 0.70731705\n",
      "Epoch: 383 , Loss: 0.7072582\n",
      "Epoch: 384 , Loss: 0.70719993\n",
      "Epoch: 385 , Loss: 0.70714206\n",
      "Epoch: 386 , Loss: 0.7070846\n",
      "Epoch: 387 , Loss: 0.7070277\n",
      "Epoch: 388 , Loss: 0.70697117\n",
      "Epoch: 389 , Loss: 0.70691514\n",
      "Epoch: 390 , Loss: 0.7068596\n",
      "Epoch: 391 , Loss: 0.70680434\n",
      "Epoch: 392 , Loss: 0.70674956\n",
      "Epoch: 393 , Loss: 0.70669514\n",
      "Epoch: 394 , Loss: 0.70664114\n",
      "Epoch: 395 , Loss: 0.7065873\n",
      "Epoch: 396 , Loss: 0.7065341\n",
      "Epoch: 397 , Loss: 0.7064811\n",
      "Epoch: 398 , Loss: 0.7064287\n",
      "Epoch: 399 , Loss: 0.7063764\n",
      "Epoch: 400 , Loss: 0.7063246\n",
      "Epoch: 401 , Loss: 0.706273\n",
      "Epoch: 402 , Loss: 0.7062218\n",
      "Epoch: 403 , Loss: 0.706171\n",
      "Epoch: 404 , Loss: 0.7061204\n",
      "Epoch: 405 , Loss: 0.7060702\n",
      "Epoch: 406 , Loss: 0.70602024\n",
      "Epoch: 407 , Loss: 0.70597047\n",
      "Epoch: 408 , Loss: 0.7059213\n",
      "Epoch: 409 , Loss: 0.70587224\n",
      "Epoch: 410 , Loss: 0.7058234\n",
      "Epoch: 411 , Loss: 0.70577496\n",
      "Epoch: 412 , Loss: 0.7057268\n",
      "Epoch: 413 , Loss: 0.7056789\n",
      "Epoch: 414 , Loss: 0.70563114\n",
      "Epoch: 415 , Loss: 0.7055839\n",
      "Epoch: 416 , Loss: 0.7055367\n",
      "Epoch: 417 , Loss: 0.7054898\n",
      "Epoch: 418 , Loss: 0.7054432\n",
      "Epoch: 419 , Loss: 0.7053968\n",
      "Epoch: 420 , Loss: 0.7053507\n",
      "Epoch: 421 , Loss: 0.7053047\n",
      "Epoch: 422 , Loss: 0.7052592\n",
      "Epoch: 423 , Loss: 0.7052138\n",
      "Epoch: 424 , Loss: 0.7051686\n",
      "Epoch: 425 , Loss: 0.70512366\n",
      "Epoch: 426 , Loss: 0.70507896\n",
      "Epoch: 427 , Loss: 0.70503443\n",
      "Epoch: 428 , Loss: 0.7049904\n",
      "Epoch: 429 , Loss: 0.70494634\n",
      "Epoch: 430 , Loss: 0.70490247\n",
      "Epoch: 431 , Loss: 0.70485866\n",
      "Epoch: 432 , Loss: 0.7048154\n",
      "Epoch: 433 , Loss: 0.70477235\n",
      "Epoch: 434 , Loss: 0.7047292\n",
      "Epoch: 435 , Loss: 0.7046863\n",
      "Epoch: 436 , Loss: 0.7046439\n",
      "Epoch: 437 , Loss: 0.70460093\n",
      "Epoch: 438 , Loss: 0.7045593\n",
      "Epoch: 439 , Loss: 0.7045174\n",
      "Epoch: 440 , Loss: 0.70447546\n",
      "Epoch: 441 , Loss: 0.70443404\n",
      "Epoch: 442 , Loss: 0.7043922\n",
      "Epoch: 443 , Loss: 0.7043513\n",
      "Epoch: 444 , Loss: 0.7043099\n",
      "Epoch: 445 , Loss: 0.70427006\n",
      "Epoch: 446 , Loss: 0.70422846\n",
      "Epoch: 447 , Loss: 0.70418924\n",
      "Epoch: 448 , Loss: 0.70414734\n",
      "Epoch: 449 , Loss: 0.70410794\n",
      "Epoch: 450 , Loss: 0.70406777\n",
      "Epoch: 451 , Loss: 0.7040268\n",
      "Epoch: 452 , Loss: 0.7039903\n",
      "Epoch: 453 , Loss: 0.7039501\n",
      "Epoch: 454 , Loss: 0.7039109\n",
      "Epoch: 455 , Loss: 0.7038703\n",
      "Epoch: 456 , Loss: 0.703832\n",
      "Epoch: 457 , Loss: 0.7037906\n",
      "Epoch: 458 , Loss: 0.70375705\n",
      "Epoch: 459 , Loss: 0.70371574\n",
      "Epoch: 460 , Loss: 0.7036777\n",
      "Epoch: 461 , Loss: 0.70363986\n",
      "Epoch: 462 , Loss: 0.7036045\n",
      "Epoch: 463 , Loss: 0.70356226\n",
      "Epoch: 464 , Loss: 0.70353216\n",
      "Epoch: 465 , Loss: 0.7034984\n",
      "Epoch: 466 , Loss: 0.7034535\n",
      "Epoch: 467 , Loss: 0.70342135\n",
      "Epoch: 468 , Loss: 0.70337754\n",
      "Epoch: 469 , Loss: 0.7033326\n",
      "Epoch: 470 , Loss: 0.70330745\n",
      "Epoch: 471 , Loss: 0.7032733\n",
      "Epoch: 472 , Loss: 0.703217\n",
      "Epoch: 473 , Loss: 0.7031828\n",
      "Epoch: 474 , Loss: 0.7031591\n",
      "Epoch: 475 , Loss: 0.70312446\n",
      "Epoch: 476 , Loss: 0.7030898\n",
      "Epoch: 477 , Loss: 0.7030658\n",
      "Epoch: 478 , Loss: 0.70302933\n",
      "Epoch: 479 , Loss: 0.7029763\n",
      "Epoch: 480 , Loss: 0.70295644\n",
      "Epoch: 481 , Loss: 0.70291734\n",
      "Epoch: 482 , Loss: 0.7028599\n",
      "Epoch: 483 , Loss: 0.7028301\n",
      "Epoch: 484 , Loss: 0.7027905\n",
      "Epoch: 485 , Loss: 0.7027437\n",
      "Epoch: 486 , Loss: 0.70272535\n",
      "Epoch: 487 , Loss: 0.70271224\n",
      "Epoch: 488 , Loss: 0.7026708\n",
      "Epoch: 489 , Loss: 0.7026\n",
      "Epoch: 490 , Loss: 0.70254856\n",
      "Epoch: 491 , Loss: 0.7024854\n",
      "Epoch: 492 , Loss: 0.70245725\n",
      "Epoch: 493 , Loss: 0.70262545\n",
      "Epoch: 494 , Loss: 0.7022773\n",
      "Epoch: 495 , Loss: 0.7021749\n",
      "Epoch: 496 , Loss: 0.7058269\n",
      "Epoch: 497 , Loss: 0.7027542\n",
      "Epoch: 498 , Loss: 0.7023905\n",
      "Epoch: 499 , Loss: 0.70234555\n",
      "Epoch: 500 , Loss: 0.7023582\n",
      "=============================================\n",
      "10 correctly classified among 100\n",
      "Accuracy as of 500 epochs: 10.0\n",
      "=============================================\n",
      "Epoch: 501 , Loss: 0.70236266\n",
      "Epoch: 502 , Loss: 0.70236903\n",
      "Epoch: 503 , Loss: 0.7023746\n",
      "Epoch: 504 , Loss: 0.702378\n",
      "Epoch: 505 , Loss: 0.7023769\n",
      "Epoch: 506 , Loss: 0.7023719\n",
      "Epoch: 507 , Loss: 0.70236504\n",
      "Epoch: 508 , Loss: 0.7023509\n",
      "Epoch: 509 , Loss: 0.70233405\n",
      "Epoch: 510 , Loss: 0.7023134\n",
      "Epoch: 511 , Loss: 0.7022897\n",
      "Epoch: 512 , Loss: 0.70226276\n",
      "Epoch: 513 , Loss: 0.70223284\n",
      "Epoch: 514 , Loss: 0.70219314\n",
      "Epoch: 515 , Loss: 0.70212185\n",
      "Epoch: 516 , Loss: 0.70213336\n",
      "Epoch: 517 , Loss: 0.70209765\n",
      "Epoch: 518 , Loss: 0.7020609\n",
      "Epoch: 519 , Loss: 0.7020233\n",
      "Epoch: 520 , Loss: 0.7019855\n",
      "Epoch: 521 , Loss: 0.7019472\n",
      "Epoch: 522 , Loss: 0.70190877\n",
      "Epoch: 523 , Loss: 0.7018702\n",
      "Epoch: 524 , Loss: 0.70183164\n",
      "Epoch: 525 , Loss: 0.7017933\n",
      "Epoch: 526 , Loss: 0.70175505\n",
      "Epoch: 527 , Loss: 0.7017169\n",
      "Epoch: 528 , Loss: 0.701679\n",
      "Epoch: 529 , Loss: 0.70164156\n",
      "Epoch: 530 , Loss: 0.70160425\n",
      "Epoch: 531 , Loss: 0.7015672\n",
      "Epoch: 532 , Loss: 0.7015306\n",
      "Epoch: 533 , Loss: 0.7014944\n",
      "Epoch: 534 , Loss: 0.70145845\n",
      "Epoch: 535 , Loss: 0.70142275\n",
      "Epoch: 536 , Loss: 0.7013874\n",
      "Epoch: 537 , Loss: 0.7013527\n",
      "Epoch: 538 , Loss: 0.7013181\n",
      "Epoch: 539 , Loss: 0.701284\n",
      "Epoch: 540 , Loss: 0.7012499\n",
      "Epoch: 541 , Loss: 0.7012166\n",
      "Epoch: 542 , Loss: 0.70118314\n",
      "Epoch: 543 , Loss: 0.70115036\n",
      "Epoch: 544 , Loss: 0.70111746\n",
      "Epoch: 545 , Loss: 0.7010851\n",
      "Epoch: 546 , Loss: 0.70105284\n",
      "Epoch: 547 , Loss: 0.70102113\n",
      "Epoch: 548 , Loss: 0.70098954\n",
      "Epoch: 549 , Loss: 0.70095813\n",
      "Epoch: 550 , Loss: 0.7009269\n",
      "Epoch: 551 , Loss: 0.7008957\n",
      "Epoch: 552 , Loss: 0.7008649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 553 , Loss: 0.7008344\n",
      "Epoch: 554 , Loss: 0.7008032\n",
      "Epoch: 555 , Loss: 0.70077014\n",
      "Epoch: 556 , Loss: 0.7007455\n",
      "Epoch: 557 , Loss: 0.7007374\n",
      "Epoch: 558 , Loss: 0.7007144\n",
      "Epoch: 559 , Loss: 0.70068663\n",
      "Epoch: 560 , Loss: 0.7006272\n",
      "Epoch: 561 , Loss: 0.70059675\n",
      "Epoch: 562 , Loss: 0.7005657\n",
      "Epoch: 563 , Loss: 0.7005438\n",
      "Epoch: 564 , Loss: 0.70051515\n",
      "Epoch: 565 , Loss: 0.7004843\n",
      "Epoch: 566 , Loss: 0.70045435\n",
      "Epoch: 567 , Loss: 0.7004286\n",
      "Epoch: 568 , Loss: 0.7003991\n",
      "Epoch: 569 , Loss: 0.70037353\n",
      "Epoch: 570 , Loss: 0.70034844\n",
      "Epoch: 571 , Loss: 0.70032394\n",
      "Epoch: 572 , Loss: 0.7002968\n",
      "Epoch: 573 , Loss: 0.70026577\n",
      "Epoch: 574 , Loss: 0.7002338\n",
      "Epoch: 575 , Loss: 0.70021105\n",
      "Epoch: 576 , Loss: 0.7001858\n",
      "Epoch: 577 , Loss: 0.70015705\n",
      "Epoch: 578 , Loss: 0.7001276\n",
      "Epoch: 579 , Loss: 0.70010924\n",
      "Epoch: 580 , Loss: 0.7000724\n",
      "Epoch: 581 , Loss: 0.70004684\n",
      "Epoch: 582 , Loss: 0.7000296\n",
      "Epoch: 583 , Loss: 0.6999931\n",
      "Epoch: 584 , Loss: 0.6999777\n",
      "Epoch: 585 , Loss: 0.6999476\n",
      "Epoch: 586 , Loss: 0.69991976\n",
      "Epoch: 587 , Loss: 0.6999001\n",
      "Epoch: 588 , Loss: 0.6998692\n",
      "Epoch: 589 , Loss: 0.69983083\n",
      "Epoch: 590 , Loss: 0.69980615\n",
      "Epoch: 591 , Loss: 0.6997855\n",
      "Epoch: 592 , Loss: 0.69974256\n",
      "Epoch: 593 , Loss: 0.69971114\n",
      "Epoch: 594 , Loss: 0.69977486\n",
      "Epoch: 595 , Loss: 0.6996559\n",
      "Epoch: 596 , Loss: 0.6996898\n",
      "Epoch: 597 , Loss: 0.6996198\n",
      "Epoch: 598 , Loss: 0.6996744\n",
      "Epoch: 599 , Loss: 0.6996578\n",
      "Epoch: 600 , Loss: 0.6996003\n",
      "Epoch: 601 , Loss: 0.69955945\n",
      "Epoch: 602 , Loss: 0.69958127\n",
      "Epoch: 603 , Loss: 0.6995455\n",
      "Epoch: 604 , Loss: 0.69947785\n",
      "Epoch: 605 , Loss: 0.6994767\n",
      "Epoch: 606 , Loss: 0.6994256\n",
      "Epoch: 607 , Loss: 0.69941694\n",
      "Epoch: 608 , Loss: 0.699391\n",
      "Epoch: 609 , Loss: 0.69936687\n",
      "Epoch: 610 , Loss: 0.69934314\n",
      "Epoch: 611 , Loss: 0.6993196\n",
      "Epoch: 612 , Loss: 0.69929755\n",
      "Epoch: 613 , Loss: 0.69927996\n",
      "Epoch: 614 , Loss: 0.69925183\n",
      "Epoch: 615 , Loss: 0.6992344\n",
      "Epoch: 616 , Loss: 0.6992228\n",
      "Epoch: 617 , Loss: 0.6991935\n",
      "Epoch: 618 , Loss: 0.6991721\n",
      "Epoch: 619 , Loss: 0.6991277\n",
      "Epoch: 620 , Loss: 0.6991208\n",
      "Epoch: 621 , Loss: 0.69910836\n",
      "Epoch: 622 , Loss: 0.6990679\n",
      "Epoch: 623 , Loss: 0.69905454\n",
      "Epoch: 624 , Loss: 0.6990319\n",
      "Epoch: 625 , Loss: 0.6990099\n",
      "Epoch: 626 , Loss: 0.69898516\n",
      "Epoch: 627 , Loss: 0.6989591\n",
      "Epoch: 628 , Loss: 0.6989524\n",
      "Epoch: 629 , Loss: 0.69892794\n",
      "Epoch: 630 , Loss: 0.69889456\n",
      "Epoch: 631 , Loss: 0.69887817\n",
      "Epoch: 632 , Loss: 0.6988542\n",
      "Epoch: 633 , Loss: 0.6988328\n",
      "Epoch: 634 , Loss: 0.69880944\n",
      "Epoch: 635 , Loss: 0.69877905\n",
      "Epoch: 636 , Loss: 0.69877094\n",
      "Epoch: 637 , Loss: 0.6987611\n",
      "Epoch: 638 , Loss: 0.69873303\n",
      "Epoch: 639 , Loss: 0.69871783\n",
      "Epoch: 640 , Loss: 0.6986987\n",
      "Epoch: 641 , Loss: 0.6986436\n",
      "Epoch: 642 , Loss: 0.6986464\n",
      "Epoch: 643 , Loss: 0.69864666\n",
      "Epoch: 644 , Loss: 0.6985396\n",
      "Epoch: 645 , Loss: 0.6984994\n",
      "Epoch: 646 , Loss: 0.6985876\n",
      "Epoch: 647 , Loss: 0.6985061\n",
      "Epoch: 648 , Loss: 0.6985951\n",
      "Epoch: 649 , Loss: 0.6983993\n",
      "Epoch: 650 , Loss: 0.698809\n",
      "Epoch: 651 , Loss: 0.69866055\n",
      "Epoch: 652 , Loss: 0.6985895\n",
      "Epoch: 653 , Loss: 0.69844127\n",
      "Epoch: 654 , Loss: 0.69843656\n",
      "Epoch: 655 , Loss: 0.69839406\n",
      "Epoch: 656 , Loss: 0.69838315\n",
      "Epoch: 657 , Loss: 0.6983733\n",
      "Epoch: 658 , Loss: 0.6983555\n",
      "Epoch: 659 , Loss: 0.6983353\n",
      "Epoch: 660 , Loss: 0.6983179\n",
      "Epoch: 661 , Loss: 0.6983089\n",
      "Epoch: 662 , Loss: 0.6982861\n",
      "Epoch: 663 , Loss: 0.69827485\n",
      "Epoch: 664 , Loss: 0.6982571\n",
      "Epoch: 665 , Loss: 0.6982342\n",
      "Epoch: 666 , Loss: 0.69822043\n",
      "Epoch: 667 , Loss: 0.6981964\n",
      "Epoch: 668 , Loss: 0.6981755\n",
      "Epoch: 669 , Loss: 0.6981634\n",
      "Epoch: 670 , Loss: 0.6981418\n",
      "Epoch: 671 , Loss: 0.6981201\n",
      "Epoch: 672 , Loss: 0.69809955\n",
      "Epoch: 673 , Loss: 0.69808507\n",
      "Epoch: 674 , Loss: 0.6980622\n",
      "Epoch: 675 , Loss: 0.6980377\n",
      "Epoch: 676 , Loss: 0.69803464\n",
      "Epoch: 677 , Loss: 0.698002\n",
      "Epoch: 678 , Loss: 0.697989\n",
      "Epoch: 679 , Loss: 0.6979656\n",
      "Epoch: 680 , Loss: 0.69794625\n",
      "Epoch: 681 , Loss: 0.6979277\n",
      "Epoch: 682 , Loss: 0.69790757\n",
      "Epoch: 683 , Loss: 0.69789344\n",
      "Epoch: 684 , Loss: 0.6978762\n",
      "Epoch: 685 , Loss: 0.6978448\n",
      "Epoch: 686 , Loss: 0.69784176\n",
      "Epoch: 687 , Loss: 0.69780666\n",
      "Epoch: 688 , Loss: 0.6978052\n",
      "Epoch: 689 , Loss: 0.69777554\n",
      "Epoch: 690 , Loss: 0.6977534\n",
      "Epoch: 691 , Loss: 0.69773823\n",
      "Epoch: 692 , Loss: 0.69776267\n",
      "Epoch: 693 , Loss: 0.6976991\n",
      "Epoch: 694 , Loss: 0.6977237\n",
      "Epoch: 695 , Loss: 0.69767\n",
      "Epoch: 696 , Loss: 0.69765395\n",
      "Epoch: 697 , Loss: 0.6976341\n",
      "Epoch: 698 , Loss: 0.69765353\n",
      "Epoch: 699 , Loss: 0.6975908\n",
      "Epoch: 700 , Loss: 0.69755894\n",
      "Epoch: 701 , Loss: 0.697566\n",
      "Epoch: 702 , Loss: 0.69753855\n",
      "Epoch: 703 , Loss: 0.6975273\n",
      "Epoch: 704 , Loss: 0.6975236\n",
      "Epoch: 705 , Loss: 0.69752175\n",
      "Epoch: 706 , Loss: 0.69747245\n",
      "Epoch: 707 , Loss: 0.6974662\n",
      "Epoch: 708 , Loss: 0.69744015\n",
      "Epoch: 709 , Loss: 0.69743073\n",
      "Epoch: 710 , Loss: 0.69741076\n",
      "Epoch: 711 , Loss: 0.6973967\n",
      "Epoch: 712 , Loss: 0.6973764\n",
      "Epoch: 713 , Loss: 0.69736636\n",
      "Epoch: 714 , Loss: 0.69735366\n",
      "Epoch: 715 , Loss: 0.6973336\n",
      "Epoch: 716 , Loss: 0.69732463\n",
      "Epoch: 717 , Loss: 0.69728094\n",
      "Epoch: 718 , Loss: 0.6972875\n",
      "Epoch: 719 , Loss: 0.6972481\n",
      "Epoch: 720 , Loss: 0.6972617\n",
      "Epoch: 721 , Loss: 0.69723463\n",
      "Epoch: 722 , Loss: 0.69719034\n",
      "Epoch: 723 , Loss: 0.6971818\n",
      "Epoch: 724 , Loss: 0.6972615\n",
      "Epoch: 725 , Loss: 0.69708544\n",
      "Epoch: 726 , Loss: 0.6971002\n",
      "Epoch: 727 , Loss: 0.69722295\n",
      "Epoch: 728 , Loss: 0.6971261\n",
      "Epoch: 729 , Loss: 0.697299\n",
      "Epoch: 730 , Loss: 0.6969535\n",
      "Epoch: 731 , Loss: 0.69706184\n",
      "Epoch: 732 , Loss: 0.69712025\n",
      "Epoch: 733 , Loss: 0.6970123\n",
      "Epoch: 734 , Loss: 0.69706994\n",
      "Epoch: 735 , Loss: 0.69710314\n",
      "Epoch: 736 , Loss: 0.69703704\n",
      "Epoch: 737 , Loss: 0.6969962\n",
      "Epoch: 738 , Loss: 0.69700545\n",
      "Epoch: 739 , Loss: 0.696969\n",
      "Epoch: 740 , Loss: 0.6969877\n",
      "Epoch: 741 , Loss: 0.6969873\n",
      "Epoch: 742 , Loss: 0.69692916\n",
      "Epoch: 743 , Loss: 0.6968962\n",
      "Epoch: 744 , Loss: 0.69690377\n",
      "Epoch: 745 , Loss: 0.6969314\n",
      "Epoch: 746 , Loss: 0.6968743\n",
      "Epoch: 747 , Loss: 0.69687015\n",
      "Epoch: 748 , Loss: 0.6968492\n",
      "Epoch: 749 , Loss: 0.69683266\n",
      "Epoch: 750 , Loss: 0.69680816\n",
      "=============================================\n",
      "18 correctly classified among 100\n",
      "Accuracy as of 750 epochs: 18.0\n",
      "=============================================\n",
      "Epoch: 751 , Loss: 0.6967921\n",
      "Epoch: 752 , Loss: 0.6967897\n",
      "Epoch: 753 , Loss: 0.6967724\n",
      "Epoch: 754 , Loss: 0.696757\n",
      "Epoch: 755 , Loss: 0.6967439\n",
      "Epoch: 756 , Loss: 0.69671774\n",
      "Epoch: 757 , Loss: 0.69669735\n",
      "Epoch: 758 , Loss: 0.6966971\n",
      "Epoch: 759 , Loss: 0.69668484\n",
      "Epoch: 760 , Loss: 0.69666165\n",
      "Epoch: 761 , Loss: 0.69664395\n",
      "Epoch: 762 , Loss: 0.69664246\n",
      "Epoch: 763 , Loss: 0.6966216\n",
      "Epoch: 764 , Loss: 0.69660145\n",
      "Epoch: 765 , Loss: 0.6965895\n",
      "Epoch: 766 , Loss: 0.69658023\n",
      "Epoch: 767 , Loss: 0.6965808\n",
      "Epoch: 768 , Loss: 0.6965401\n",
      "Epoch: 769 , Loss: 0.6965432\n",
      "Epoch: 770 , Loss: 0.6965219\n",
      "Epoch: 771 , Loss: 0.6964683\n",
      "Epoch: 772 , Loss: 0.69643486\n",
      "Epoch: 773 , Loss: 0.6968146\n",
      "Epoch: 774 , Loss: 0.69634986\n",
      "Epoch: 775 , Loss: 0.69649553\n",
      "Epoch: 776 , Loss: 0.6965202\n",
      "Epoch: 777 , Loss: 0.6964647\n",
      "Epoch: 778 , Loss: 0.69654083\n",
      "Epoch: 779 , Loss: 0.69640535\n",
      "Epoch: 780 , Loss: 0.69640744\n",
      "Epoch: 781 , Loss: 0.6963809\n",
      "Epoch: 782 , Loss: 0.6963818\n",
      "Epoch: 783 , Loss: 0.6963555\n",
      "Epoch: 784 , Loss: 0.69637066\n",
      "Epoch: 785 , Loss: 0.69641376\n",
      "Epoch: 786 , Loss: 0.6963353\n",
      "Epoch: 787 , Loss: 0.6963312\n",
      "Epoch: 788 , Loss: 0.6963097\n",
      "Epoch: 789 , Loss: 0.6963129\n",
      "Epoch: 790 , Loss: 0.6962821\n",
      "Epoch: 791 , Loss: 0.69628745\n",
      "Epoch: 792 , Loss: 0.6962495\n",
      "Epoch: 793 , Loss: 0.6963169\n",
      "Epoch: 794 , Loss: 0.6961795\n",
      "Epoch: 795 , Loss: 0.6962612\n",
      "Epoch: 796 , Loss: 0.69619524\n",
      "Epoch: 797 , Loss: 0.69629556\n",
      "Epoch: 798 , Loss: 0.69613147\n",
      "Epoch: 799 , Loss: 0.69606274\n",
      "Epoch: 800 , Loss: 0.69629335\n",
      "Epoch: 801 , Loss: 0.6960734\n",
      "Epoch: 802 , Loss: 0.69630265\n",
      "Epoch: 803 , Loss: 0.69625103\n",
      "Epoch: 804 , Loss: 0.69603974\n",
      "Epoch: 805 , Loss: 0.69609964\n",
      "Epoch: 806 , Loss: 0.69611484\n",
      "Epoch: 807 , Loss: 0.6960782\n",
      "Epoch: 808 , Loss: 0.69614357\n",
      "Epoch: 809 , Loss: 0.6960385\n",
      "Epoch: 810 , Loss: 0.6960545\n",
      "Epoch: 811 , Loss: 0.6960382\n",
      "Epoch: 812 , Loss: 0.69599795\n",
      "Epoch: 813 , Loss: 0.69599587\n",
      "Epoch: 814 , Loss: 0.69600713\n",
      "Epoch: 815 , Loss: 0.6959769\n",
      "Epoch: 816 , Loss: 0.6959766\n",
      "Epoch: 817 , Loss: 0.69599086\n",
      "Epoch: 818 , Loss: 0.69594836\n",
      "Epoch: 819 , Loss: 0.6959401\n",
      "Epoch: 820 , Loss: 0.69592655\n",
      "Epoch: 821 , Loss: 0.69591653\n",
      "Epoch: 822 , Loss: 0.6958911\n",
      "Epoch: 823 , Loss: 0.69586617\n",
      "Epoch: 824 , Loss: 0.6958437\n",
      "Epoch: 825 , Loss: 0.69567674\n",
      "Epoch: 826 , Loss: 0.6960969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 827 , Loss: 0.6960758\n",
      "Epoch: 828 , Loss: 0.69585174\n",
      "Epoch: 829 , Loss: 0.69609314\n",
      "Epoch: 830 , Loss: 0.69580203\n",
      "Epoch: 831 , Loss: 0.69579357\n",
      "Epoch: 832 , Loss: 0.69580764\n",
      "Epoch: 833 , Loss: 0.6958018\n",
      "Epoch: 834 , Loss: 0.695796\n",
      "Epoch: 835 , Loss: 0.69579136\n",
      "Epoch: 836 , Loss: 0.695784\n",
      "Epoch: 837 , Loss: 0.695775\n",
      "Epoch: 838 , Loss: 0.6957644\n",
      "Epoch: 839 , Loss: 0.6957593\n",
      "Epoch: 840 , Loss: 0.6957483\n",
      "Epoch: 841 , Loss: 0.6957348\n",
      "Epoch: 842 , Loss: 0.69572926\n",
      "Epoch: 843 , Loss: 0.6957128\n",
      "Epoch: 844 , Loss: 0.69570357\n",
      "Epoch: 845 , Loss: 0.6956909\n",
      "Epoch: 846 , Loss: 0.695676\n",
      "Epoch: 847 , Loss: 0.69566625\n",
      "Epoch: 848 , Loss: 0.6956524\n",
      "Epoch: 849 , Loss: 0.69563985\n",
      "Epoch: 850 , Loss: 0.69563127\n",
      "Epoch: 851 , Loss: 0.6956185\n",
      "Epoch: 852 , Loss: 0.69560766\n",
      "Epoch: 853 , Loss: 0.6955934\n",
      "Epoch: 854 , Loss: 0.69558394\n",
      "Epoch: 855 , Loss: 0.69557154\n",
      "Epoch: 856 , Loss: 0.6955536\n",
      "Epoch: 857 , Loss: 0.69554555\n",
      "Epoch: 858 , Loss: 0.6955381\n",
      "Epoch: 859 , Loss: 0.695527\n",
      "Epoch: 860 , Loss: 0.6955111\n",
      "Epoch: 861 , Loss: 0.69550174\n",
      "Epoch: 862 , Loss: 0.69548756\n",
      "Epoch: 863 , Loss: 0.69548017\n",
      "Epoch: 864 , Loss: 0.6954688\n",
      "Epoch: 865 , Loss: 0.6954601\n",
      "Epoch: 866 , Loss: 0.6954457\n",
      "Epoch: 867 , Loss: 0.69544333\n",
      "Epoch: 868 , Loss: 0.6954239\n",
      "Epoch: 869 , Loss: 0.6954251\n",
      "Epoch: 870 , Loss: 0.6954075\n",
      "Epoch: 871 , Loss: 0.6953911\n",
      "Epoch: 872 , Loss: 0.6953807\n",
      "Epoch: 873 , Loss: 0.69539946\n",
      "Epoch: 874 , Loss: 0.695366\n",
      "Epoch: 875 , Loss: 0.6953678\n",
      "Epoch: 876 , Loss: 0.695338\n",
      "Epoch: 877 , Loss: 0.69535094\n",
      "Epoch: 878 , Loss: 0.6953354\n",
      "Epoch: 879 , Loss: 0.69531065\n",
      "Epoch: 880 , Loss: 0.69530463\n",
      "Epoch: 881 , Loss: 0.69531614\n",
      "Epoch: 882 , Loss: 0.6952741\n",
      "Epoch: 883 , Loss: 0.69529873\n",
      "Epoch: 884 , Loss: 0.6952697\n",
      "Epoch: 885 , Loss: 0.6952457\n",
      "Epoch: 886 , Loss: 0.6952475\n",
      "Epoch: 887 , Loss: 0.6952856\n",
      "Epoch: 888 , Loss: 0.69518703\n",
      "Epoch: 889 , Loss: 0.6952162\n",
      "Epoch: 890 , Loss: 0.69523054\n",
      "Epoch: 891 , Loss: 0.695194\n",
      "Epoch: 892 , Loss: 0.6951304\n",
      "Epoch: 893 , Loss: 0.6953055\n",
      "Epoch: 894 , Loss: 0.69515246\n",
      "Epoch: 895 , Loss: 0.6953289\n",
      "Epoch: 896 , Loss: 0.6952358\n",
      "Epoch: 897 , Loss: 0.695222\n",
      "Epoch: 898 , Loss: 0.69514585\n",
      "Epoch: 899 , Loss: 0.69515324\n",
      "Epoch: 900 , Loss: 0.6951414\n",
      "Epoch: 901 , Loss: 0.6951373\n",
      "Epoch: 902 , Loss: 0.69513255\n",
      "Epoch: 903 , Loss: 0.6951183\n",
      "Epoch: 904 , Loss: 0.695112\n",
      "Epoch: 905 , Loss: 0.6951172\n",
      "Epoch: 906 , Loss: 0.6951012\n",
      "Epoch: 907 , Loss: 0.6951011\n",
      "Epoch: 908 , Loss: 0.6950935\n",
      "Epoch: 909 , Loss: 0.6950867\n",
      "Epoch: 910 , Loss: 0.6950652\n",
      "Epoch: 911 , Loss: 0.69505835\n",
      "Epoch: 912 , Loss: 0.6950465\n",
      "Epoch: 913 , Loss: 0.6950464\n",
      "Epoch: 914 , Loss: 0.6950337\n",
      "Epoch: 915 , Loss: 0.69502753\n",
      "Epoch: 916 , Loss: 0.6950119\n",
      "Epoch: 917 , Loss: 0.69499654\n",
      "Epoch: 918 , Loss: 0.6949802\n",
      "Epoch: 919 , Loss: 0.6950036\n",
      "Epoch: 920 , Loss: 0.6949541\n",
      "Epoch: 921 , Loss: 0.69496727\n",
      "Epoch: 922 , Loss: 0.6949542\n",
      "Epoch: 923 , Loss: 0.6949753\n",
      "Epoch: 924 , Loss: 0.6949126\n",
      "Epoch: 925 , Loss: 0.6949478\n",
      "Epoch: 926 , Loss: 0.6950144\n",
      "Epoch: 927 , Loss: 0.6947864\n",
      "Epoch: 928 , Loss: 0.6949241\n",
      "Epoch: 929 , Loss: 0.69494283\n",
      "Epoch: 930 , Loss: 0.69500303\n",
      "Epoch: 931 , Loss: 0.69496953\n",
      "Epoch: 932 , Loss: 0.6948738\n",
      "Epoch: 933 , Loss: 0.69487256\n",
      "Epoch: 934 , Loss: 0.6948768\n",
      "Epoch: 935 , Loss: 0.69484746\n",
      "Epoch: 936 , Loss: 0.6948078\n",
      "Epoch: 937 , Loss: 0.69486165\n",
      "Epoch: 938 , Loss: 0.6948825\n",
      "Epoch: 939 , Loss: 0.69488764\n",
      "Epoch: 940 , Loss: 0.6948112\n",
      "Epoch: 941 , Loss: 0.69478434\n",
      "Epoch: 942 , Loss: 0.69484305\n",
      "Epoch: 943 , Loss: 0.69476175\n",
      "Epoch: 944 , Loss: 0.69457954\n",
      "Epoch: 945 , Loss: 0.6952777\n",
      "Epoch: 946 , Loss: 0.69381344\n",
      "Epoch: 947 , Loss: 0.69817054\n",
      "Epoch: 948 , Loss: 0.6939806\n",
      "Epoch: 949 , Loss: 0.69559795\n",
      "Epoch: 950 , Loss: 0.6947096\n",
      "Epoch: 951 , Loss: 0.69513696\n",
      "Epoch: 952 , Loss: 0.69526446\n",
      "Epoch: 953 , Loss: 0.69589907\n",
      "Epoch: 954 , Loss: 0.6949794\n",
      "Epoch: 955 , Loss: 0.6953715\n",
      "Epoch: 956 , Loss: 0.69553083\n",
      "Epoch: 957 , Loss: 0.69538087\n",
      "Epoch: 958 , Loss: 0.69533086\n",
      "Epoch: 959 , Loss: 0.6955152\n",
      "Epoch: 960 , Loss: 0.69549525\n",
      "Epoch: 961 , Loss: 0.69556195\n",
      "Epoch: 962 , Loss: 0.695554\n",
      "Epoch: 963 , Loss: 0.69558275\n",
      "Epoch: 964 , Loss: 0.69556564\n",
      "Epoch: 965 , Loss: 0.6955903\n",
      "Epoch: 966 , Loss: 0.6955352\n",
      "Epoch: 967 , Loss: 0.69558614\n",
      "Epoch: 968 , Loss: 0.69558185\n",
      "Epoch: 969 , Loss: 0.6955313\n",
      "Epoch: 970 , Loss: 0.69547397\n",
      "Epoch: 971 , Loss: 0.69545156\n",
      "Epoch: 972 , Loss: 0.6954199\n",
      "Epoch: 973 , Loss: 0.6953825\n",
      "Epoch: 974 , Loss: 0.69535017\n",
      "Epoch: 975 , Loss: 0.6953182\n",
      "Epoch: 976 , Loss: 0.6952848\n",
      "Epoch: 977 , Loss: 0.6952548\n",
      "Epoch: 978 , Loss: 0.69522065\n",
      "Epoch: 979 , Loss: 0.6951873\n",
      "Epoch: 980 , Loss: 0.69515514\n",
      "Epoch: 981 , Loss: 0.6951344\n",
      "Epoch: 982 , Loss: 0.6950888\n",
      "Epoch: 983 , Loss: 0.6950642\n",
      "Epoch: 984 , Loss: 0.69503975\n",
      "Epoch: 985 , Loss: 0.69503397\n",
      "Epoch: 986 , Loss: 0.6949899\n",
      "Epoch: 987 , Loss: 0.6949593\n",
      "Epoch: 988 , Loss: 0.69493496\n",
      "Epoch: 989 , Loss: 0.69490373\n",
      "Epoch: 990 , Loss: 0.69485855\n",
      "Epoch: 991 , Loss: 0.69487226\n",
      "Epoch: 992 , Loss: 0.6948279\n",
      "Epoch: 993 , Loss: 0.6947917\n",
      "Epoch: 994 , Loss: 0.69483274\n",
      "Epoch: 995 , Loss: 0.69469345\n",
      "Epoch: 996 , Loss: 0.69476444\n",
      "Epoch: 997 , Loss: 0.6947191\n",
      "Epoch: 998 , Loss: 0.69489735\n",
      "Epoch: 999 , Loss: 0.6944873\n",
      "Epoch: 1000 , Loss: 0.694853\n",
      "=============================================\n",
      "3 correctly classified among 100\n",
      "Accuracy as of 1000 epochs: 3.0\n",
      "=============================================\n",
      "Epoch: 1001 , Loss: 0.6951885\n",
      "Epoch: 1002 , Loss: 0.694879\n",
      "Epoch: 1003 , Loss: 0.6944675\n",
      "Epoch: 1004 , Loss: 0.69463974\n",
      "Epoch: 1005 , Loss: 0.6948852\n",
      "Epoch: 1006 , Loss: 0.69460547\n",
      "Epoch: 1007 , Loss: 0.69473624\n",
      "Epoch: 1008 , Loss: 0.69472146\n",
      "Epoch: 1009 , Loss: 0.6946232\n",
      "Epoch: 1010 , Loss: 0.69469905\n",
      "Epoch: 1011 , Loss: 0.69460523\n",
      "Epoch: 1012 , Loss: 0.69469696\n",
      "Epoch: 1013 , Loss: 0.6946462\n",
      "Epoch: 1014 , Loss: 0.69463956\n",
      "Epoch: 1015 , Loss: 0.69462174\n",
      "Epoch: 1016 , Loss: 0.6946157\n",
      "Epoch: 1017 , Loss: 0.69459975\n",
      "Epoch: 1018 , Loss: 0.6945892\n",
      "Epoch: 1019 , Loss: 0.6945667\n",
      "Epoch: 1020 , Loss: 0.6945531\n",
      "Epoch: 1021 , Loss: 0.6945399\n",
      "Epoch: 1022 , Loss: 0.6945307\n",
      "Epoch: 1023 , Loss: 0.694501\n",
      "Epoch: 1024 , Loss: 0.6945096\n",
      "Epoch: 1025 , Loss: 0.6944745\n",
      "Epoch: 1026 , Loss: 0.69447476\n",
      "Epoch: 1027 , Loss: 0.6944598\n",
      "Epoch: 1028 , Loss: 0.6944428\n",
      "Epoch: 1029 , Loss: 0.694415\n",
      "Epoch: 1030 , Loss: 0.69439185\n",
      "Epoch: 1031 , Loss: 0.69453156\n",
      "Epoch: 1032 , Loss: 0.6944071\n",
      "Epoch: 1033 , Loss: 0.69439626\n",
      "Epoch: 1034 , Loss: 0.69437975\n",
      "Epoch: 1035 , Loss: 0.69438934\n",
      "Epoch: 1036 , Loss: 0.69436485\n",
      "Epoch: 1037 , Loss: 0.69436276\n",
      "Epoch: 1038 , Loss: 0.6943271\n",
      "Epoch: 1039 , Loss: 0.694358\n",
      "Epoch: 1040 , Loss: 0.69432116\n",
      "Epoch: 1041 , Loss: 0.69431067\n",
      "Epoch: 1042 , Loss: 0.6943101\n",
      "Epoch: 1043 , Loss: 0.6942895\n",
      "Epoch: 1044 , Loss: 0.6942995\n",
      "Epoch: 1045 , Loss: 0.6942137\n",
      "Epoch: 1046 , Loss: 0.6942826\n",
      "Epoch: 1047 , Loss: 0.6941764\n",
      "Epoch: 1048 , Loss: 0.6941801\n",
      "Epoch: 1049 , Loss: 0.6942298\n",
      "Epoch: 1050 , Loss: 0.6946603\n",
      "Epoch: 1051 , Loss: 0.69449645\n",
      "Epoch: 1052 , Loss: 0.694044\n",
      "Epoch: 1053 , Loss: 0.6944398\n",
      "Epoch: 1054 , Loss: 0.69427127\n",
      "Epoch: 1055 , Loss: 0.6942868\n",
      "Epoch: 1056 , Loss: 0.69417775\n",
      "Epoch: 1057 , Loss: 0.69424736\n",
      "Epoch: 1058 , Loss: 0.694246\n",
      "Epoch: 1059 , Loss: 0.69415617\n",
      "Epoch: 1060 , Loss: 0.6941956\n",
      "Epoch: 1061 , Loss: 0.69418263\n",
      "Epoch: 1062 , Loss: 0.69418555\n",
      "Epoch: 1063 , Loss: 0.69418865\n",
      "Epoch: 1064 , Loss: 0.69417405\n",
      "Epoch: 1065 , Loss: 0.6941662\n",
      "Epoch: 1066 , Loss: 0.69415814\n",
      "Epoch: 1067 , Loss: 0.6941361\n",
      "Epoch: 1068 , Loss: 0.694151\n",
      "Epoch: 1069 , Loss: 0.6941349\n",
      "Epoch: 1070 , Loss: 0.69412494\n",
      "Epoch: 1071 , Loss: 0.6941416\n",
      "Epoch: 1072 , Loss: 0.6941442\n",
      "Epoch: 1073 , Loss: 0.6941093\n",
      "Epoch: 1074 , Loss: 0.6941013\n",
      "Epoch: 1075 , Loss: 0.6940994\n",
      "Epoch: 1076 , Loss: 0.69413096\n",
      "Epoch: 1077 , Loss: 0.694073\n",
      "Epoch: 1078 , Loss: 0.69408494\n",
      "Epoch: 1079 , Loss: 0.6940685\n",
      "Epoch: 1080 , Loss: 0.69409746\n",
      "Epoch: 1081 , Loss: 0.69407517\n",
      "Epoch: 1082 , Loss: 0.69403607\n",
      "Epoch: 1083 , Loss: 0.6940202\n",
      "Epoch: 1084 , Loss: 0.6940542\n",
      "Epoch: 1085 , Loss: 0.6940961\n",
      "Epoch: 1086 , Loss: 0.69410163\n",
      "Epoch: 1087 , Loss: 0.6939467\n",
      "Epoch: 1088 , Loss: 0.6940808\n",
      "Epoch: 1089 , Loss: 0.6939834\n",
      "Epoch: 1090 , Loss: 0.6940354\n",
      "Epoch: 1091 , Loss: 0.6939975\n",
      "Epoch: 1092 , Loss: 0.69391227\n",
      "Epoch: 1093 , Loss: 0.69397557\n",
      "Epoch: 1094 , Loss: 0.69403756\n",
      "Epoch: 1095 , Loss: 0.6940388\n",
      "Epoch: 1096 , Loss: 0.6936712\n",
      "Epoch: 1097 , Loss: 0.6938512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1098 , Loss: 0.69414276\n",
      "Epoch: 1099 , Loss: 0.6930129\n",
      "Epoch: 1100 , Loss: 0.6924726\n",
      "Epoch: 1101 , Loss: 0.699532\n",
      "Epoch: 1102 , Loss: 0.6938537\n",
      "Epoch: 1103 , Loss: 0.69526654\n",
      "Epoch: 1104 , Loss: 0.67811996\n",
      "Epoch: 1105 , Loss: 0.71154267\n",
      "Epoch: 1106 , Loss: 0.7012596\n",
      "Epoch: 1107 , Loss: 0.6990886\n",
      "Epoch: 1108 , Loss: 0.697808\n",
      "Epoch: 1109 , Loss: 0.6981376\n",
      "Epoch: 1110 , Loss: 0.69861037\n",
      "Epoch: 1111 , Loss: 0.6992889\n",
      "Epoch: 1112 , Loss: 0.69977736\n",
      "Epoch: 1113 , Loss: 0.7002055\n",
      "Epoch: 1114 , Loss: 0.7006193\n",
      "Epoch: 1115 , Loss: 0.700918\n",
      "Epoch: 1116 , Loss: 0.7011314\n",
      "Epoch: 1117 , Loss: 0.70133334\n",
      "Epoch: 1118 , Loss: 0.70146686\n",
      "Epoch: 1119 , Loss: 0.7017259\n",
      "Epoch: 1120 , Loss: 0.7016075\n",
      "Epoch: 1121 , Loss: 0.70173293\n",
      "Epoch: 1122 , Loss: 0.7056044\n",
      "Epoch: 1123 , Loss: 0.70357406\n",
      "Epoch: 1124 , Loss: 0.70067745\n",
      "Epoch: 1125 , Loss: 0.70101887\n",
      "Epoch: 1126 , Loss: 0.70126706\n",
      "Epoch: 1127 , Loss: 0.70188594\n",
      "Epoch: 1128 , Loss: 0.7026002\n",
      "Epoch: 1129 , Loss: 0.7005026\n",
      "Epoch: 1130 , Loss: 0.7014413\n",
      "Epoch: 1131 , Loss: 0.7008191\n",
      "Epoch: 1132 , Loss: 0.7010409\n",
      "Epoch: 1133 , Loss: 0.70123816\n",
      "Epoch: 1134 , Loss: 0.70094633\n",
      "Epoch: 1135 , Loss: 0.70091176\n",
      "Epoch: 1136 , Loss: 0.70077366\n",
      "Epoch: 1137 , Loss: 0.7004827\n",
      "Epoch: 1138 , Loss: 0.70059\n",
      "Epoch: 1139 , Loss: 0.70049125\n",
      "Epoch: 1140 , Loss: 0.70038825\n",
      "Epoch: 1141 , Loss: 0.70029145\n",
      "Epoch: 1142 , Loss: 0.7001889\n",
      "Epoch: 1143 , Loss: 0.70008326\n",
      "Epoch: 1144 , Loss: 0.69997525\n",
      "Epoch: 1145 , Loss: 0.69986516\n",
      "Epoch: 1146 , Loss: 0.6997533\n",
      "Epoch: 1147 , Loss: 0.6996401\n",
      "Epoch: 1148 , Loss: 0.6995258\n",
      "Epoch: 1149 , Loss: 0.6994108\n",
      "Epoch: 1150 , Loss: 0.6992955\n",
      "Epoch: 1151 , Loss: 0.6991806\n",
      "Epoch: 1152 , Loss: 0.6990661\n",
      "Epoch: 1153 , Loss: 0.6989526\n",
      "Epoch: 1154 , Loss: 0.69884026\n",
      "Epoch: 1155 , Loss: 0.69872934\n",
      "Epoch: 1156 , Loss: 0.69862014\n",
      "Epoch: 1157 , Loss: 0.69851303\n",
      "Epoch: 1158 , Loss: 0.69840795\n",
      "Epoch: 1159 , Loss: 0.6983054\n",
      "Epoch: 1160 , Loss: 0.69820464\n",
      "Epoch: 1161 , Loss: 0.6981067\n",
      "Epoch: 1162 , Loss: 0.6980112\n",
      "Epoch: 1163 , Loss: 0.6979181\n",
      "Epoch: 1164 , Loss: 0.69782776\n",
      "Epoch: 1165 , Loss: 0.69773996\n",
      "Epoch: 1166 , Loss: 0.6976547\n",
      "Epoch: 1167 , Loss: 0.6975781\n",
      "Epoch: 1168 , Loss: 0.6974126\n",
      "Epoch: 1169 , Loss: 0.69741434\n",
      "Epoch: 1170 , Loss: 0.69725645\n",
      "Epoch: 1171 , Loss: 0.6960872\n",
      "Epoch: 1172 , Loss: 0.7017853\n",
      "Epoch: 1173 , Loss: 0.69674444\n",
      "Epoch: 1174 , Loss: 0.6971145\n",
      "Epoch: 1175 , Loss: 0.6975285\n",
      "Epoch: 1176 , Loss: 0.69714475\n",
      "Epoch: 1177 , Loss: 0.6960973\n",
      "Epoch: 1178 , Loss: 0.698747\n",
      "Epoch: 1179 , Loss: 0.697208\n",
      "Epoch: 1180 , Loss: 0.69703984\n",
      "Epoch: 1181 , Loss: 0.6970463\n",
      "Epoch: 1182 , Loss: 0.69702464\n",
      "Epoch: 1183 , Loss: 0.6970043\n",
      "Epoch: 1184 , Loss: 0.6969837\n",
      "Epoch: 1185 , Loss: 0.69696236\n",
      "Epoch: 1186 , Loss: 0.69693846\n",
      "Epoch: 1187 , Loss: 0.69691247\n",
      "Epoch: 1188 , Loss: 0.6968839\n",
      "Epoch: 1189 , Loss: 0.69685274\n",
      "Epoch: 1190 , Loss: 0.6968195\n",
      "Epoch: 1191 , Loss: 0.69678324\n",
      "Epoch: 1192 , Loss: 0.6967452\n",
      "Epoch: 1193 , Loss: 0.69670486\n",
      "Epoch: 1194 , Loss: 0.69666183\n",
      "Epoch: 1195 , Loss: 0.696625\n",
      "Epoch: 1196 , Loss: 0.6965765\n",
      "Epoch: 1197 , Loss: 0.69653314\n",
      "Epoch: 1198 , Loss: 0.69648623\n",
      "Epoch: 1199 , Loss: 0.69644046\n",
      "Epoch: 1200 , Loss: 0.6963944\n",
      "Epoch: 1201 , Loss: 0.69635177\n",
      "Epoch: 1202 , Loss: 0.69630194\n",
      "Epoch: 1203 , Loss: 0.6962573\n",
      "Epoch: 1204 , Loss: 0.6961992\n",
      "Epoch: 1205 , Loss: 0.696169\n",
      "Epoch: 1206 , Loss: 0.6961668\n",
      "Epoch: 1207 , Loss: 0.69608396\n",
      "Epoch: 1208 , Loss: 0.69604224\n",
      "Epoch: 1209 , Loss: 0.6960015\n",
      "Epoch: 1210 , Loss: 0.69596195\n",
      "Epoch: 1211 , Loss: 0.6959231\n",
      "Epoch: 1212 , Loss: 0.6958852\n",
      "Epoch: 1213 , Loss: 0.695849\n",
      "Epoch: 1214 , Loss: 0.6958123\n",
      "Epoch: 1215 , Loss: 0.69577557\n",
      "Epoch: 1216 , Loss: 0.695743\n",
      "Epoch: 1217 , Loss: 0.6957388\n",
      "Epoch: 1218 , Loss: 0.6956745\n",
      "Epoch: 1219 , Loss: 0.695644\n",
      "Epoch: 1220 , Loss: 0.69564104\n",
      "Epoch: 1221 , Loss: 0.6956069\n",
      "Epoch: 1222 , Loss: 0.69555736\n",
      "Epoch: 1223 , Loss: 0.6955291\n",
      "Epoch: 1224 , Loss: 0.69550174\n",
      "Epoch: 1225 , Loss: 0.69547534\n",
      "Epoch: 1226 , Loss: 0.69545007\n",
      "Epoch: 1227 , Loss: 0.6954247\n",
      "Epoch: 1228 , Loss: 0.6954006\n",
      "Epoch: 1229 , Loss: 0.69537514\n",
      "Epoch: 1230 , Loss: 0.69535226\n",
      "Epoch: 1231 , Loss: 0.6953311\n",
      "Epoch: 1232 , Loss: 0.69530797\n",
      "Epoch: 1233 , Loss: 0.69529474\n",
      "Epoch: 1234 , Loss: 0.6952539\n",
      "Epoch: 1235 , Loss: 0.6952379\n",
      "Epoch: 1236 , Loss: 0.6952052\n",
      "Epoch: 1237 , Loss: 0.6952005\n",
      "Epoch: 1238 , Loss: 0.6952224\n",
      "Epoch: 1239 , Loss: 0.6951734\n",
      "Epoch: 1240 , Loss: 0.6951509\n",
      "Epoch: 1241 , Loss: 0.69511944\n",
      "Epoch: 1242 , Loss: 0.69511193\n",
      "Epoch: 1243 , Loss: 0.69510114\n",
      "Epoch: 1244 , Loss: 0.6950551\n",
      "Epoch: 1245 , Loss: 0.6950689\n",
      "Epoch: 1246 , Loss: 0.6950661\n",
      "Epoch: 1247 , Loss: 0.6950738\n",
      "Epoch: 1248 , Loss: 0.6950171\n",
      "Epoch: 1249 , Loss: 0.69499296\n",
      "Epoch: 1250 , Loss: 0.69498354\n",
      "=============================================\n",
      "4 correctly classified among 100\n",
      "Accuracy as of 1250 epochs: 4.0\n",
      "=============================================\n",
      "Epoch: 1251 , Loss: 0.694978\n",
      "Epoch: 1252 , Loss: 0.6949563\n",
      "Epoch: 1253 , Loss: 0.6949479\n",
      "Epoch: 1254 , Loss: 0.69492793\n",
      "Epoch: 1255 , Loss: 0.6949179\n",
      "Epoch: 1256 , Loss: 0.694896\n",
      "Epoch: 1257 , Loss: 0.69486856\n",
      "Epoch: 1258 , Loss: 0.69491774\n",
      "Epoch: 1259 , Loss: 0.6948884\n",
      "Epoch: 1260 , Loss: 0.6949882\n",
      "Epoch: 1261 , Loss: 0.69481987\n",
      "Epoch: 1262 , Loss: 0.6948283\n",
      "Epoch: 1263 , Loss: 0.6948166\n",
      "Epoch: 1264 , Loss: 0.6948036\n",
      "Epoch: 1265 , Loss: 0.69479465\n",
      "Epoch: 1266 , Loss: 0.69478446\n",
      "Epoch: 1267 , Loss: 0.6947737\n",
      "Epoch: 1268 , Loss: 0.6947632\n",
      "Epoch: 1269 , Loss: 0.69475317\n",
      "Epoch: 1270 , Loss: 0.6947432\n",
      "Epoch: 1271 , Loss: 0.6947283\n",
      "Epoch: 1272 , Loss: 0.69472307\n",
      "Epoch: 1273 , Loss: 0.69471115\n",
      "Epoch: 1274 , Loss: 0.69469553\n",
      "Epoch: 1275 , Loss: 0.69469696\n",
      "Epoch: 1276 , Loss: 0.6946709\n",
      "Epoch: 1277 , Loss: 0.6946882\n",
      "Epoch: 1278 , Loss: 0.6946518\n",
      "Epoch: 1279 , Loss: 0.69466686\n",
      "Epoch: 1280 , Loss: 0.69464386\n",
      "Epoch: 1281 , Loss: 0.6946323\n",
      "Epoch: 1282 , Loss: 0.6946223\n",
      "Epoch: 1283 , Loss: 0.69461167\n",
      "Epoch: 1284 , Loss: 0.69459957\n",
      "Epoch: 1285 , Loss: 0.6945916\n",
      "Epoch: 1286 , Loss: 0.6945764\n",
      "Epoch: 1287 , Loss: 0.69457436\n",
      "Epoch: 1288 , Loss: 0.69454956\n",
      "Epoch: 1289 , Loss: 0.69455063\n",
      "Epoch: 1290 , Loss: 0.6945426\n",
      "Epoch: 1291 , Loss: 0.6945526\n",
      "Epoch: 1292 , Loss: 0.69452137\n",
      "Epoch: 1293 , Loss: 0.6945073\n",
      "Epoch: 1294 , Loss: 0.6945374\n",
      "Epoch: 1295 , Loss: 0.69450706\n",
      "Epoch: 1296 , Loss: 0.69452393\n",
      "Epoch: 1297 , Loss: 0.69447315\n",
      "Epoch: 1298 , Loss: 0.69448817\n",
      "Epoch: 1299 , Loss: 0.6944626\n",
      "Epoch: 1300 , Loss: 0.69448394\n",
      "Epoch: 1301 , Loss: 0.6944872\n",
      "Epoch: 1302 , Loss: 0.694452\n",
      "Epoch: 1303 , Loss: 0.6944327\n",
      "Epoch: 1304 , Loss: 0.6944924\n",
      "Epoch: 1305 , Loss: 0.6944323\n",
      "Epoch: 1306 , Loss: 0.6944107\n",
      "Epoch: 1307 , Loss: 0.6944103\n",
      "Epoch: 1308 , Loss: 0.6944335\n",
      "Epoch: 1309 , Loss: 0.6944324\n",
      "Epoch: 1310 , Loss: 0.6943328\n",
      "Epoch: 1311 , Loss: 0.6943429\n",
      "Epoch: 1312 , Loss: 0.6943981\n",
      "Epoch: 1313 , Loss: 0.69429874\n",
      "Epoch: 1314 , Loss: 0.693935\n",
      "Epoch: 1315 , Loss: 0.69421446\n",
      "Epoch: 1316 , Loss: 0.6983907\n",
      "Epoch: 1317 , Loss: 0.69447976\n",
      "Epoch: 1318 , Loss: 0.6944855\n",
      "Epoch: 1319 , Loss: 0.6946861\n",
      "Epoch: 1320 , Loss: 0.6948941\n",
      "Epoch: 1321 , Loss: 0.695178\n",
      "Epoch: 1322 , Loss: 0.69533396\n",
      "Epoch: 1323 , Loss: 0.69555914\n",
      "Epoch: 1324 , Loss: 0.6957676\n",
      "Epoch: 1325 , Loss: 0.69596195\n",
      "Epoch: 1326 , Loss: 0.6961365\n",
      "Epoch: 1327 , Loss: 0.6962894\n",
      "Epoch: 1328 , Loss: 0.69642043\n",
      "Epoch: 1329 , Loss: 0.6965293\n",
      "Epoch: 1330 , Loss: 0.69661695\n",
      "Epoch: 1331 , Loss: 0.6966859\n",
      "Epoch: 1332 , Loss: 0.69673353\n",
      "Epoch: 1333 , Loss: 0.6967657\n",
      "Epoch: 1334 , Loss: 0.69678277\n",
      "Epoch: 1335 , Loss: 0.69678646\n",
      "Epoch: 1336 , Loss: 0.6967786\n",
      "Epoch: 1337 , Loss: 0.69676065\n",
      "Epoch: 1338 , Loss: 0.6967343\n",
      "Epoch: 1339 , Loss: 0.69670093\n",
      "Epoch: 1340 , Loss: 0.69666153\n",
      "Epoch: 1341 , Loss: 0.6966175\n",
      "Epoch: 1342 , Loss: 0.69656944\n",
      "Epoch: 1343 , Loss: 0.69651854\n",
      "Epoch: 1344 , Loss: 0.6964655\n",
      "Epoch: 1345 , Loss: 0.6964109\n",
      "Epoch: 1346 , Loss: 0.6963551\n",
      "Epoch: 1347 , Loss: 0.6962987\n",
      "Epoch: 1348 , Loss: 0.69624245\n",
      "Epoch: 1349 , Loss: 0.6961861\n",
      "Epoch: 1350 , Loss: 0.6961301\n",
      "Epoch: 1351 , Loss: 0.6960716\n",
      "Epoch: 1352 , Loss: 0.6960206\n",
      "Epoch: 1353 , Loss: 0.6959671\n",
      "Epoch: 1354 , Loss: 0.6959146\n",
      "Epoch: 1355 , Loss: 0.6958633\n",
      "Epoch: 1356 , Loss: 0.69581324\n",
      "Epoch: 1357 , Loss: 0.6957643\n",
      "Epoch: 1358 , Loss: 0.6957168\n",
      "Epoch: 1359 , Loss: 0.6956705\n",
      "Epoch: 1360 , Loss: 0.6956255\n",
      "Epoch: 1361 , Loss: 0.6955816\n",
      "Epoch: 1362 , Loss: 0.69553936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1363 , Loss: 0.69549817\n",
      "Epoch: 1364 , Loss: 0.69545823\n",
      "Epoch: 1365 , Loss: 0.6954195\n",
      "Epoch: 1366 , Loss: 0.695382\n",
      "Epoch: 1367 , Loss: 0.6953456\n",
      "Epoch: 1368 , Loss: 0.69531035\n",
      "Epoch: 1369 , Loss: 0.6952762\n",
      "Epoch: 1370 , Loss: 0.69524306\n",
      "Epoch: 1371 , Loss: 0.695211\n",
      "Epoch: 1372 , Loss: 0.6951799\n",
      "Epoch: 1373 , Loss: 0.6951496\n",
      "Epoch: 1374 , Loss: 0.6951204\n",
      "Epoch: 1375 , Loss: 0.6950921\n",
      "Epoch: 1376 , Loss: 0.6950644\n",
      "Epoch: 1377 , Loss: 0.69503766\n",
      "Epoch: 1378 , Loss: 0.6950121\n",
      "Epoch: 1379 , Loss: 0.6949866\n",
      "Epoch: 1380 , Loss: 0.69496197\n",
      "Epoch: 1381 , Loss: 0.6949381\n",
      "Epoch: 1382 , Loss: 0.69491595\n",
      "Epoch: 1383 , Loss: 0.69489247\n",
      "Epoch: 1384 , Loss: 0.69487154\n",
      "Epoch: 1385 , Loss: 0.69485813\n",
      "Epoch: 1386 , Loss: 0.694819\n",
      "Epoch: 1387 , Loss: 0.69478136\n",
      "Epoch: 1388 , Loss: 0.6948163\n",
      "Epoch: 1389 , Loss: 0.69478375\n",
      "Epoch: 1390 , Loss: 0.6947519\n",
      "Epoch: 1391 , Loss: 0.6947342\n",
      "Epoch: 1392 , Loss: 0.6947165\n",
      "Epoch: 1393 , Loss: 0.6946995\n",
      "Epoch: 1394 , Loss: 0.6946845\n",
      "Epoch: 1395 , Loss: 0.6946677\n",
      "Epoch: 1396 , Loss: 0.6946611\n",
      "Epoch: 1397 , Loss: 0.6946362\n",
      "Epoch: 1398 , Loss: 0.6946218\n",
      "Epoch: 1399 , Loss: 0.69460744\n",
      "Epoch: 1400 , Loss: 0.69459337\n",
      "Epoch: 1401 , Loss: 0.6945801\n",
      "Epoch: 1402 , Loss: 0.6945663\n",
      "Epoch: 1403 , Loss: 0.6945532\n",
      "Epoch: 1404 , Loss: 0.69453996\n",
      "Epoch: 1405 , Loss: 0.69452834\n",
      "Epoch: 1406 , Loss: 0.69451445\n",
      "Epoch: 1407 , Loss: 0.69450253\n",
      "Epoch: 1408 , Loss: 0.6944932\n",
      "Epoch: 1409 , Loss: 0.69447976\n",
      "Epoch: 1410 , Loss: 0.69446594\n",
      "Epoch: 1411 , Loss: 0.69445467\n",
      "Epoch: 1412 , Loss: 0.69444275\n",
      "Epoch: 1413 , Loss: 0.69443095\n",
      "Epoch: 1414 , Loss: 0.694433\n",
      "Epoch: 1415 , Loss: 0.6944103\n",
      "Epoch: 1416 , Loss: 0.6943979\n",
      "Epoch: 1417 , Loss: 0.6943882\n",
      "Epoch: 1418 , Loss: 0.69437844\n",
      "Epoch: 1419 , Loss: 0.6943689\n",
      "Epoch: 1420 , Loss: 0.6943545\n",
      "Epoch: 1421 , Loss: 0.6943403\n",
      "Epoch: 1422 , Loss: 0.69433457\n",
      "Epoch: 1423 , Loss: 0.6943295\n",
      "Epoch: 1424 , Loss: 0.6943304\n",
      "Epoch: 1425 , Loss: 0.6943069\n",
      "Epoch: 1426 , Loss: 0.694317\n",
      "Epoch: 1427 , Loss: 0.69431543\n",
      "Epoch: 1428 , Loss: 0.6942799\n",
      "Epoch: 1429 , Loss: 0.69428897\n",
      "Epoch: 1430 , Loss: 0.69426656\n",
      "Epoch: 1431 , Loss: 0.6942556\n",
      "Epoch: 1432 , Loss: 0.6942529\n",
      "Epoch: 1433 , Loss: 0.694239\n",
      "Epoch: 1434 , Loss: 0.6942273\n",
      "Epoch: 1435 , Loss: 0.69422835\n",
      "Epoch: 1436 , Loss: 0.6941799\n",
      "Epoch: 1437 , Loss: 0.69422626\n",
      "Epoch: 1438 , Loss: 0.69420344\n",
      "Epoch: 1439 , Loss: 0.6941714\n",
      "Epoch: 1440 , Loss: 0.694302\n",
      "Epoch: 1441 , Loss: 0.69417876\n",
      "Epoch: 1442 , Loss: 0.69418985\n",
      "Epoch: 1443 , Loss: 0.6941739\n",
      "Epoch: 1444 , Loss: 0.69415414\n",
      "Epoch: 1445 , Loss: 0.6942006\n",
      "Epoch: 1446 , Loss: 0.69416326\n",
      "Epoch: 1447 , Loss: 0.6941196\n",
      "Epoch: 1448 , Loss: 0.6942526\n",
      "Epoch: 1449 , Loss: 0.6941468\n",
      "Epoch: 1450 , Loss: 0.69413525\n",
      "Epoch: 1451 , Loss: 0.69412667\n",
      "Epoch: 1452 , Loss: 0.69413143\n",
      "Epoch: 1453 , Loss: 0.69410604\n",
      "Epoch: 1454 , Loss: 0.6941247\n",
      "Epoch: 1455 , Loss: 0.6940584\n",
      "Epoch: 1456 , Loss: 0.69407064\n",
      "Epoch: 1457 , Loss: 0.69406945\n",
      "Epoch: 1458 , Loss: 0.6938515\n",
      "Epoch: 1459 , Loss: 0.6940637\n",
      "Epoch: 1460 , Loss: 0.6935284\n",
      "Epoch: 1461 , Loss: 0.694093\n",
      "Epoch: 1462 , Loss: 0.69374156\n",
      "Epoch: 1463 , Loss: 0.694272\n",
      "Epoch: 1464 , Loss: 0.6938064\n",
      "Epoch: 1465 , Loss: 0.6949237\n",
      "Epoch: 1466 , Loss: 0.69413584\n",
      "Epoch: 1467 , Loss: 0.69425124\n",
      "Epoch: 1468 , Loss: 0.69409883\n",
      "Epoch: 1469 , Loss: 0.6941154\n",
      "Epoch: 1470 , Loss: 0.6941143\n",
      "Epoch: 1471 , Loss: 0.69410735\n",
      "Epoch: 1472 , Loss: 0.6941416\n",
      "Epoch: 1473 , Loss: 0.6941091\n",
      "Epoch: 1474 , Loss: 0.6941544\n",
      "Epoch: 1475 , Loss: 0.6940751\n",
      "Epoch: 1476 , Loss: 0.69404876\n",
      "Epoch: 1477 , Loss: 0.6940526\n",
      "Epoch: 1478 , Loss: 0.6941268\n",
      "Epoch: 1479 , Loss: 0.6941155\n",
      "Epoch: 1480 , Loss: 0.6941038\n",
      "Epoch: 1481 , Loss: 0.69409674\n",
      "Epoch: 1482 , Loss: 0.69411594\n",
      "Epoch: 1483 , Loss: 0.6940652\n",
      "Epoch: 1484 , Loss: 0.6940768\n",
      "Epoch: 1485 , Loss: 0.694063\n",
      "Epoch: 1486 , Loss: 0.6940487\n",
      "Epoch: 1487 , Loss: 0.69407105\n",
      "Epoch: 1488 , Loss: 0.6940161\n",
      "Epoch: 1489 , Loss: 0.6939668\n",
      "Epoch: 1490 , Loss: 0.6940578\n",
      "Epoch: 1491 , Loss: 0.6943888\n",
      "Epoch: 1492 , Loss: 0.69401836\n",
      "Epoch: 1493 , Loss: 0.6939733\n",
      "Epoch: 1494 , Loss: 0.6939646\n",
      "Epoch: 1495 , Loss: 0.6939882\n",
      "Epoch: 1496 , Loss: 0.69398963\n",
      "Epoch: 1497 , Loss: 0.6939549\n",
      "Epoch: 1498 , Loss: 0.693973\n",
      "Epoch: 1499 , Loss: 0.69396955\n",
      "Epoch: 1500 , Loss: 0.6939667\n",
      "=============================================\n",
      "10 correctly classified among 100\n",
      "Accuracy as of 1500 epochs: 10.0\n",
      "=============================================\n",
      "Epoch: 1501 , Loss: 0.69392174\n",
      "Epoch: 1502 , Loss: 0.6939595\n",
      "Epoch: 1503 , Loss: 0.69398385\n",
      "Epoch: 1504 , Loss: 0.6939298\n",
      "Epoch: 1505 , Loss: 0.69392073\n",
      "Epoch: 1506 , Loss: 0.693936\n",
      "Epoch: 1507 , Loss: 0.6939071\n",
      "Epoch: 1508 , Loss: 0.6938983\n",
      "Epoch: 1509 , Loss: 0.6939219\n",
      "Epoch: 1510 , Loss: 0.69389695\n",
      "Epoch: 1511 , Loss: 0.69388634\n",
      "Epoch: 1512 , Loss: 0.69387025\n",
      "Epoch: 1513 , Loss: 0.6938877\n",
      "Epoch: 1514 , Loss: 0.6938752\n",
      "Epoch: 1515 , Loss: 0.69389886\n",
      "Epoch: 1516 , Loss: 0.69385076\n",
      "Epoch: 1517 , Loss: 0.6938577\n",
      "Epoch: 1518 , Loss: 0.6938554\n",
      "Epoch: 1519 , Loss: 0.69386566\n",
      "Epoch: 1520 , Loss: 0.69384235\n",
      "Epoch: 1521 , Loss: 0.6938464\n",
      "Epoch: 1522 , Loss: 0.6938582\n",
      "Epoch: 1523 , Loss: 0.6938462\n",
      "Epoch: 1524 , Loss: 0.69382507\n",
      "Epoch: 1525 , Loss: 0.6938303\n",
      "Epoch: 1526 , Loss: 0.6938514\n",
      "Epoch: 1527 , Loss: 0.69382703\n",
      "Epoch: 1528 , Loss: 0.69381803\n",
      "Epoch: 1529 , Loss: 0.69381183\n",
      "Epoch: 1530 , Loss: 0.6938051\n",
      "Epoch: 1531 , Loss: 0.69382226\n",
      "Epoch: 1532 , Loss: 0.6938402\n",
      "Epoch: 1533 , Loss: 0.6938099\n",
      "Epoch: 1534 , Loss: 0.6937947\n",
      "Epoch: 1535 , Loss: 0.6937953\n",
      "Epoch: 1536 , Loss: 0.69378173\n",
      "Epoch: 1537 , Loss: 0.6937997\n",
      "Epoch: 1538 , Loss: 0.6937583\n",
      "Epoch: 1539 , Loss: 0.69377494\n",
      "Epoch: 1540 , Loss: 0.6938379\n",
      "Epoch: 1541 , Loss: 0.6936967\n",
      "Epoch: 1542 , Loss: 0.69375575\n",
      "Epoch: 1543 , Loss: 0.69399774\n",
      "Epoch: 1544 , Loss: 0.6937052\n",
      "Epoch: 1545 , Loss: 0.6937653\n",
      "Epoch: 1546 , Loss: 0.6937228\n",
      "Epoch: 1547 , Loss: 0.69379884\n",
      "Epoch: 1548 , Loss: 0.6937582\n",
      "Epoch: 1549 , Loss: 0.693756\n",
      "Epoch: 1550 , Loss: 0.6937244\n",
      "Epoch: 1551 , Loss: 0.69374424\n",
      "Epoch: 1552 , Loss: 0.6937456\n",
      "Epoch: 1553 , Loss: 0.69374967\n",
      "Epoch: 1554 , Loss: 0.69376373\n",
      "Epoch: 1555 , Loss: 0.69374365\n",
      "Epoch: 1556 , Loss: 0.69377047\n",
      "Epoch: 1557 , Loss: 0.6936937\n",
      "Epoch: 1558 , Loss: 0.69375587\n",
      "Epoch: 1559 , Loss: 0.69372624\n",
      "Epoch: 1560 , Loss: 0.6937449\n",
      "Epoch: 1561 , Loss: 0.69371533\n",
      "Epoch: 1562 , Loss: 0.6937259\n",
      "Epoch: 1563 , Loss: 0.69373226\n",
      "Epoch: 1564 , Loss: 0.6937083\n",
      "Epoch: 1565 , Loss: 0.6937142\n",
      "Epoch: 1566 , Loss: 0.69370705\n",
      "Epoch: 1567 , Loss: 0.6937004\n",
      "Epoch: 1568 , Loss: 0.6936984\n",
      "Epoch: 1569 , Loss: 0.6936911\n",
      "Epoch: 1570 , Loss: 0.6937018\n",
      "Epoch: 1571 , Loss: 0.6936901\n",
      "Epoch: 1572 , Loss: 0.6937047\n",
      "Epoch: 1573 , Loss: 0.6936692\n",
      "Epoch: 1574 , Loss: 0.69363517\n",
      "Epoch: 1575 , Loss: 0.69364434\n",
      "Epoch: 1576 , Loss: 0.69368154\n",
      "Epoch: 1577 , Loss: 0.6937738\n",
      "Epoch: 1578 , Loss: 0.6938248\n",
      "Epoch: 1579 , Loss: 0.6938391\n",
      "Epoch: 1580 , Loss: 0.693741\n",
      "Epoch: 1581 , Loss: 0.69363165\n",
      "Epoch: 1582 , Loss: 0.693656\n",
      "Epoch: 1583 , Loss: 0.6936906\n",
      "Epoch: 1584 , Loss: 0.69369006\n",
      "Epoch: 1585 , Loss: 0.6936941\n",
      "Epoch: 1586 , Loss: 0.69370055\n",
      "Epoch: 1587 , Loss: 0.6936722\n",
      "Epoch: 1588 , Loss: 0.6936778\n",
      "Epoch: 1589 , Loss: 0.6936781\n",
      "Epoch: 1590 , Loss: 0.6936749\n",
      "Epoch: 1591 , Loss: 0.69367397\n",
      "Epoch: 1592 , Loss: 0.693675\n",
      "Epoch: 1593 , Loss: 0.69367313\n",
      "Epoch: 1594 , Loss: 0.6936717\n",
      "Epoch: 1595 , Loss: 0.6936696\n",
      "Epoch: 1596 , Loss: 0.69366765\n",
      "Epoch: 1597 , Loss: 0.6936651\n",
      "Epoch: 1598 , Loss: 0.6936631\n",
      "Epoch: 1599 , Loss: 0.69365996\n",
      "Epoch: 1600 , Loss: 0.69365746\n",
      "Epoch: 1601 , Loss: 0.6936536\n",
      "Epoch: 1602 , Loss: 0.69365174\n",
      "Epoch: 1603 , Loss: 0.6936492\n",
      "Epoch: 1604 , Loss: 0.69364583\n",
      "Epoch: 1605 , Loss: 0.6936438\n",
      "Epoch: 1606 , Loss: 0.6936404\n",
      "Epoch: 1607 , Loss: 0.69363743\n",
      "Epoch: 1608 , Loss: 0.69363487\n",
      "Epoch: 1609 , Loss: 0.6936314\n",
      "Epoch: 1610 , Loss: 0.6936293\n",
      "Epoch: 1611 , Loss: 0.69362557\n",
      "Epoch: 1612 , Loss: 0.6936224\n",
      "Epoch: 1613 , Loss: 0.69362015\n",
      "Epoch: 1614 , Loss: 0.6936172\n",
      "Epoch: 1615 , Loss: 0.6936147\n",
      "Epoch: 1616 , Loss: 0.6936142\n",
      "Epoch: 1617 , Loss: 0.6936103\n",
      "Epoch: 1618 , Loss: 0.6936064\n",
      "Epoch: 1619 , Loss: 0.69360405\n",
      "Epoch: 1620 , Loss: 0.69360226\n",
      "Epoch: 1621 , Loss: 0.6936008\n",
      "Epoch: 1622 , Loss: 0.693599\n",
      "Epoch: 1623 , Loss: 0.6935995\n",
      "Epoch: 1624 , Loss: 0.69359195\n",
      "Epoch: 1625 , Loss: 0.69359356\n",
      "Epoch: 1626 , Loss: 0.6935893\n",
      "Epoch: 1627 , Loss: 0.6935871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1628 , Loss: 0.6935853\n",
      "Epoch: 1629 , Loss: 0.6935856\n",
      "Epoch: 1630 , Loss: 0.6935821\n",
      "Epoch: 1631 , Loss: 0.6935824\n",
      "Epoch: 1632 , Loss: 0.6935764\n",
      "Epoch: 1633 , Loss: 0.6935787\n",
      "Epoch: 1634 , Loss: 0.6935737\n",
      "Epoch: 1635 , Loss: 0.693574\n",
      "Epoch: 1636 , Loss: 0.6935708\n",
      "Epoch: 1637 , Loss: 0.69356763\n",
      "Epoch: 1638 , Loss: 0.69356763\n",
      "Epoch: 1639 , Loss: 0.6935623\n",
      "Epoch: 1640 , Loss: 0.6935653\n",
      "Epoch: 1641 , Loss: 0.6935683\n",
      "Epoch: 1642 , Loss: 0.69354916\n",
      "Epoch: 1643 , Loss: 0.6935574\n",
      "Epoch: 1644 , Loss: 0.69358724\n",
      "Epoch: 1645 , Loss: 0.69360846\n",
      "Epoch: 1646 , Loss: 0.6935458\n",
      "Epoch: 1647 , Loss: 0.69355375\n",
      "Epoch: 1648 , Loss: 0.6935527\n",
      "Epoch: 1649 , Loss: 0.69354916\n",
      "Epoch: 1650 , Loss: 0.6935466\n",
      "Epoch: 1651 , Loss: 0.6935441\n",
      "Epoch: 1652 , Loss: 0.69354385\n",
      "Epoch: 1653 , Loss: 0.69354326\n",
      "Epoch: 1654 , Loss: 0.69354045\n",
      "Epoch: 1655 , Loss: 0.69353884\n",
      "Epoch: 1656 , Loss: 0.6935407\n",
      "Epoch: 1657 , Loss: 0.6935364\n",
      "Epoch: 1658 , Loss: 0.6935333\n",
      "Epoch: 1659 , Loss: 0.6935254\n",
      "Epoch: 1660 , Loss: 0.6935322\n",
      "Epoch: 1661 , Loss: 0.69350076\n",
      "Epoch: 1662 , Loss: 0.6935491\n",
      "Epoch: 1663 , Loss: 0.69350994\n",
      "Epoch: 1664 , Loss: 0.6935872\n",
      "Epoch: 1665 , Loss: 0.6935265\n",
      "Epoch: 1666 , Loss: 0.6934821\n",
      "Epoch: 1667 , Loss: 0.69362825\n",
      "Epoch: 1668 , Loss: 0.6935809\n",
      "Epoch: 1669 , Loss: 0.6935248\n",
      "Epoch: 1670 , Loss: 0.69350713\n",
      "Epoch: 1671 , Loss: 0.69351614\n",
      "Epoch: 1672 , Loss: 0.69351315\n",
      "Epoch: 1673 , Loss: 0.6935183\n",
      "Epoch: 1674 , Loss: 0.6935227\n",
      "Epoch: 1675 , Loss: 0.6935245\n",
      "Epoch: 1676 , Loss: 0.6935167\n",
      "Epoch: 1677 , Loss: 0.6935121\n",
      "Epoch: 1678 , Loss: 0.69350654\n",
      "Epoch: 1679 , Loss: 0.6935134\n",
      "Epoch: 1680 , Loss: 0.69349736\n",
      "Epoch: 1681 , Loss: 0.69350773\n",
      "Epoch: 1682 , Loss: 0.6935454\n",
      "Epoch: 1683 , Loss: 0.6934759\n",
      "Epoch: 1684 , Loss: 0.69348425\n",
      "Epoch: 1685 , Loss: 0.6934056\n",
      "Epoch: 1686 , Loss: 0.693503\n",
      "Epoch: 1687 , Loss: 0.6934386\n",
      "Epoch: 1688 , Loss: 0.6934085\n",
      "Epoch: 1689 , Loss: 0.6932215\n",
      "Epoch: 1690 , Loss: 0.693832\n",
      "Epoch: 1691 , Loss: 0.69385695\n",
      "Epoch: 1692 , Loss: 0.6932961\n",
      "Epoch: 1693 , Loss: 0.69276375\n",
      "Epoch: 1694 , Loss: 0.6938175\n",
      "Epoch: 1695 , Loss: 0.6942472\n",
      "Epoch: 1696 , Loss: 0.6928989\n",
      "Epoch: 1697 , Loss: 0.69287217\n",
      "Epoch: 1698 , Loss: 0.691317\n",
      "Epoch: 1699 , Loss: 0.70231986\n",
      "Epoch: 1700 , Loss: 0.6934207\n",
      "Epoch: 1701 , Loss: 0.69366676\n",
      "Epoch: 1702 , Loss: 0.6942494\n",
      "Epoch: 1703 , Loss: 0.69536155\n",
      "Epoch: 1704 , Loss: 0.6940636\n",
      "Epoch: 1705 , Loss: 0.6945244\n",
      "Epoch: 1706 , Loss: 0.69424635\n",
      "Epoch: 1707 , Loss: 0.69611067\n",
      "Epoch: 1708 , Loss: 0.6950443\n",
      "Epoch: 1709 , Loss: 0.6949043\n",
      "Epoch: 1710 , Loss: 0.69659984\n",
      "Epoch: 1711 , Loss: 0.6958041\n",
      "Epoch: 1712 , Loss: 0.6958206\n",
      "Epoch: 1713 , Loss: 0.695729\n",
      "Epoch: 1714 , Loss: 0.69562197\n",
      "Epoch: 1715 , Loss: 0.69577533\n",
      "Epoch: 1716 , Loss: 0.6958872\n",
      "Epoch: 1717 , Loss: 0.6959123\n",
      "Epoch: 1718 , Loss: 0.6959131\n",
      "Epoch: 1719 , Loss: 0.69590217\n",
      "Epoch: 1720 , Loss: 0.69587713\n",
      "Epoch: 1721 , Loss: 0.69585645\n",
      "Epoch: 1722 , Loss: 0.6958662\n",
      "Epoch: 1723 , Loss: 0.69577295\n",
      "Epoch: 1724 , Loss: 0.6957199\n",
      "Epoch: 1725 , Loss: 0.69566196\n",
      "Epoch: 1726 , Loss: 0.6956096\n",
      "Epoch: 1727 , Loss: 0.6955311\n",
      "Epoch: 1728 , Loss: 0.69542617\n",
      "Epoch: 1729 , Loss: 0.695493\n",
      "Epoch: 1730 , Loss: 0.6953334\n",
      "Epoch: 1731 , Loss: 0.69526684\n",
      "Epoch: 1732 , Loss: 0.6952011\n",
      "Epoch: 1733 , Loss: 0.6951372\n",
      "Epoch: 1734 , Loss: 0.69507366\n",
      "Epoch: 1735 , Loss: 0.69501525\n",
      "Epoch: 1736 , Loss: 0.69495225\n",
      "Epoch: 1737 , Loss: 0.6948874\n",
      "Epoch: 1738 , Loss: 0.69486266\n",
      "Epoch: 1739 , Loss: 0.6947908\n",
      "Epoch: 1740 , Loss: 0.6947398\n",
      "Epoch: 1741 , Loss: 0.6946965\n",
      "Epoch: 1742 , Loss: 0.6946438\n",
      "Epoch: 1743 , Loss: 0.6945964\n",
      "Epoch: 1744 , Loss: 0.6945558\n",
      "Epoch: 1745 , Loss: 0.69453895\n",
      "Epoch: 1746 , Loss: 0.6944802\n",
      "Epoch: 1747 , Loss: 0.6944402\n",
      "Epoch: 1748 , Loss: 0.69440025\n",
      "Epoch: 1749 , Loss: 0.6943622\n",
      "Epoch: 1750 , Loss: 0.6943218\n",
      "=============================================\n",
      "24 correctly classified among 100\n",
      "Accuracy as of 1750 epochs: 24.0\n",
      "=============================================\n",
      "Epoch: 1751 , Loss: 0.69433564\n",
      "Epoch: 1752 , Loss: 0.6942636\n",
      "Epoch: 1753 , Loss: 0.6942544\n",
      "Epoch: 1754 , Loss: 0.6942725\n",
      "Epoch: 1755 , Loss: 0.6941994\n",
      "Epoch: 1756 , Loss: 0.69415087\n",
      "Epoch: 1757 , Loss: 0.69409996\n",
      "Epoch: 1758 , Loss: 0.6940871\n",
      "Epoch: 1759 , Loss: 0.6942221\n",
      "Epoch: 1760 , Loss: 0.69402266\n",
      "Epoch: 1761 , Loss: 0.6937087\n",
      "Epoch: 1762 , Loss: 0.6940856\n",
      "Epoch: 1763 , Loss: 0.69339657\n",
      "Epoch: 1764 , Loss: 0.6954947\n",
      "Epoch: 1765 , Loss: 0.6940562\n",
      "Epoch: 1766 , Loss: 0.69066\n",
      "Epoch: 1767 , Loss: 0.6938731\n",
      "Epoch: 1768 , Loss: 0.69364226\n",
      "Epoch: 1769 , Loss: 0.6950104\n",
      "Epoch: 1770 , Loss: 0.69581085\n",
      "Epoch: 1771 , Loss: 0.6959498\n",
      "Epoch: 1772 , Loss: 0.6963848\n",
      "Epoch: 1773 , Loss: 0.6965623\n",
      "Epoch: 1774 , Loss: 0.6969066\n",
      "Epoch: 1775 , Loss: 0.6971815\n",
      "Epoch: 1776 , Loss: 0.697479\n",
      "Epoch: 1777 , Loss: 0.697502\n",
      "Epoch: 1778 , Loss: 0.6977068\n",
      "Epoch: 1779 , Loss: 0.69817483\n",
      "Epoch: 1780 , Loss: 0.6984686\n",
      "Epoch: 1781 , Loss: 0.69851285\n",
      "Epoch: 1782 , Loss: 0.6984216\n",
      "Epoch: 1783 , Loss: 0.6970346\n",
      "Epoch: 1784 , Loss: 0.69850653\n",
      "Epoch: 1785 , Loss: 0.6983988\n",
      "Epoch: 1786 , Loss: 0.6988003\n",
      "Epoch: 1787 , Loss: 0.69886494\n",
      "Epoch: 1788 , Loss: 0.6989124\n",
      "Epoch: 1789 , Loss: 0.6989422\n",
      "Epoch: 1790 , Loss: 0.69895405\n",
      "Epoch: 1791 , Loss: 0.6989484\n",
      "Epoch: 1792 , Loss: 0.69892627\n",
      "Epoch: 1793 , Loss: 0.69888324\n",
      "Epoch: 1794 , Loss: 0.69883704\n",
      "Epoch: 1795 , Loss: 0.69877267\n",
      "Epoch: 1796 , Loss: 0.69869727\n",
      "Epoch: 1797 , Loss: 0.69860893\n",
      "Epoch: 1798 , Loss: 0.69851923\n",
      "Epoch: 1799 , Loss: 0.6984193\n",
      "Epoch: 1800 , Loss: 0.6983137\n",
      "Epoch: 1801 , Loss: 0.6982039\n",
      "Epoch: 1802 , Loss: 0.6980906\n",
      "Epoch: 1803 , Loss: 0.6979751\n",
      "Epoch: 1804 , Loss: 0.69785815\n",
      "Epoch: 1805 , Loss: 0.69774026\n",
      "Epoch: 1806 , Loss: 0.6976225\n",
      "Epoch: 1807 , Loss: 0.6975052\n",
      "Epoch: 1808 , Loss: 0.6973888\n",
      "Epoch: 1809 , Loss: 0.6972741\n",
      "Epoch: 1810 , Loss: 0.69716114\n",
      "Epoch: 1811 , Loss: 0.6970502\n",
      "Epoch: 1812 , Loss: 0.69694173\n",
      "Epoch: 1813 , Loss: 0.69683564\n",
      "Epoch: 1814 , Loss: 0.6967324\n",
      "Epoch: 1815 , Loss: 0.6966317\n",
      "Epoch: 1816 , Loss: 0.6965341\n",
      "Epoch: 1817 , Loss: 0.69636595\n",
      "Epoch: 1818 , Loss: 0.6959052\n",
      "Epoch: 1819 , Loss: 0.6962624\n",
      "Epoch: 1820 , Loss: 0.6961784\n",
      "Epoch: 1821 , Loss: 0.69610256\n",
      "Epoch: 1822 , Loss: 0.6960185\n",
      "Epoch: 1823 , Loss: 0.69594276\n",
      "Epoch: 1824 , Loss: 0.69586945\n",
      "Epoch: 1825 , Loss: 0.6957981\n",
      "Epoch: 1826 , Loss: 0.69572943\n",
      "Epoch: 1827 , Loss: 0.6956644\n",
      "Epoch: 1828 , Loss: 0.695599\n",
      "Epoch: 1829 , Loss: 0.6955369\n",
      "Epoch: 1830 , Loss: 0.69548976\n",
      "Epoch: 1831 , Loss: 0.69523245\n",
      "Epoch: 1832 , Loss: 0.69532186\n",
      "Epoch: 1833 , Loss: 0.69530654\n",
      "Epoch: 1834 , Loss: 0.6952567\n",
      "Epoch: 1835 , Loss: 0.6952108\n",
      "Epoch: 1836 , Loss: 0.6951599\n",
      "Epoch: 1837 , Loss: 0.6951236\n",
      "Epoch: 1838 , Loss: 0.695067\n",
      "Epoch: 1839 , Loss: 0.69532055\n",
      "Epoch: 1840 , Loss: 0.69498724\n",
      "Epoch: 1841 , Loss: 0.6949489\n",
      "Epoch: 1842 , Loss: 0.69491345\n",
      "Epoch: 1843 , Loss: 0.6948798\n",
      "Epoch: 1844 , Loss: 0.69484454\n",
      "Epoch: 1845 , Loss: 0.69481206\n",
      "Epoch: 1846 , Loss: 0.6947806\n",
      "Epoch: 1847 , Loss: 0.6947499\n",
      "Epoch: 1848 , Loss: 0.6947197\n",
      "Epoch: 1849 , Loss: 0.69468945\n",
      "Epoch: 1850 , Loss: 0.6946607\n",
      "Epoch: 1851 , Loss: 0.6946331\n",
      "Epoch: 1852 , Loss: 0.69460595\n",
      "Epoch: 1853 , Loss: 0.6945769\n",
      "Epoch: 1854 , Loss: 0.69455004\n",
      "Epoch: 1855 , Loss: 0.69452465\n",
      "Epoch: 1856 , Loss: 0.6944999\n",
      "Epoch: 1857 , Loss: 0.6944736\n",
      "Epoch: 1858 , Loss: 0.6944494\n",
      "Epoch: 1859 , Loss: 0.694426\n",
      "Epoch: 1860 , Loss: 0.69440216\n",
      "Epoch: 1861 , Loss: 0.6943786\n",
      "Epoch: 1862 , Loss: 0.6943455\n",
      "Epoch: 1863 , Loss: 0.69432527\n",
      "Epoch: 1864 , Loss: 0.6941772\n",
      "Epoch: 1865 , Loss: 0.6944114\n",
      "Epoch: 1866 , Loss: 0.694305\n",
      "Epoch: 1867 , Loss: 0.69426596\n",
      "Epoch: 1868 , Loss: 0.694223\n",
      "Epoch: 1869 , Loss: 0.69411147\n",
      "Epoch: 1870 , Loss: 0.69414556\n",
      "Epoch: 1871 , Loss: 0.69427437\n",
      "Epoch: 1872 , Loss: 0.69421434\n",
      "Epoch: 1873 , Loss: 0.69418275\n",
      "Epoch: 1874 , Loss: 0.6941341\n",
      "Epoch: 1875 , Loss: 0.69412327\n",
      "Epoch: 1876 , Loss: 0.69410783\n",
      "Epoch: 1877 , Loss: 0.6940962\n",
      "Epoch: 1878 , Loss: 0.6940422\n",
      "Epoch: 1879 , Loss: 0.69408554\n",
      "Epoch: 1880 , Loss: 0.69402057\n",
      "Epoch: 1881 , Loss: 0.6939737\n",
      "Epoch: 1882 , Loss: 0.6940639\n",
      "Epoch: 1883 , Loss: 0.69430405\n",
      "Epoch: 1884 , Loss: 0.69406503\n",
      "Epoch: 1885 , Loss: 0.69412315\n",
      "Epoch: 1886 , Loss: 0.6939683\n",
      "Epoch: 1887 , Loss: 0.6942474\n",
      "Epoch: 1888 , Loss: 0.69394284\n",
      "Epoch: 1889 , Loss: 0.69396675\n",
      "Epoch: 1890 , Loss: 0.69395643\n",
      "Epoch: 1891 , Loss: 0.69394666\n",
      "Epoch: 1892 , Loss: 0.69393754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1893 , Loss: 0.69393176\n",
      "Epoch: 1894 , Loss: 0.6939392\n",
      "Epoch: 1895 , Loss: 0.6939092\n",
      "Epoch: 1896 , Loss: 0.69384104\n",
      "Epoch: 1897 , Loss: 0.6938891\n",
      "Epoch: 1898 , Loss: 0.69389886\n",
      "Epoch: 1899 , Loss: 0.6938995\n",
      "Epoch: 1900 , Loss: 0.69392383\n",
      "Epoch: 1901 , Loss: 0.69388175\n",
      "Epoch: 1902 , Loss: 0.6938843\n",
      "Epoch: 1903 , Loss: 0.6938489\n",
      "Epoch: 1904 , Loss: 0.6938498\n",
      "Epoch: 1905 , Loss: 0.6938372\n",
      "Epoch: 1906 , Loss: 0.6938214\n",
      "Epoch: 1907 , Loss: 0.6938252\n",
      "Epoch: 1908 , Loss: 0.69381636\n",
      "Epoch: 1909 , Loss: 0.6937924\n",
      "Epoch: 1910 , Loss: 0.6937933\n",
      "Epoch: 1911 , Loss: 0.69377583\n",
      "Epoch: 1912 , Loss: 0.69378096\n",
      "Epoch: 1913 , Loss: 0.693787\n",
      "Epoch: 1914 , Loss: 0.69373316\n",
      "Epoch: 1915 , Loss: 0.6937487\n",
      "Epoch: 1916 , Loss: 0.6937082\n",
      "Epoch: 1917 , Loss: 0.6936669\n",
      "Epoch: 1918 , Loss: 0.6938505\n",
      "Epoch: 1919 , Loss: 0.69374335\n",
      "Epoch: 1920 , Loss: 0.6940335\n",
      "Epoch: 1921 , Loss: 0.69363725\n",
      "Epoch: 1922 , Loss: 0.6937631\n",
      "Epoch: 1923 , Loss: 0.69365895\n",
      "Epoch: 1924 , Loss: 0.6936672\n",
      "Epoch: 1925 , Loss: 0.6936787\n",
      "Epoch: 1926 , Loss: 0.69359845\n",
      "Epoch: 1927 , Loss: 0.6935598\n",
      "Epoch: 1928 , Loss: 0.69365317\n",
      "Epoch: 1929 , Loss: 0.69354707\n",
      "Epoch: 1930 , Loss: 0.6940173\n",
      "Epoch: 1931 , Loss: 0.6937452\n",
      "Epoch: 1932 , Loss: 0.6936507\n",
      "Epoch: 1933 , Loss: 0.6936419\n",
      "Epoch: 1934 , Loss: 0.6937426\n",
      "Epoch: 1935 , Loss: 0.69367725\n",
      "Epoch: 1936 , Loss: 0.6934528\n",
      "Epoch: 1937 , Loss: 0.69374937\n",
      "Epoch: 1938 , Loss: 0.6938448\n",
      "Epoch: 1939 , Loss: 0.69363075\n",
      "Epoch: 1940 , Loss: 0.69356763\n",
      "Epoch: 1941 , Loss: 0.69377863\n",
      "Epoch: 1942 , Loss: 0.69392943\n",
      "Epoch: 1943 , Loss: 0.6933324\n",
      "Epoch: 1944 , Loss: 0.69426775\n",
      "Epoch: 1945 , Loss: 0.69384485\n",
      "Epoch: 1946 , Loss: 0.69371235\n",
      "Epoch: 1947 , Loss: 0.69379914\n",
      "Epoch: 1948 , Loss: 0.6936383\n",
      "Epoch: 1949 , Loss: 0.69353193\n",
      "Epoch: 1950 , Loss: 0.69380635\n",
      "Epoch: 1951 , Loss: 0.6936582\n",
      "Epoch: 1952 , Loss: 0.69371235\n",
      "Epoch: 1953 , Loss: 0.69365263\n",
      "Epoch: 1954 , Loss: 0.6936311\n",
      "Epoch: 1955 , Loss: 0.6936149\n",
      "Epoch: 1956 , Loss: 0.6934797\n",
      "Epoch: 1957 , Loss: 0.6932545\n",
      "Epoch: 1958 , Loss: 0.69314516\n",
      "Epoch: 1959 , Loss: 0.6938892\n",
      "Epoch: 1960 , Loss: 0.69369596\n",
      "Epoch: 1961 , Loss: 0.6935924\n",
      "Epoch: 1962 , Loss: 0.6936508\n",
      "Epoch: 1963 , Loss: 0.693491\n",
      "Epoch: 1964 , Loss: 0.69383115\n",
      "Epoch: 1965 , Loss: 0.6936504\n",
      "Epoch: 1966 , Loss: 0.6936584\n",
      "Epoch: 1967 , Loss: 0.69371367\n",
      "Epoch: 1968 , Loss: 0.6936665\n",
      "Epoch: 1969 , Loss: 0.69366264\n",
      "Epoch: 1970 , Loss: 0.69365215\n",
      "Epoch: 1971 , Loss: 0.6936599\n",
      "Epoch: 1972 , Loss: 0.69365996\n",
      "Epoch: 1973 , Loss: 0.6936356\n",
      "Epoch: 1974 , Loss: 0.69362235\n",
      "Epoch: 1975 , Loss: 0.69362944\n",
      "Epoch: 1976 , Loss: 0.69361955\n",
      "Epoch: 1977 , Loss: 0.6936022\n",
      "Epoch: 1978 , Loss: 0.693594\n",
      "Epoch: 1979 , Loss: 0.69356495\n",
      "Epoch: 1980 , Loss: 0.69344205\n",
      "Epoch: 1981 , Loss: 0.6935846\n",
      "Epoch: 1982 , Loss: 0.69289416\n",
      "Epoch: 1983 , Loss: 0.6945243\n",
      "Epoch: 1984 , Loss: 0.6935602\n",
      "Epoch: 1985 , Loss: 0.6936884\n",
      "Epoch: 1986 , Loss: 0.6934694\n",
      "Epoch: 1987 , Loss: 0.6942568\n",
      "Epoch: 1988 , Loss: 0.69345486\n",
      "Epoch: 1989 , Loss: 0.6936096\n",
      "Epoch: 1990 , Loss: 0.69357765\n",
      "Epoch: 1991 , Loss: 0.6935762\n",
      "Epoch: 1992 , Loss: 0.6937084\n",
      "Epoch: 1993 , Loss: 0.69368184\n",
      "Epoch: 1994 , Loss: 0.69362634\n",
      "Epoch: 1995 , Loss: 0.6936348\n",
      "Epoch: 1996 , Loss: 0.6936624\n",
      "Epoch: 1997 , Loss: 0.6937445\n",
      "Epoch: 1998 , Loss: 0.6936312\n",
      "Epoch: 1999 , Loss: 0.693677\n",
      "Epoch: 2000 , Loss: 0.69367373\n",
      "=============================================\n",
      "4 correctly classified among 100\n",
      "Accuracy as of 2000 epochs: 4.0\n",
      "=============================================\n",
      "Epoch: 2001 , Loss: 0.69359183\n",
      "Epoch: 2002 , Loss: 0.69369346\n",
      "Epoch: 2003 , Loss: 0.6937204\n",
      "Epoch: 2004 , Loss: 0.6936294\n",
      "Epoch: 2005 , Loss: 0.6936661\n",
      "Epoch: 2006 , Loss: 0.69363207\n",
      "Epoch: 2007 , Loss: 0.69361347\n",
      "Epoch: 2008 , Loss: 0.6936159\n",
      "Epoch: 2009 , Loss: 0.6936\n",
      "Epoch: 2010 , Loss: 0.69359446\n",
      "Epoch: 2011 , Loss: 0.6935727\n",
      "Epoch: 2012 , Loss: 0.6935606\n",
      "Epoch: 2013 , Loss: 0.69354975\n",
      "Epoch: 2014 , Loss: 0.6935668\n",
      "Epoch: 2015 , Loss: 0.693525\n",
      "Epoch: 2016 , Loss: 0.69351125\n",
      "Epoch: 2017 , Loss: 0.6935088\n",
      "Epoch: 2018 , Loss: 0.6935274\n",
      "Epoch: 2019 , Loss: 0.69350374\n",
      "Epoch: 2020 , Loss: 0.6934856\n",
      "Epoch: 2021 , Loss: 0.6935967\n",
      "Epoch: 2022 , Loss: 0.6935292\n",
      "Epoch: 2023 , Loss: 0.6934965\n",
      "Epoch: 2024 , Loss: 0.6934092\n",
      "Epoch: 2025 , Loss: 0.69348836\n",
      "Epoch: 2026 , Loss: 0.69350994\n",
      "Epoch: 2027 , Loss: 0.693409\n",
      "Epoch: 2028 , Loss: 0.6935031\n",
      "Epoch: 2029 , Loss: 0.69348323\n",
      "Epoch: 2030 , Loss: 0.69341034\n",
      "Epoch: 2031 , Loss: 0.6934498\n",
      "Epoch: 2032 , Loss: 0.69345564\n",
      "Epoch: 2033 , Loss: 0.69343275\n",
      "Epoch: 2034 , Loss: 0.69344604\n",
      "Epoch: 2035 , Loss: 0.6934355\n",
      "Epoch: 2036 , Loss: 0.69344527\n",
      "Epoch: 2037 , Loss: 0.6934293\n",
      "Epoch: 2038 , Loss: 0.6934158\n",
      "Epoch: 2039 , Loss: 0.6934123\n",
      "Epoch: 2040 , Loss: 0.6934171\n",
      "Epoch: 2041 , Loss: 0.693399\n",
      "Epoch: 2042 , Loss: 0.69342136\n",
      "Epoch: 2043 , Loss: 0.69339377\n",
      "Epoch: 2044 , Loss: 0.6933847\n",
      "Epoch: 2045 , Loss: 0.6934061\n",
      "Epoch: 2046 , Loss: 0.6933853\n",
      "Epoch: 2047 , Loss: 0.6934075\n",
      "Epoch: 2048 , Loss: 0.6933539\n",
      "Epoch: 2049 , Loss: 0.6934189\n",
      "Epoch: 2050 , Loss: 0.69345033\n",
      "Epoch: 2051 , Loss: 0.6934864\n",
      "Epoch: 2052 , Loss: 0.6934398\n",
      "Epoch: 2053 , Loss: 0.69332623\n",
      "Epoch: 2054 , Loss: 0.69348097\n",
      "Epoch: 2055 , Loss: 0.69340086\n",
      "Epoch: 2056 , Loss: 0.6933696\n",
      "Epoch: 2057 , Loss: 0.69338197\n",
      "Epoch: 2058 , Loss: 0.6933689\n",
      "Epoch: 2059 , Loss: 0.6933668\n",
      "Epoch: 2060 , Loss: 0.6933773\n",
      "Epoch: 2061 , Loss: 0.693369\n",
      "Epoch: 2062 , Loss: 0.69337654\n",
      "Epoch: 2063 , Loss: 0.6933693\n",
      "Epoch: 2064 , Loss: 0.69337445\n",
      "Epoch: 2065 , Loss: 0.6933736\n",
      "Epoch: 2066 , Loss: 0.69336087\n",
      "Epoch: 2067 , Loss: 0.6933704\n",
      "Epoch: 2068 , Loss: 0.6933562\n",
      "Epoch: 2069 , Loss: 0.69336617\n",
      "Epoch: 2070 , Loss: 0.6933822\n",
      "Epoch: 2071 , Loss: 0.693316\n",
      "Epoch: 2072 , Loss: 0.6933481\n",
      "Epoch: 2073 , Loss: 0.6933609\n",
      "Epoch: 2074 , Loss: 0.6933877\n",
      "Epoch: 2075 , Loss: 0.69338244\n",
      "Epoch: 2076 , Loss: 0.69329005\n",
      "Epoch: 2077 , Loss: 0.6932643\n",
      "Epoch: 2078 , Loss: 0.69349897\n",
      "Epoch: 2079 , Loss: 0.6934996\n",
      "Epoch: 2080 , Loss: 0.69340855\n",
      "Epoch: 2081 , Loss: 0.693406\n",
      "Epoch: 2082 , Loss: 0.6933532\n",
      "Epoch: 2083 , Loss: 0.69335157\n",
      "Epoch: 2084 , Loss: 0.6933582\n",
      "Epoch: 2085 , Loss: 0.69333977\n",
      "Epoch: 2086 , Loss: 0.69334394\n",
      "Epoch: 2087 , Loss: 0.69334525\n",
      "Epoch: 2088 , Loss: 0.6933394\n",
      "Epoch: 2089 , Loss: 0.6933416\n",
      "Epoch: 2090 , Loss: 0.6933618\n",
      "Epoch: 2091 , Loss: 0.6933449\n",
      "Epoch: 2092 , Loss: 0.69335496\n",
      "Epoch: 2093 , Loss: 0.693352\n",
      "Epoch: 2094 , Loss: 0.69336414\n",
      "Epoch: 2095 , Loss: 0.693362\n",
      "Epoch: 2096 , Loss: 0.69338036\n",
      "Epoch: 2097 , Loss: 0.6933314\n",
      "Epoch: 2098 , Loss: 0.6933418\n",
      "Epoch: 2099 , Loss: 0.6933395\n",
      "Epoch: 2100 , Loss: 0.69331926\n",
      "Epoch: 2101 , Loss: 0.6933437\n",
      "Epoch: 2102 , Loss: 0.69332844\n",
      "Epoch: 2103 , Loss: 0.693322\n",
      "Epoch: 2104 , Loss: 0.6933257\n",
      "Epoch: 2105 , Loss: 0.6933296\n",
      "Epoch: 2106 , Loss: 0.69335586\n",
      "Epoch: 2107 , Loss: 0.6933543\n",
      "Epoch: 2108 , Loss: 0.693325\n",
      "Epoch: 2109 , Loss: 0.6933027\n",
      "Epoch: 2110 , Loss: 0.693319\n",
      "Epoch: 2111 , Loss: 0.6933318\n",
      "Epoch: 2112 , Loss: 0.69331783\n",
      "Epoch: 2113 , Loss: 0.6932683\n",
      "Epoch: 2114 , Loss: 0.6932807\n",
      "Epoch: 2115 , Loss: 0.6932951\n",
      "Epoch: 2116 , Loss: 0.6930801\n",
      "Epoch: 2117 , Loss: 0.6938428\n",
      "Epoch: 2118 , Loss: 0.6933338\n",
      "Epoch: 2119 , Loss: 0.6933487\n",
      "Epoch: 2120 , Loss: 0.6934067\n",
      "Epoch: 2121 , Loss: 0.69342905\n",
      "Epoch: 2122 , Loss: 0.69345397\n",
      "Epoch: 2123 , Loss: 0.6935468\n",
      "Epoch: 2124 , Loss: 0.69329786\n",
      "Epoch: 2125 , Loss: 0.6929888\n",
      "Epoch: 2126 , Loss: 0.6922039\n",
      "Epoch: 2127 , Loss: 0.6976663\n",
      "Epoch: 2128 , Loss: 0.6938015\n",
      "Epoch: 2129 , Loss: 0.69413376\n",
      "Epoch: 2130 , Loss: 0.694827\n",
      "Epoch: 2131 , Loss: 0.69516605\n",
      "Epoch: 2132 , Loss: 0.6952802\n",
      "Epoch: 2133 , Loss: 0.69598234\n",
      "Epoch: 2134 , Loss: 0.6967602\n",
      "Epoch: 2135 , Loss: 0.69480807\n",
      "Epoch: 2136 , Loss: 0.69896144\n",
      "Epoch: 2137 , Loss: 0.69833726\n",
      "Epoch: 2138 , Loss: 0.6974404\n",
      "Epoch: 2139 , Loss: 0.69924057\n",
      "Epoch: 2140 , Loss: 0.69917375\n",
      "Epoch: 2141 , Loss: 0.6991445\n",
      "Epoch: 2142 , Loss: 0.69976586\n",
      "Epoch: 2143 , Loss: 0.70120376\n",
      "Epoch: 2144 , Loss: 0.70043284\n",
      "Epoch: 2145 , Loss: 0.70106673\n",
      "Epoch: 2146 , Loss: 0.7006344\n",
      "Epoch: 2147 , Loss: 0.70174295\n",
      "Epoch: 2148 , Loss: 0.69935596\n",
      "Epoch: 2149 , Loss: 0.7018445\n",
      "Epoch: 2150 , Loss: 0.7001044\n",
      "Epoch: 2151 , Loss: 0.69949937\n",
      "Epoch: 2152 , Loss: 0.69998336\n",
      "Epoch: 2153 , Loss: 0.7017769\n",
      "Epoch: 2154 , Loss: 0.70182437\n",
      "Epoch: 2155 , Loss: 0.7024366\n",
      "Epoch: 2156 , Loss: 0.70156884\n",
      "Epoch: 2157 , Loss: 0.7016446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2158 , Loss: 0.7011524\n",
      "Epoch: 2159 , Loss: 0.70167357\n",
      "Epoch: 2160 , Loss: 0.7014935\n",
      "Epoch: 2161 , Loss: 0.7007452\n",
      "Epoch: 2162 , Loss: 0.70136595\n",
      "Epoch: 2163 , Loss: 0.7012375\n",
      "Epoch: 2164 , Loss: 0.7011003\n",
      "Epoch: 2165 , Loss: 0.7009555\n",
      "Epoch: 2166 , Loss: 0.70080537\n",
      "Epoch: 2167 , Loss: 0.70065063\n",
      "Epoch: 2168 , Loss: 0.7004929\n",
      "Epoch: 2169 , Loss: 0.7003333\n",
      "Epoch: 2170 , Loss: 0.70017284\n",
      "Epoch: 2171 , Loss: 0.7000124\n",
      "Epoch: 2172 , Loss: 0.6998527\n",
      "Epoch: 2173 , Loss: 0.69969445\n",
      "Epoch: 2174 , Loss: 0.69953763\n",
      "Epoch: 2175 , Loss: 0.69969106\n",
      "Epoch: 2176 , Loss: 0.69923395\n",
      "Epoch: 2177 , Loss: 0.69908804\n",
      "Epoch: 2178 , Loss: 0.6989466\n",
      "Epoch: 2179 , Loss: 0.69880915\n",
      "Epoch: 2180 , Loss: 0.69867593\n",
      "Epoch: 2181 , Loss: 0.6985467\n",
      "Epoch: 2182 , Loss: 0.6984213\n",
      "Epoch: 2183 , Loss: 0.69829977\n",
      "Epoch: 2184 , Loss: 0.6981809\n",
      "Epoch: 2185 , Loss: 0.698068\n",
      "Epoch: 2186 , Loss: 0.6979576\n",
      "Epoch: 2187 , Loss: 0.69785064\n",
      "Epoch: 2188 , Loss: 0.6977471\n",
      "Epoch: 2189 , Loss: 0.69764715\n",
      "Epoch: 2190 , Loss: 0.697549\n",
      "Epoch: 2191 , Loss: 0.69745225\n",
      "Epoch: 2192 , Loss: 0.69736373\n",
      "Epoch: 2193 , Loss: 0.6973068\n",
      "Epoch: 2194 , Loss: 0.6971929\n",
      "Epoch: 2195 , Loss: 0.697111\n",
      "Epoch: 2196 , Loss: 0.69703436\n",
      "Epoch: 2197 , Loss: 0.6969556\n",
      "Epoch: 2198 , Loss: 0.6968554\n",
      "Epoch: 2199 , Loss: 0.69681096\n",
      "Epoch: 2200 , Loss: 0.6967414\n",
      "Epoch: 2201 , Loss: 0.69667506\n",
      "Epoch: 2202 , Loss: 0.696611\n",
      "Epoch: 2203 , Loss: 0.69654936\n",
      "Epoch: 2204 , Loss: 0.6964897\n",
      "Epoch: 2205 , Loss: 0.6964321\n",
      "Epoch: 2206 , Loss: 0.69637626\n",
      "Epoch: 2207 , Loss: 0.69632244\n",
      "Epoch: 2208 , Loss: 0.6962702\n",
      "Epoch: 2209 , Loss: 0.6962201\n",
      "Epoch: 2210 , Loss: 0.6961705\n",
      "Epoch: 2211 , Loss: 0.696123\n",
      "Epoch: 2212 , Loss: 0.69607645\n",
      "Epoch: 2213 , Loss: 0.69603556\n",
      "Epoch: 2214 , Loss: 0.6959861\n",
      "Epoch: 2215 , Loss: 0.6959467\n",
      "Epoch: 2216 , Loss: 0.69590575\n",
      "Epoch: 2217 , Loss: 0.69586456\n",
      "Epoch: 2218 , Loss: 0.69585323\n",
      "Epoch: 2219 , Loss: 0.6957921\n",
      "Epoch: 2220 , Loss: 0.69575554\n",
      "Epoch: 2221 , Loss: 0.69572043\n",
      "Epoch: 2222 , Loss: 0.69568586\n",
      "Epoch: 2223 , Loss: 0.69565356\n",
      "Epoch: 2224 , Loss: 0.6956216\n",
      "Epoch: 2225 , Loss: 0.69558996\n",
      "Epoch: 2226 , Loss: 0.69555974\n",
      "Epoch: 2227 , Loss: 0.69553024\n",
      "Epoch: 2228 , Loss: 0.69550186\n",
      "Epoch: 2229 , Loss: 0.69547486\n",
      "Epoch: 2230 , Loss: 0.6954468\n",
      "Epoch: 2231 , Loss: 0.69541866\n",
      "Epoch: 2232 , Loss: 0.69539994\n",
      "Epoch: 2233 , Loss: 0.6953723\n",
      "Epoch: 2234 , Loss: 0.6953447\n",
      "Epoch: 2235 , Loss: 0.69532186\n",
      "Epoch: 2236 , Loss: 0.6952987\n",
      "Epoch: 2237 , Loss: 0.69527394\n",
      "Epoch: 2238 , Loss: 0.6952548\n",
      "Epoch: 2239 , Loss: 0.6952337\n",
      "Epoch: 2240 , Loss: 0.6952141\n",
      "Epoch: 2241 , Loss: 0.6951867\n",
      "Epoch: 2242 , Loss: 0.6951733\n",
      "Epoch: 2243 , Loss: 0.69515014\n",
      "Epoch: 2244 , Loss: 0.6951292\n",
      "Epoch: 2245 , Loss: 0.695123\n",
      "Epoch: 2246 , Loss: 0.69509614\n",
      "Epoch: 2247 , Loss: 0.6950753\n",
      "Epoch: 2248 , Loss: 0.69507736\n",
      "Epoch: 2249 , Loss: 0.69506073\n",
      "Epoch: 2250 , Loss: 0.69502753\n",
      "=============================================\n",
      "11 correctly classified among 100\n",
      "Accuracy as of 2250 epochs: 11.0\n",
      "=============================================\n",
      "Epoch: 2251 , Loss: 0.69501424\n",
      "Epoch: 2252 , Loss: 0.69499594\n",
      "Epoch: 2253 , Loss: 0.69498146\n",
      "Epoch: 2254 , Loss: 0.6949664\n",
      "Epoch: 2255 , Loss: 0.6949521\n",
      "Epoch: 2256 , Loss: 0.69493806\n",
      "Epoch: 2257 , Loss: 0.69492394\n",
      "Epoch: 2258 , Loss: 0.69490963\n",
      "Epoch: 2259 , Loss: 0.69489646\n",
      "Epoch: 2260 , Loss: 0.6948827\n",
      "Epoch: 2261 , Loss: 0.6948714\n",
      "Epoch: 2262 , Loss: 0.6948567\n",
      "Epoch: 2263 , Loss: 0.69484526\n",
      "Epoch: 2264 , Loss: 0.69483215\n",
      "Epoch: 2265 , Loss: 0.694819\n",
      "Epoch: 2266 , Loss: 0.6948068\n",
      "Epoch: 2267 , Loss: 0.69479585\n",
      "Epoch: 2268 , Loss: 0.69478685\n",
      "Epoch: 2269 , Loss: 0.69477695\n",
      "Epoch: 2270 , Loss: 0.6947681\n",
      "Epoch: 2271 , Loss: 0.69474787\n",
      "Epoch: 2272 , Loss: 0.6947427\n",
      "Epoch: 2273 , Loss: 0.69472724\n",
      "Epoch: 2274 , Loss: 0.69472367\n",
      "Epoch: 2275 , Loss: 0.6947113\n",
      "Epoch: 2276 , Loss: 0.69470066\n",
      "Epoch: 2277 , Loss: 0.6946856\n",
      "Epoch: 2278 , Loss: 0.69468325\n",
      "Epoch: 2279 , Loss: 0.6946731\n",
      "Epoch: 2280 , Loss: 0.6946723\n",
      "Epoch: 2281 , Loss: 0.6946428\n",
      "Epoch: 2282 , Loss: 0.6946477\n",
      "Epoch: 2283 , Loss: 0.69463676\n",
      "Epoch: 2284 , Loss: 0.694635\n",
      "Epoch: 2285 , Loss: 0.6946223\n",
      "Epoch: 2286 , Loss: 0.694603\n",
      "Epoch: 2287 , Loss: 0.69459873\n",
      "Epoch: 2288 , Loss: 0.6945794\n",
      "Epoch: 2289 , Loss: 0.69457245\n",
      "Epoch: 2290 , Loss: 0.6945897\n",
      "Epoch: 2291 , Loss: 0.6946124\n",
      "Epoch: 2292 , Loss: 0.6946044\n",
      "Epoch: 2293 , Loss: 0.69455415\n",
      "Epoch: 2294 , Loss: 0.694526\n",
      "Epoch: 2295 , Loss: 0.69453895\n",
      "Epoch: 2296 , Loss: 0.69452393\n",
      "Epoch: 2297 , Loss: 0.6945736\n",
      "Epoch: 2298 , Loss: 0.69449764\n",
      "Epoch: 2299 , Loss: 0.69452643\n",
      "Epoch: 2300 , Loss: 0.6944657\n",
      "Epoch: 2301 , Loss: 0.69445384\n",
      "Epoch: 2302 , Loss: 0.6944893\n",
      "Epoch: 2303 , Loss: 0.69455767\n",
      "Epoch: 2304 , Loss: 0.69448566\n",
      "Epoch: 2305 , Loss: 0.69446653\n",
      "Epoch: 2306 , Loss: 0.69447833\n",
      "Epoch: 2307 , Loss: 0.69446313\n",
      "Epoch: 2308 , Loss: 0.6944732\n",
      "Epoch: 2309 , Loss: 0.69443405\n",
      "Epoch: 2310 , Loss: 0.6944316\n",
      "Epoch: 2311 , Loss: 0.69434404\n",
      "Epoch: 2312 , Loss: 0.6944882\n",
      "Epoch: 2313 , Loss: 0.6944774\n",
      "Epoch: 2314 , Loss: 0.6944327\n",
      "Epoch: 2315 , Loss: 0.69442403\n",
      "Epoch: 2316 , Loss: 0.6944161\n",
      "Epoch: 2317 , Loss: 0.69444245\n",
      "Epoch: 2318 , Loss: 0.6944477\n",
      "Epoch: 2319 , Loss: 0.6943888\n",
      "Epoch: 2320 , Loss: 0.69440037\n",
      "Epoch: 2321 , Loss: 0.69439137\n",
      "Epoch: 2322 , Loss: 0.69439703\n",
      "Epoch: 2323 , Loss: 0.6943845\n",
      "Epoch: 2324 , Loss: 0.6943779\n",
      "Epoch: 2325 , Loss: 0.6943787\n",
      "Epoch: 2326 , Loss: 0.6943688\n",
      "Epoch: 2327 , Loss: 0.69438344\n",
      "Epoch: 2328 , Loss: 0.6943355\n",
      "Epoch: 2329 , Loss: 0.6943728\n",
      "Epoch: 2330 , Loss: 0.69434935\n",
      "Epoch: 2331 , Loss: 0.69433874\n",
      "Epoch: 2332 , Loss: 0.69434196\n",
      "Epoch: 2333 , Loss: 0.6943244\n",
      "Epoch: 2334 , Loss: 0.694321\n",
      "Epoch: 2335 , Loss: 0.69432133\n",
      "Epoch: 2336 , Loss: 0.6943277\n",
      "Epoch: 2337 , Loss: 0.6942982\n",
      "Epoch: 2338 , Loss: 0.6942703\n",
      "Epoch: 2339 , Loss: 0.6942949\n",
      "Epoch: 2340 , Loss: 0.6942791\n",
      "Epoch: 2341 , Loss: 0.6942589\n",
      "Epoch: 2342 , Loss: 0.6945935\n",
      "Epoch: 2343 , Loss: 0.69426024\n",
      "Epoch: 2344 , Loss: 0.6942399\n",
      "Epoch: 2345 , Loss: 0.69426763\n",
      "Epoch: 2346 , Loss: 0.6942764\n",
      "Epoch: 2347 , Loss: 0.69425803\n",
      "Epoch: 2348 , Loss: 0.69429827\n",
      "Epoch: 2349 , Loss: 0.6942782\n",
      "Epoch: 2350 , Loss: 0.69413674\n",
      "Epoch: 2351 , Loss: 0.6944648\n",
      "Epoch: 2352 , Loss: 0.69435155\n",
      "Epoch: 2353 , Loss: 0.69389266\n",
      "Epoch: 2354 , Loss: 0.6943402\n",
      "Epoch: 2355 , Loss: 0.6938861\n",
      "Epoch: 2356 , Loss: 0.6936348\n",
      "Epoch: 2357 , Loss: 0.6957145\n",
      "Epoch: 2358 , Loss: 0.6948033\n",
      "Epoch: 2359 , Loss: 0.69424915\n",
      "Epoch: 2360 , Loss: 0.69431573\n",
      "Epoch: 2361 , Loss: 0.69276273\n",
      "Epoch: 2362 , Loss: 0.69418746\n",
      "Epoch: 2363 , Loss: 0.6957236\n",
      "Epoch: 2364 , Loss: 0.69490725\n",
      "Epoch: 2365 , Loss: 0.69528866\n",
      "Epoch: 2366 , Loss: 0.69550234\n",
      "Epoch: 2367 , Loss: 0.69604474\n",
      "Epoch: 2368 , Loss: 0.69639534\n",
      "Epoch: 2369 , Loss: 0.696244\n",
      "Epoch: 2370 , Loss: 0.6950345\n",
      "Epoch: 2371 , Loss: 0.70050025\n",
      "Epoch: 2372 , Loss: 0.6976104\n",
      "Epoch: 2373 , Loss: 0.6983914\n",
      "Epoch: 2374 , Loss: 0.7002334\n",
      "Epoch: 2375 , Loss: 0.6967399\n",
      "Epoch: 2376 , Loss: 0.6986715\n",
      "Epoch: 2377 , Loss: 0.6988219\n",
      "Epoch: 2378 , Loss: 0.6989778\n",
      "Epoch: 2379 , Loss: 0.69875807\n",
      "Epoch: 2380 , Loss: 0.69918114\n",
      "Epoch: 2381 , Loss: 0.6992527\n",
      "Epoch: 2382 , Loss: 0.6992534\n",
      "Epoch: 2383 , Loss: 0.6995619\n",
      "Epoch: 2384 , Loss: 0.6993232\n",
      "Epoch: 2385 , Loss: 0.69923115\n",
      "Epoch: 2386 , Loss: 0.69923055\n",
      "Epoch: 2387 , Loss: 0.70299125\n",
      "Epoch: 2388 , Loss: 0.69713205\n",
      "Epoch: 2389 , Loss: 0.6990395\n",
      "Epoch: 2390 , Loss: 0.6972811\n",
      "Epoch: 2391 , Loss: 0.697822\n",
      "Epoch: 2392 , Loss: 0.69634306\n",
      "Epoch: 2393 , Loss: 0.7004427\n",
      "Epoch: 2394 , Loss: 0.7007285\n",
      "Epoch: 2395 , Loss: 0.69826394\n",
      "Epoch: 2396 , Loss: 0.6975958\n",
      "Epoch: 2397 , Loss: 0.6971045\n",
      "Epoch: 2398 , Loss: 0.6992539\n",
      "Epoch: 2399 , Loss: 0.6961418\n",
      "Epoch: 2400 , Loss: 0.6998374\n",
      "Epoch: 2401 , Loss: 0.7002098\n",
      "Epoch: 2402 , Loss: 0.7014172\n",
      "Epoch: 2403 , Loss: 0.7003106\n",
      "Epoch: 2404 , Loss: 0.7011764\n",
      "Epoch: 2405 , Loss: 0.6997649\n",
      "Epoch: 2406 , Loss: 0.6995174\n",
      "Epoch: 2407 , Loss: 0.6999734\n",
      "Epoch: 2408 , Loss: 0.69926524\n",
      "Epoch: 2409 , Loss: 0.70000505\n",
      "Epoch: 2410 , Loss: 0.6997096\n",
      "Epoch: 2411 , Loss: 0.6998323\n",
      "Epoch: 2412 , Loss: 0.6996884\n",
      "Epoch: 2413 , Loss: 0.69965625\n",
      "Epoch: 2414 , Loss: 0.699608\n",
      "Epoch: 2415 , Loss: 0.6996015\n",
      "Epoch: 2416 , Loss: 0.6996085\n",
      "Epoch: 2417 , Loss: 0.699531\n",
      "Epoch: 2418 , Loss: 0.6995002\n",
      "Epoch: 2419 , Loss: 0.7001996\n",
      "Epoch: 2420 , Loss: 0.69942063\n",
      "Epoch: 2421 , Loss: 0.6993778\n",
      "Epoch: 2422 , Loss: 0.6993345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2423 , Loss: 0.6992907\n",
      "Epoch: 2424 , Loss: 0.69924676\n",
      "Epoch: 2425 , Loss: 0.6992027\n",
      "Epoch: 2426 , Loss: 0.6991586\n",
      "Epoch: 2427 , Loss: 0.6991146\n",
      "Epoch: 2428 , Loss: 0.69907093\n",
      "Epoch: 2429 , Loss: 0.6990273\n",
      "Epoch: 2430 , Loss: 0.69898415\n",
      "Epoch: 2431 , Loss: 0.69894135\n",
      "Epoch: 2432 , Loss: 0.69889903\n",
      "Epoch: 2433 , Loss: 0.6988571\n",
      "Epoch: 2434 , Loss: 0.6988158\n",
      "Epoch: 2435 , Loss: 0.698775\n",
      "Epoch: 2436 , Loss: 0.6987348\n",
      "Epoch: 2437 , Loss: 0.69869506\n",
      "Epoch: 2438 , Loss: 0.698656\n",
      "Epoch: 2439 , Loss: 0.6986177\n",
      "Epoch: 2440 , Loss: 0.6986033\n",
      "Epoch: 2441 , Loss: 0.69854254\n",
      "Epoch: 2442 , Loss: 0.69850594\n",
      "Epoch: 2443 , Loss: 0.69847\n",
      "Epoch: 2444 , Loss: 0.69843465\n",
      "Epoch: 2445 , Loss: 0.6984001\n",
      "Epoch: 2446 , Loss: 0.6983659\n",
      "Epoch: 2447 , Loss: 0.6983324\n",
      "Epoch: 2448 , Loss: 0.69829947\n",
      "Epoch: 2449 , Loss: 0.69826716\n",
      "Epoch: 2450 , Loss: 0.6982353\n",
      "Epoch: 2451 , Loss: 0.69820404\n",
      "Epoch: 2452 , Loss: 0.6981527\n",
      "Epoch: 2453 , Loss: 0.6981431\n",
      "Epoch: 2454 , Loss: 0.69811344\n",
      "Epoch: 2455 , Loss: 0.69808424\n",
      "Epoch: 2456 , Loss: 0.69805545\n",
      "Epoch: 2457 , Loss: 0.6980273\n",
      "Epoch: 2458 , Loss: 0.69799954\n",
      "Epoch: 2459 , Loss: 0.69797224\n",
      "Epoch: 2460 , Loss: 0.6979455\n",
      "Epoch: 2461 , Loss: 0.697919\n",
      "Epoch: 2462 , Loss: 0.697893\n",
      "Epoch: 2463 , Loss: 0.69786745\n",
      "Epoch: 2464 , Loss: 0.69784236\n",
      "Epoch: 2465 , Loss: 0.6978175\n",
      "Epoch: 2466 , Loss: 0.69779426\n",
      "Epoch: 2467 , Loss: 0.6977691\n",
      "Epoch: 2468 , Loss: 0.6977454\n",
      "Epoch: 2469 , Loss: 0.6977221\n",
      "Epoch: 2470 , Loss: 0.69769907\n",
      "Epoch: 2471 , Loss: 0.6976765\n",
      "Epoch: 2472 , Loss: 0.6976541\n",
      "Epoch: 2473 , Loss: 0.6976322\n",
      "Epoch: 2474 , Loss: 0.69761056\n",
      "Epoch: 2475 , Loss: 0.6975892\n",
      "Epoch: 2476 , Loss: 0.6975682\n",
      "Epoch: 2477 , Loss: 0.6975474\n",
      "Epoch: 2478 , Loss: 0.6975269\n",
      "Epoch: 2479 , Loss: 0.69750696\n",
      "Epoch: 2480 , Loss: 0.697487\n",
      "Epoch: 2481 , Loss: 0.69746715\n",
      "Epoch: 2482 , Loss: 0.6974478\n",
      "Epoch: 2483 , Loss: 0.69742864\n",
      "Epoch: 2484 , Loss: 0.6974098\n",
      "Epoch: 2485 , Loss: 0.6973912\n",
      "Epoch: 2486 , Loss: 0.69737273\n",
      "Epoch: 2487 , Loss: 0.6973546\n",
      "Epoch: 2488 , Loss: 0.6973366\n",
      "Epoch: 2489 , Loss: 0.69731885\n",
      "Epoch: 2490 , Loss: 0.6973014\n",
      "Epoch: 2491 , Loss: 0.6972842\n",
      "Epoch: 2492 , Loss: 0.69726706\n",
      "Epoch: 2493 , Loss: 0.6972501\n",
      "Epoch: 2494 , Loss: 0.6972335\n",
      "Epoch: 2495 , Loss: 0.69721687\n",
      "Epoch: 2496 , Loss: 0.69720066\n",
      "Epoch: 2497 , Loss: 0.6971844\n",
      "Epoch: 2498 , Loss: 0.69716847\n",
      "Epoch: 2499 , Loss: 0.69715273\n",
      "Epoch: 2500 , Loss: 0.69713694\n",
      "=============================================\n",
      "13 correctly classified among 100\n",
      "Accuracy as of 2500 epochs: 13.0\n",
      "=============================================\n",
      "Epoch: 2501 , Loss: 0.6971224\n",
      "Epoch: 2502 , Loss: 0.69710636\n",
      "Epoch: 2503 , Loss: 0.6970912\n",
      "Epoch: 2504 , Loss: 0.69707626\n",
      "Epoch: 2505 , Loss: 0.69706154\n",
      "Epoch: 2506 , Loss: 0.6970469\n",
      "Epoch: 2507 , Loss: 0.69703233\n",
      "Epoch: 2508 , Loss: 0.69701785\n",
      "Epoch: 2509 , Loss: 0.69700307\n",
      "Epoch: 2510 , Loss: 0.6969894\n",
      "Epoch: 2511 , Loss: 0.6969756\n",
      "Epoch: 2512 , Loss: 0.69696176\n",
      "Epoch: 2513 , Loss: 0.6969481\n",
      "Epoch: 2514 , Loss: 0.6969345\n",
      "Epoch: 2515 , Loss: 0.6969211\n",
      "Epoch: 2516 , Loss: 0.6969077\n",
      "Epoch: 2517 , Loss: 0.69689447\n",
      "Epoch: 2518 , Loss: 0.6968813\n",
      "Epoch: 2519 , Loss: 0.69686896\n",
      "Epoch: 2520 , Loss: 0.6968555\n",
      "Epoch: 2521 , Loss: 0.6968429\n",
      "Epoch: 2522 , Loss: 0.6968302\n",
      "Epoch: 2523 , Loss: 0.6968177\n",
      "Epoch: 2524 , Loss: 0.6968052\n",
      "Epoch: 2525 , Loss: 0.69679296\n",
      "Epoch: 2526 , Loss: 0.69678074\n",
      "Epoch: 2527 , Loss: 0.6967686\n",
      "Epoch: 2528 , Loss: 0.6967565\n",
      "Epoch: 2529 , Loss: 0.6967446\n",
      "Epoch: 2530 , Loss: 0.69673276\n",
      "Epoch: 2531 , Loss: 0.696721\n",
      "Epoch: 2532 , Loss: 0.6967094\n",
      "Epoch: 2533 , Loss: 0.69669783\n",
      "Epoch: 2534 , Loss: 0.6966863\n",
      "Epoch: 2535 , Loss: 0.69667494\n",
      "Epoch: 2536 , Loss: 0.6966636\n",
      "Epoch: 2537 , Loss: 0.6966523\n",
      "Epoch: 2538 , Loss: 0.69664115\n",
      "Epoch: 2539 , Loss: 0.69662976\n",
      "Epoch: 2540 , Loss: 0.69662046\n",
      "Epoch: 2541 , Loss: 0.6966176\n",
      "Epoch: 2542 , Loss: 0.6965976\n",
      "Epoch: 2543 , Loss: 0.6965869\n",
      "Epoch: 2544 , Loss: 0.69657624\n",
      "Epoch: 2545 , Loss: 0.6965655\n",
      "Epoch: 2546 , Loss: 0.69655514\n",
      "Epoch: 2547 , Loss: 0.69654477\n",
      "Epoch: 2548 , Loss: 0.6965343\n",
      "Epoch: 2549 , Loss: 0.6965239\n",
      "Epoch: 2550 , Loss: 0.6965138\n",
      "Epoch: 2551 , Loss: 0.69650376\n",
      "Epoch: 2552 , Loss: 0.69649357\n",
      "Epoch: 2553 , Loss: 0.69648373\n",
      "Epoch: 2554 , Loss: 0.6964735\n",
      "Epoch: 2555 , Loss: 0.6964637\n",
      "Epoch: 2556 , Loss: 0.6964535\n",
      "Epoch: 2557 , Loss: 0.6964441\n",
      "Epoch: 2558 , Loss: 0.69643456\n",
      "Epoch: 2559 , Loss: 0.6964248\n",
      "Epoch: 2560 , Loss: 0.696415\n",
      "Epoch: 2561 , Loss: 0.69640553\n",
      "Epoch: 2562 , Loss: 0.6963961\n",
      "Epoch: 2563 , Loss: 0.6963865\n",
      "Epoch: 2564 , Loss: 0.69637716\n",
      "Epoch: 2565 , Loss: 0.696368\n",
      "Epoch: 2566 , Loss: 0.6963587\n",
      "Epoch: 2567 , Loss: 0.69634956\n",
      "Epoch: 2568 , Loss: 0.6963398\n",
      "Epoch: 2569 , Loss: 0.69633085\n",
      "Epoch: 2570 , Loss: 0.6963217\n",
      "Epoch: 2571 , Loss: 0.69631416\n",
      "Epoch: 2572 , Loss: 0.6963043\n",
      "Epoch: 2573 , Loss: 0.69629455\n",
      "Epoch: 2574 , Loss: 0.6962877\n",
      "Epoch: 2575 , Loss: 0.6962787\n",
      "Epoch: 2576 , Loss: 0.69626904\n",
      "Epoch: 2577 , Loss: 0.6962602\n",
      "Epoch: 2578 , Loss: 0.69625163\n",
      "Epoch: 2579 , Loss: 0.696243\n",
      "Epoch: 2580 , Loss: 0.6962344\n",
      "Epoch: 2581 , Loss: 0.69622594\n",
      "Epoch: 2582 , Loss: 0.6962174\n",
      "Epoch: 2583 , Loss: 0.69620913\n",
      "Epoch: 2584 , Loss: 0.6962006\n",
      "Epoch: 2585 , Loss: 0.69619197\n",
      "Epoch: 2586 , Loss: 0.6961838\n",
      "Epoch: 2587 , Loss: 0.6961756\n",
      "Epoch: 2588 , Loss: 0.6961672\n",
      "Epoch: 2589 , Loss: 0.6961592\n",
      "Epoch: 2590 , Loss: 0.696151\n",
      "Epoch: 2591 , Loss: 0.696143\n",
      "Epoch: 2592 , Loss: 0.69613487\n",
      "Epoch: 2593 , Loss: 0.69612664\n",
      "Epoch: 2594 , Loss: 0.6961188\n",
      "Epoch: 2595 , Loss: 0.6961106\n",
      "Epoch: 2596 , Loss: 0.69610333\n",
      "Epoch: 2597 , Loss: 0.6960955\n",
      "Epoch: 2598 , Loss: 0.69608706\n",
      "Epoch: 2599 , Loss: 0.69607955\n",
      "Epoch: 2600 , Loss: 0.69607186\n",
      "Epoch: 2601 , Loss: 0.6960644\n",
      "Epoch: 2602 , Loss: 0.6960563\n",
      "Epoch: 2603 , Loss: 0.6960487\n",
      "Epoch: 2604 , Loss: 0.6960407\n",
      "Epoch: 2605 , Loss: 0.6960333\n",
      "Epoch: 2606 , Loss: 0.6960264\n",
      "Epoch: 2607 , Loss: 0.6960184\n",
      "Epoch: 2608 , Loss: 0.6960115\n",
      "Epoch: 2609 , Loss: 0.6960035\n",
      "Epoch: 2610 , Loss: 0.695996\n",
      "Epoch: 2611 , Loss: 0.69598883\n",
      "Epoch: 2612 , Loss: 0.6959813\n",
      "Epoch: 2613 , Loss: 0.69597393\n",
      "Epoch: 2614 , Loss: 0.6959668\n",
      "Epoch: 2615 , Loss: 0.69595975\n",
      "Epoch: 2616 , Loss: 0.69595224\n",
      "Epoch: 2617 , Loss: 0.6959449\n",
      "Epoch: 2618 , Loss: 0.69593805\n",
      "Epoch: 2619 , Loss: 0.69593054\n",
      "Epoch: 2620 , Loss: 0.695923\n",
      "Epoch: 2621 , Loss: 0.6959154\n",
      "Epoch: 2622 , Loss: 0.69591093\n",
      "Epoch: 2623 , Loss: 0.69590247\n",
      "Epoch: 2624 , Loss: 0.69589466\n",
      "Epoch: 2625 , Loss: 0.69589096\n",
      "Epoch: 2626 , Loss: 0.69588065\n",
      "Epoch: 2627 , Loss: 0.69587404\n",
      "Epoch: 2628 , Loss: 0.6958686\n",
      "Epoch: 2629 , Loss: 0.6958606\n",
      "Epoch: 2630 , Loss: 0.6958539\n",
      "Epoch: 2631 , Loss: 0.69584775\n",
      "Epoch: 2632 , Loss: 0.6958405\n",
      "Epoch: 2633 , Loss: 0.69583344\n",
      "Epoch: 2634 , Loss: 0.6958278\n",
      "Epoch: 2635 , Loss: 0.6958206\n",
      "Epoch: 2636 , Loss: 0.6958141\n",
      "Epoch: 2637 , Loss: 0.6958068\n",
      "Epoch: 2638 , Loss: 0.6958011\n",
      "Epoch: 2639 , Loss: 0.6957936\n",
      "Epoch: 2640 , Loss: 0.6957871\n",
      "Epoch: 2641 , Loss: 0.6957804\n",
      "Epoch: 2642 , Loss: 0.69577396\n",
      "Epoch: 2643 , Loss: 0.6957672\n",
      "Epoch: 2644 , Loss: 0.69576144\n",
      "Epoch: 2645 , Loss: 0.6957551\n",
      "Epoch: 2646 , Loss: 0.6957486\n",
      "Epoch: 2647 , Loss: 0.69574195\n",
      "Epoch: 2648 , Loss: 0.69573593\n",
      "Epoch: 2649 , Loss: 0.69572884\n",
      "Epoch: 2650 , Loss: 0.69572294\n",
      "Epoch: 2651 , Loss: 0.6957166\n",
      "Epoch: 2652 , Loss: 0.6957102\n",
      "Epoch: 2653 , Loss: 0.6957036\n",
      "Epoch: 2654 , Loss: 0.6956975\n",
      "Epoch: 2655 , Loss: 0.69569105\n",
      "Epoch: 2656 , Loss: 0.6956848\n",
      "Epoch: 2657 , Loss: 0.6956791\n",
      "Epoch: 2658 , Loss: 0.69567263\n",
      "Epoch: 2659 , Loss: 0.69566745\n",
      "Epoch: 2660 , Loss: 0.69566005\n",
      "Epoch: 2661 , Loss: 0.69565475\n",
      "Epoch: 2662 , Loss: 0.69564855\n",
      "Epoch: 2663 , Loss: 0.69564146\n",
      "Epoch: 2664 , Loss: 0.69563586\n",
      "Epoch: 2665 , Loss: 0.69562984\n",
      "Epoch: 2666 , Loss: 0.6956253\n",
      "Epoch: 2667 , Loss: 0.69561833\n",
      "Epoch: 2668 , Loss: 0.6956136\n",
      "Epoch: 2669 , Loss: 0.6956059\n",
      "Epoch: 2670 , Loss: 0.6956002\n",
      "Epoch: 2671 , Loss: 0.69559455\n",
      "Epoch: 2672 , Loss: 0.69558877\n",
      "Epoch: 2673 , Loss: 0.69558287\n",
      "Epoch: 2674 , Loss: 0.6955774\n",
      "Epoch: 2675 , Loss: 0.69557106\n",
      "Epoch: 2676 , Loss: 0.6955652\n",
      "Epoch: 2677 , Loss: 0.69555926\n",
      "Epoch: 2678 , Loss: 0.6955536\n",
      "Epoch: 2679 , Loss: 0.6955479\n",
      "Epoch: 2680 , Loss: 0.69554275\n",
      "Epoch: 2681 , Loss: 0.69553554\n",
      "Epoch: 2682 , Loss: 0.69553125\n",
      "Epoch: 2683 , Loss: 0.6955204\n",
      "Epoch: 2684 , Loss: 0.69551116\n",
      "Epoch: 2685 , Loss: 0.6955522\n",
      "Epoch: 2686 , Loss: 0.69549555\n",
      "Epoch: 2687 , Loss: 0.69550914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2688 , Loss: 0.69548196\n",
      "Epoch: 2689 , Loss: 0.6954874\n",
      "Epoch: 2690 , Loss: 0.6954878\n",
      "Epoch: 2691 , Loss: 0.6954306\n",
      "Epoch: 2692 , Loss: 0.69568366\n",
      "Epoch: 2693 , Loss: 0.69547695\n",
      "Epoch: 2694 , Loss: 0.69546723\n",
      "Epoch: 2695 , Loss: 0.69546527\n",
      "Epoch: 2696 , Loss: 0.69546694\n",
      "Epoch: 2697 , Loss: 0.6954622\n",
      "Epoch: 2698 , Loss: 0.6954645\n",
      "Epoch: 2699 , Loss: 0.6954601\n",
      "Epoch: 2700 , Loss: 0.6954651\n",
      "Epoch: 2701 , Loss: 0.69546205\n",
      "Epoch: 2702 , Loss: 0.6954578\n",
      "Epoch: 2703 , Loss: 0.69545525\n",
      "Epoch: 2704 , Loss: 0.6954526\n",
      "Epoch: 2705 , Loss: 0.69544894\n",
      "Epoch: 2706 , Loss: 0.6954446\n",
      "Epoch: 2707 , Loss: 0.695437\n",
      "Epoch: 2708 , Loss: 0.69543606\n",
      "Epoch: 2709 , Loss: 0.6954444\n",
      "Epoch: 2710 , Loss: 0.69542783\n",
      "Epoch: 2711 , Loss: 0.695419\n",
      "Epoch: 2712 , Loss: 0.6954135\n",
      "Epoch: 2713 , Loss: 0.69538724\n",
      "Epoch: 2714 , Loss: 0.6953983\n",
      "Epoch: 2715 , Loss: 0.69538254\n",
      "Epoch: 2716 , Loss: 0.69541323\n",
      "Epoch: 2717 , Loss: 0.6953832\n",
      "Epoch: 2718 , Loss: 0.6953727\n",
      "Epoch: 2719 , Loss: 0.6953653\n",
      "Epoch: 2720 , Loss: 0.6953594\n",
      "Epoch: 2721 , Loss: 0.69535923\n",
      "Epoch: 2722 , Loss: 0.6953549\n",
      "Epoch: 2723 , Loss: 0.6953537\n",
      "Epoch: 2724 , Loss: 0.6953368\n",
      "Epoch: 2725 , Loss: 0.6953323\n",
      "Epoch: 2726 , Loss: 0.6953246\n",
      "Epoch: 2727 , Loss: 0.69531876\n",
      "Epoch: 2728 , Loss: 0.69531184\n",
      "Epoch: 2729 , Loss: 0.69530743\n",
      "Epoch: 2730 , Loss: 0.69530046\n",
      "Epoch: 2731 , Loss: 0.69529337\n",
      "Epoch: 2732 , Loss: 0.6952895\n",
      "Epoch: 2733 , Loss: 0.6952779\n",
      "Epoch: 2734 , Loss: 0.6952778\n",
      "Epoch: 2735 , Loss: 0.6952706\n",
      "Epoch: 2736 , Loss: 0.6952641\n",
      "Epoch: 2737 , Loss: 0.6952589\n",
      "Epoch: 2738 , Loss: 0.69524884\n",
      "Epoch: 2739 , Loss: 0.6952416\n",
      "Epoch: 2740 , Loss: 0.6952382\n",
      "Epoch: 2741 , Loss: 0.69523555\n",
      "Epoch: 2742 , Loss: 0.6952375\n",
      "Epoch: 2743 , Loss: 0.69522804\n",
      "Epoch: 2744 , Loss: 0.69522077\n",
      "Epoch: 2745 , Loss: 0.69521475\n",
      "Epoch: 2746 , Loss: 0.69520605\n",
      "Epoch: 2747 , Loss: 0.69520265\n",
      "Epoch: 2748 , Loss: 0.69520164\n",
      "Epoch: 2749 , Loss: 0.6951914\n",
      "Epoch: 2750 , Loss: 0.6951863\n",
      "=============================================\n",
      "1 correctly classified among 100\n",
      "Accuracy as of 2750 epochs: 1.0\n",
      "=============================================\n",
      "Epoch: 2751 , Loss: 0.6951836\n",
      "Epoch: 2752 , Loss: 0.6951767\n",
      "Epoch: 2753 , Loss: 0.69517267\n",
      "Epoch: 2754 , Loss: 0.6951667\n",
      "Epoch: 2755 , Loss: 0.69516253\n",
      "Epoch: 2756 , Loss: 0.69515747\n",
      "Epoch: 2757 , Loss: 0.6951519\n",
      "Epoch: 2758 , Loss: 0.6951469\n",
      "Epoch: 2759 , Loss: 0.6951428\n",
      "Epoch: 2760 , Loss: 0.6951379\n",
      "Epoch: 2761 , Loss: 0.6951335\n",
      "Epoch: 2762 , Loss: 0.69512796\n",
      "Epoch: 2763 , Loss: 0.69512355\n",
      "Epoch: 2764 , Loss: 0.6951187\n",
      "Epoch: 2765 , Loss: 0.69511384\n",
      "Epoch: 2766 , Loss: 0.69510984\n",
      "Epoch: 2767 , Loss: 0.69510496\n",
      "Epoch: 2768 , Loss: 0.69510025\n",
      "Epoch: 2769 , Loss: 0.6950954\n",
      "Epoch: 2770 , Loss: 0.6950913\n",
      "Epoch: 2771 , Loss: 0.6950854\n",
      "Epoch: 2772 , Loss: 0.69508153\n",
      "Epoch: 2773 , Loss: 0.6950788\n",
      "Epoch: 2774 , Loss: 0.6950734\n",
      "Epoch: 2775 , Loss: 0.6950658\n",
      "Epoch: 2776 , Loss: 0.69506365\n",
      "Epoch: 2777 , Loss: 0.6950602\n",
      "Epoch: 2778 , Loss: 0.69505835\n",
      "Epoch: 2779 , Loss: 0.6950504\n",
      "Epoch: 2780 , Loss: 0.6950489\n",
      "Epoch: 2781 , Loss: 0.6950385\n",
      "Epoch: 2782 , Loss: 0.6950371\n",
      "Epoch: 2783 , Loss: 0.69504386\n",
      "Epoch: 2784 , Loss: 0.69503254\n",
      "Epoch: 2785 , Loss: 0.69502515\n",
      "Epoch: 2786 , Loss: 0.6950209\n",
      "Epoch: 2787 , Loss: 0.6950158\n",
      "Epoch: 2788 , Loss: 0.695009\n",
      "Epoch: 2789 , Loss: 0.69500893\n",
      "Epoch: 2790 , Loss: 0.6950053\n",
      "Epoch: 2791 , Loss: 0.6949987\n",
      "Epoch: 2792 , Loss: 0.6949962\n",
      "Epoch: 2793 , Loss: 0.6949937\n",
      "Epoch: 2794 , Loss: 0.69498664\n",
      "Epoch: 2795 , Loss: 0.6949826\n",
      "Epoch: 2796 , Loss: 0.6949781\n",
      "Epoch: 2797 , Loss: 0.69497466\n",
      "Epoch: 2798 , Loss: 0.6949704\n",
      "Epoch: 2799 , Loss: 0.69496596\n",
      "Epoch: 2800 , Loss: 0.6949618\n",
      "Epoch: 2801 , Loss: 0.6949573\n",
      "Epoch: 2802 , Loss: 0.6949548\n",
      "Epoch: 2803 , Loss: 0.6949482\n",
      "Epoch: 2804 , Loss: 0.69494396\n",
      "Epoch: 2805 , Loss: 0.69494146\n",
      "Epoch: 2806 , Loss: 0.69493777\n",
      "Epoch: 2807 , Loss: 0.6949336\n",
      "Epoch: 2808 , Loss: 0.6949304\n",
      "Epoch: 2809 , Loss: 0.69492596\n",
      "Epoch: 2810 , Loss: 0.6949204\n",
      "Epoch: 2811 , Loss: 0.694916\n",
      "Epoch: 2812 , Loss: 0.6949147\n",
      "Epoch: 2813 , Loss: 0.69490784\n",
      "Epoch: 2814 , Loss: 0.69491214\n",
      "Epoch: 2815 , Loss: 0.6949022\n",
      "Epoch: 2816 , Loss: 0.69489753\n",
      "Epoch: 2817 , Loss: 0.69489306\n",
      "Epoch: 2818 , Loss: 0.6948878\n",
      "Epoch: 2819 , Loss: 0.6948833\n",
      "Epoch: 2820 , Loss: 0.69488025\n",
      "Epoch: 2821 , Loss: 0.6948789\n",
      "Epoch: 2822 , Loss: 0.69487923\n",
      "Epoch: 2823 , Loss: 0.6948671\n",
      "Epoch: 2824 , Loss: 0.6948633\n",
      "Epoch: 2825 , Loss: 0.6948636\n",
      "Epoch: 2826 , Loss: 0.69486386\n",
      "Epoch: 2827 , Loss: 0.6948574\n",
      "Epoch: 2828 , Loss: 0.6948514\n",
      "Epoch: 2829 , Loss: 0.69484496\n",
      "Epoch: 2830 , Loss: 0.6948406\n",
      "Epoch: 2831 , Loss: 0.6948403\n",
      "Epoch: 2832 , Loss: 0.69483733\n",
      "Epoch: 2833 , Loss: 0.69483244\n",
      "Epoch: 2834 , Loss: 0.694828\n",
      "Epoch: 2835 , Loss: 0.6948245\n",
      "Epoch: 2836 , Loss: 0.6948196\n",
      "Epoch: 2837 , Loss: 0.6948154\n",
      "Epoch: 2838 , Loss: 0.6948122\n",
      "Epoch: 2839 , Loss: 0.6948091\n",
      "Epoch: 2840 , Loss: 0.6948057\n",
      "Epoch: 2841 , Loss: 0.6948013\n",
      "Epoch: 2842 , Loss: 0.6947975\n",
      "Epoch: 2843 , Loss: 0.6947935\n",
      "Epoch: 2844 , Loss: 0.69478995\n",
      "Epoch: 2845 , Loss: 0.69478697\n",
      "Epoch: 2846 , Loss: 0.69478196\n",
      "Epoch: 2847 , Loss: 0.6947788\n",
      "Epoch: 2848 , Loss: 0.6947769\n",
      "Epoch: 2849 , Loss: 0.6947718\n",
      "Epoch: 2850 , Loss: 0.69476867\n",
      "Epoch: 2851 , Loss: 0.6947645\n",
      "Epoch: 2852 , Loss: 0.69475967\n",
      "Epoch: 2853 , Loss: 0.6947568\n",
      "Epoch: 2854 , Loss: 0.694754\n",
      "Epoch: 2855 , Loss: 0.69475144\n",
      "Epoch: 2856 , Loss: 0.6947471\n",
      "Epoch: 2857 , Loss: 0.69474375\n",
      "Epoch: 2858 , Loss: 0.6947377\n",
      "Epoch: 2859 , Loss: 0.6947382\n",
      "Epoch: 2860 , Loss: 0.69473296\n",
      "Epoch: 2861 , Loss: 0.6947301\n",
      "Epoch: 2862 , Loss: 0.6947255\n",
      "Epoch: 2863 , Loss: 0.6947215\n",
      "Epoch: 2864 , Loss: 0.6947181\n",
      "Epoch: 2865 , Loss: 0.6947146\n",
      "Epoch: 2866 , Loss: 0.6947107\n",
      "Epoch: 2867 , Loss: 0.6947074\n",
      "Epoch: 2868 , Loss: 0.6947037\n",
      "Epoch: 2869 , Loss: 0.6947003\n",
      "Epoch: 2870 , Loss: 0.6946974\n",
      "Epoch: 2871 , Loss: 0.6946933\n",
      "Epoch: 2872 , Loss: 0.6946898\n",
      "Epoch: 2873 , Loss: 0.69468725\n",
      "Epoch: 2874 , Loss: 0.6946837\n",
      "Epoch: 2875 , Loss: 0.69467956\n",
      "Epoch: 2876 , Loss: 0.694677\n",
      "Epoch: 2877 , Loss: 0.69467294\n",
      "Epoch: 2878 , Loss: 0.69466925\n",
      "Epoch: 2879 , Loss: 0.69466585\n",
      "Epoch: 2880 , Loss: 0.69466275\n",
      "Epoch: 2881 , Loss: 0.69465864\n",
      "Epoch: 2882 , Loss: 0.694656\n",
      "Epoch: 2883 , Loss: 0.69465226\n",
      "Epoch: 2884 , Loss: 0.6946497\n",
      "Epoch: 2885 , Loss: 0.6946458\n",
      "Epoch: 2886 , Loss: 0.69464266\n",
      "Epoch: 2887 , Loss: 0.6946385\n",
      "Epoch: 2888 , Loss: 0.69463605\n",
      "Epoch: 2889 , Loss: 0.69463235\n",
      "Epoch: 2890 , Loss: 0.6946292\n",
      "Epoch: 2891 , Loss: 0.6946255\n",
      "Epoch: 2892 , Loss: 0.6946224\n",
      "Epoch: 2893 , Loss: 0.6946192\n",
      "Epoch: 2894 , Loss: 0.69461584\n",
      "Epoch: 2895 , Loss: 0.6946125\n",
      "Epoch: 2896 , Loss: 0.694609\n",
      "Epoch: 2897 , Loss: 0.6946059\n",
      "Epoch: 2898 , Loss: 0.69460297\n",
      "Epoch: 2899 , Loss: 0.69459945\n",
      "Epoch: 2900 , Loss: 0.694596\n",
      "Epoch: 2901 , Loss: 0.6945928\n",
      "Epoch: 2902 , Loss: 0.6945896\n",
      "Epoch: 2903 , Loss: 0.6945862\n",
      "Epoch: 2904 , Loss: 0.69458336\n",
      "Epoch: 2905 , Loss: 0.69457996\n",
      "Epoch: 2906 , Loss: 0.6945767\n",
      "Epoch: 2907 , Loss: 0.69457364\n",
      "Epoch: 2908 , Loss: 0.6945703\n",
      "Epoch: 2909 , Loss: 0.69456714\n",
      "Epoch: 2910 , Loss: 0.6945639\n",
      "Epoch: 2911 , Loss: 0.6945607\n",
      "Epoch: 2912 , Loss: 0.6945577\n",
      "Epoch: 2913 , Loss: 0.69455445\n",
      "Epoch: 2914 , Loss: 0.6945513\n",
      "Epoch: 2915 , Loss: 0.6945481\n",
      "Epoch: 2916 , Loss: 0.6945451\n",
      "Epoch: 2917 , Loss: 0.69454175\n",
      "Epoch: 2918 , Loss: 0.69453865\n",
      "Epoch: 2919 , Loss: 0.6945357\n",
      "Epoch: 2920 , Loss: 0.6945325\n",
      "Epoch: 2921 , Loss: 0.6945293\n",
      "Epoch: 2922 , Loss: 0.6945264\n",
      "Epoch: 2923 , Loss: 0.6945232\n",
      "Epoch: 2924 , Loss: 0.6945201\n",
      "Epoch: 2925 , Loss: 0.694517\n",
      "Epoch: 2926 , Loss: 0.6945139\n",
      "Epoch: 2927 , Loss: 0.69451094\n",
      "Epoch: 2928 , Loss: 0.69450784\n",
      "Epoch: 2929 , Loss: 0.6945048\n",
      "Epoch: 2930 , Loss: 0.69450176\n",
      "Epoch: 2931 , Loss: 0.6944988\n",
      "Epoch: 2932 , Loss: 0.6944957\n",
      "Epoch: 2933 , Loss: 0.69449264\n",
      "Epoch: 2934 , Loss: 0.69448966\n",
      "Epoch: 2935 , Loss: 0.6944866\n",
      "Epoch: 2936 , Loss: 0.69448364\n",
      "Epoch: 2937 , Loss: 0.69448066\n",
      "Epoch: 2938 , Loss: 0.69447756\n",
      "Epoch: 2939 , Loss: 0.69447464\n",
      "Epoch: 2940 , Loss: 0.6944717\n",
      "Epoch: 2941 , Loss: 0.6944686\n",
      "Epoch: 2942 , Loss: 0.6944658\n",
      "Epoch: 2943 , Loss: 0.6944628\n",
      "Epoch: 2944 , Loss: 0.69445974\n",
      "Epoch: 2945 , Loss: 0.6944569\n",
      "Epoch: 2946 , Loss: 0.6944542\n",
      "Epoch: 2947 , Loss: 0.69445103\n",
      "Epoch: 2948 , Loss: 0.6944483\n",
      "Epoch: 2949 , Loss: 0.69444525\n",
      "Epoch: 2950 , Loss: 0.6944421\n",
      "Epoch: 2951 , Loss: 0.69443935\n",
      "Epoch: 2952 , Loss: 0.69443643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2953 , Loss: 0.6944336\n",
      "Epoch: 2954 , Loss: 0.6944307\n",
      "Epoch: 2955 , Loss: 0.69442785\n",
      "Epoch: 2956 , Loss: 0.694425\n",
      "Epoch: 2957 , Loss: 0.6944221\n",
      "Epoch: 2958 , Loss: 0.69441926\n",
      "Epoch: 2959 , Loss: 0.6944164\n",
      "Epoch: 2960 , Loss: 0.6944135\n",
      "Epoch: 2961 , Loss: 0.6944106\n",
      "Epoch: 2962 , Loss: 0.6944078\n",
      "Epoch: 2963 , Loss: 0.694405\n",
      "Epoch: 2964 , Loss: 0.6944022\n",
      "Epoch: 2965 , Loss: 0.69439936\n",
      "Epoch: 2966 , Loss: 0.69439656\n",
      "Epoch: 2967 , Loss: 0.69439375\n",
      "Epoch: 2968 , Loss: 0.694391\n",
      "Epoch: 2969 , Loss: 0.69438815\n",
      "Epoch: 2970 , Loss: 0.69438535\n",
      "Epoch: 2971 , Loss: 0.6943825\n",
      "Epoch: 2972 , Loss: 0.6943798\n",
      "Epoch: 2973 , Loss: 0.69437695\n",
      "Epoch: 2974 , Loss: 0.6943742\n",
      "Epoch: 2975 , Loss: 0.6943716\n",
      "Epoch: 2976 , Loss: 0.69436884\n",
      "Epoch: 2977 , Loss: 0.694366\n",
      "Epoch: 2978 , Loss: 0.69436336\n",
      "Epoch: 2979 , Loss: 0.6943606\n",
      "Epoch: 2980 , Loss: 0.69435775\n",
      "Epoch: 2981 , Loss: 0.69435495\n",
      "Epoch: 2982 , Loss: 0.6943525\n",
      "Epoch: 2983 , Loss: 0.6943497\n",
      "Epoch: 2984 , Loss: 0.694347\n",
      "Epoch: 2985 , Loss: 0.69434434\n",
      "Epoch: 2986 , Loss: 0.6943415\n",
      "Epoch: 2987 , Loss: 0.6943389\n",
      "Epoch: 2988 , Loss: 0.6943361\n",
      "Epoch: 2989 , Loss: 0.6943337\n",
      "Epoch: 2990 , Loss: 0.6943309\n",
      "Epoch: 2991 , Loss: 0.69432837\n",
      "Epoch: 2992 , Loss: 0.6943257\n",
      "Epoch: 2993 , Loss: 0.694323\n",
      "Epoch: 2994 , Loss: 0.69432044\n",
      "Epoch: 2995 , Loss: 0.69431764\n",
      "Epoch: 2996 , Loss: 0.6943149\n",
      "Epoch: 2997 , Loss: 0.6943125\n",
      "Epoch: 2998 , Loss: 0.69430965\n",
      "Epoch: 2999 , Loss: 0.69430727\n",
      "Epoch: 3000 , Loss: 0.6943046\n",
      "=============================================\n",
      "4 correctly classified among 100\n",
      "Accuracy as of 3000 epochs: 4.0\n",
      "=============================================\n",
      "Epoch: 3001 , Loss: 0.6943021\n",
      "Epoch: 3002 , Loss: 0.69429934\n",
      "Epoch: 3003 , Loss: 0.6942968\n",
      "Epoch: 3004 , Loss: 0.69429415\n",
      "Epoch: 3005 , Loss: 0.69429165\n",
      "Epoch: 3006 , Loss: 0.6942891\n",
      "Epoch: 3007 , Loss: 0.6942864\n",
      "Epoch: 3008 , Loss: 0.6942839\n",
      "Epoch: 3009 , Loss: 0.6942813\n",
      "Epoch: 3010 , Loss: 0.6942788\n",
      "Epoch: 3011 , Loss: 0.6942762\n",
      "Epoch: 3012 , Loss: 0.69427353\n",
      "Epoch: 3013 , Loss: 0.69427115\n",
      "Epoch: 3014 , Loss: 0.6942686\n",
      "Epoch: 3015 , Loss: 0.694266\n",
      "Epoch: 3016 , Loss: 0.69426346\n",
      "Epoch: 3017 , Loss: 0.69426095\n",
      "Epoch: 3018 , Loss: 0.6942586\n",
      "Epoch: 3019 , Loss: 0.694256\n",
      "Epoch: 3020 , Loss: 0.69425356\n",
      "Epoch: 3021 , Loss: 0.69425106\n",
      "Epoch: 3022 , Loss: 0.6942484\n",
      "Epoch: 3023 , Loss: 0.69424593\n",
      "Epoch: 3024 , Loss: 0.6942439\n",
      "Epoch: 3025 , Loss: 0.6942406\n",
      "Epoch: 3026 , Loss: 0.6942385\n",
      "Epoch: 3027 , Loss: 0.6942361\n",
      "Epoch: 3028 , Loss: 0.6942339\n",
      "Epoch: 3029 , Loss: 0.6942312\n",
      "Epoch: 3030 , Loss: 0.6942286\n",
      "Epoch: 3031 , Loss: 0.69422644\n",
      "Epoch: 3032 , Loss: 0.6942239\n",
      "Epoch: 3033 , Loss: 0.69422156\n",
      "Epoch: 3034 , Loss: 0.69421875\n",
      "Epoch: 3035 , Loss: 0.6942169\n",
      "Epoch: 3036 , Loss: 0.6942147\n",
      "Epoch: 3037 , Loss: 0.69421154\n",
      "Epoch: 3038 , Loss: 0.69420856\n",
      "Epoch: 3039 , Loss: 0.6942076\n",
      "Epoch: 3040 , Loss: 0.6942054\n",
      "Epoch: 3041 , Loss: 0.6942026\n",
      "Epoch: 3042 , Loss: 0.69419986\n",
      "Epoch: 3043 , Loss: 0.69419765\n",
      "Epoch: 3044 , Loss: 0.6941953\n",
      "Epoch: 3045 , Loss: 0.6941932\n",
      "Epoch: 3046 , Loss: 0.69419014\n",
      "Epoch: 3047 , Loss: 0.6941878\n",
      "Epoch: 3048 , Loss: 0.6941858\n",
      "Epoch: 3049 , Loss: 0.694183\n",
      "Epoch: 3050 , Loss: 0.694181\n",
      "Epoch: 3051 , Loss: 0.6941788\n",
      "Epoch: 3052 , Loss: 0.6941764\n",
      "Epoch: 3053 , Loss: 0.69417393\n",
      "Epoch: 3054 , Loss: 0.6941719\n",
      "Epoch: 3055 , Loss: 0.6941694\n",
      "Epoch: 3056 , Loss: 0.694167\n",
      "Epoch: 3057 , Loss: 0.6941649\n",
      "Epoch: 3058 , Loss: 0.69416237\n",
      "Epoch: 3059 , Loss: 0.69416004\n",
      "Epoch: 3060 , Loss: 0.6941578\n",
      "Epoch: 3061 , Loss: 0.6941555\n",
      "Epoch: 3062 , Loss: 0.6941532\n",
      "Epoch: 3063 , Loss: 0.694151\n",
      "Epoch: 3064 , Loss: 0.6941487\n",
      "Epoch: 3065 , Loss: 0.6941464\n",
      "Epoch: 3066 , Loss: 0.6941441\n",
      "Epoch: 3067 , Loss: 0.69414186\n",
      "Epoch: 3068 , Loss: 0.69413966\n",
      "Epoch: 3069 , Loss: 0.6941374\n",
      "Epoch: 3070 , Loss: 0.6941351\n",
      "Epoch: 3071 , Loss: 0.6941329\n",
      "Epoch: 3072 , Loss: 0.69413066\n",
      "Epoch: 3073 , Loss: 0.69412833\n",
      "Epoch: 3074 , Loss: 0.69412637\n",
      "Epoch: 3075 , Loss: 0.69412404\n",
      "Epoch: 3076 , Loss: 0.6941218\n",
      "Epoch: 3077 , Loss: 0.6941195\n",
      "Epoch: 3078 , Loss: 0.6941173\n",
      "Epoch: 3079 , Loss: 0.69411516\n",
      "Epoch: 3080 , Loss: 0.6941129\n",
      "Epoch: 3081 , Loss: 0.69411075\n",
      "Epoch: 3082 , Loss: 0.69410855\n",
      "Epoch: 3083 , Loss: 0.69410634\n",
      "Epoch: 3084 , Loss: 0.6941042\n",
      "Epoch: 3085 , Loss: 0.69410205\n",
      "Epoch: 3086 , Loss: 0.69409984\n",
      "Epoch: 3087 , Loss: 0.6940977\n",
      "Epoch: 3088 , Loss: 0.6940955\n",
      "Epoch: 3089 , Loss: 0.6940934\n",
      "Epoch: 3090 , Loss: 0.69409126\n",
      "Epoch: 3091 , Loss: 0.69408906\n",
      "Epoch: 3092 , Loss: 0.6940869\n",
      "Epoch: 3093 , Loss: 0.6940848\n",
      "Epoch: 3094 , Loss: 0.6940827\n",
      "Epoch: 3095 , Loss: 0.69408053\n",
      "Epoch: 3096 , Loss: 0.69407845\n",
      "Epoch: 3097 , Loss: 0.6940763\n",
      "Epoch: 3098 , Loss: 0.6940742\n",
      "Epoch: 3099 , Loss: 0.69407207\n",
      "Epoch: 3100 , Loss: 0.69407\n",
      "Epoch: 3101 , Loss: 0.6940679\n",
      "Epoch: 3102 , Loss: 0.6940658\n",
      "Epoch: 3103 , Loss: 0.69406366\n",
      "Epoch: 3104 , Loss: 0.6940616\n",
      "Epoch: 3105 , Loss: 0.69405955\n",
      "Epoch: 3106 , Loss: 0.69405746\n",
      "Epoch: 3107 , Loss: 0.6940553\n",
      "Epoch: 3108 , Loss: 0.69405323\n",
      "Epoch: 3109 , Loss: 0.69405115\n",
      "Epoch: 3110 , Loss: 0.6940491\n",
      "Epoch: 3111 , Loss: 0.694047\n",
      "Epoch: 3112 , Loss: 0.69404507\n",
      "Epoch: 3113 , Loss: 0.694043\n",
      "Epoch: 3114 , Loss: 0.6940409\n",
      "Epoch: 3115 , Loss: 0.69403887\n",
      "Epoch: 3116 , Loss: 0.6940369\n",
      "Epoch: 3117 , Loss: 0.69403493\n",
      "Epoch: 3118 , Loss: 0.6940326\n",
      "Epoch: 3119 , Loss: 0.69403076\n",
      "Epoch: 3120 , Loss: 0.69402874\n",
      "Epoch: 3121 , Loss: 0.6940267\n",
      "Epoch: 3122 , Loss: 0.6940246\n",
      "Epoch: 3123 , Loss: 0.6940226\n",
      "Epoch: 3124 , Loss: 0.69402075\n",
      "Epoch: 3125 , Loss: 0.69401866\n",
      "Epoch: 3126 , Loss: 0.69401675\n",
      "Epoch: 3127 , Loss: 0.6940147\n",
      "Epoch: 3128 , Loss: 0.6940129\n",
      "Epoch: 3129 , Loss: 0.694011\n",
      "Epoch: 3130 , Loss: 0.694009\n",
      "Epoch: 3131 , Loss: 0.69400686\n",
      "Epoch: 3132 , Loss: 0.6940048\n",
      "Epoch: 3133 , Loss: 0.69400305\n",
      "Epoch: 3134 , Loss: 0.694001\n",
      "Epoch: 3135 , Loss: 0.69399905\n",
      "Epoch: 3136 , Loss: 0.69399685\n",
      "Epoch: 3137 , Loss: 0.693995\n",
      "Epoch: 3138 , Loss: 0.6939932\n",
      "Epoch: 3139 , Loss: 0.6939912\n",
      "Epoch: 3140 , Loss: 0.6939893\n",
      "Epoch: 3141 , Loss: 0.69398725\n",
      "Epoch: 3142 , Loss: 0.6939856\n",
      "Epoch: 3143 , Loss: 0.69398314\n",
      "Epoch: 3144 , Loss: 0.6939817\n",
      "Epoch: 3145 , Loss: 0.6939797\n",
      "Epoch: 3146 , Loss: 0.6939776\n",
      "Epoch: 3147 , Loss: 0.6939757\n",
      "Epoch: 3148 , Loss: 0.6939738\n",
      "Epoch: 3149 , Loss: 0.69397205\n",
      "Epoch: 3150 , Loss: 0.69396996\n",
      "Epoch: 3151 , Loss: 0.6939682\n",
      "Epoch: 3152 , Loss: 0.6939665\n",
      "Epoch: 3153 , Loss: 0.6939645\n",
      "Epoch: 3154 , Loss: 0.6939624\n",
      "Epoch: 3155 , Loss: 0.6939611\n",
      "Epoch: 3156 , Loss: 0.6939589\n",
      "Epoch: 3157 , Loss: 0.6939574\n",
      "Epoch: 3158 , Loss: 0.6939549\n",
      "Epoch: 3159 , Loss: 0.69395345\n",
      "Epoch: 3160 , Loss: 0.69395167\n",
      "Epoch: 3161 , Loss: 0.6939494\n",
      "Epoch: 3162 , Loss: 0.69394755\n",
      "Epoch: 3163 , Loss: 0.69394594\n",
      "Epoch: 3164 , Loss: 0.6939441\n",
      "Epoch: 3165 , Loss: 0.69394237\n",
      "Epoch: 3166 , Loss: 0.6939403\n",
      "Epoch: 3167 , Loss: 0.6939384\n",
      "Epoch: 3168 , Loss: 0.69393647\n",
      "Epoch: 3169 , Loss: 0.6939345\n",
      "Epoch: 3170 , Loss: 0.69393337\n",
      "Epoch: 3171 , Loss: 0.69393146\n",
      "Epoch: 3172 , Loss: 0.6939297\n",
      "Epoch: 3173 , Loss: 0.6939281\n",
      "Epoch: 3174 , Loss: 0.69392586\n",
      "Epoch: 3175 , Loss: 0.6939241\n",
      "Epoch: 3176 , Loss: 0.69392234\n",
      "Epoch: 3177 , Loss: 0.69392043\n",
      "Epoch: 3178 , Loss: 0.6939184\n",
      "Epoch: 3179 , Loss: 0.6939169\n",
      "Epoch: 3180 , Loss: 0.69391567\n",
      "Epoch: 3181 , Loss: 0.69391364\n",
      "Epoch: 3182 , Loss: 0.6939119\n",
      "Epoch: 3183 , Loss: 0.69390994\n",
      "Epoch: 3184 , Loss: 0.6939078\n",
      "Epoch: 3185 , Loss: 0.6939065\n",
      "Epoch: 3186 , Loss: 0.69390494\n",
      "Epoch: 3187 , Loss: 0.6939032\n",
      "Epoch: 3188 , Loss: 0.69390094\n",
      "Epoch: 3189 , Loss: 0.69389933\n",
      "Epoch: 3190 , Loss: 0.6938976\n",
      "Epoch: 3191 , Loss: 0.69389594\n",
      "Epoch: 3192 , Loss: 0.6938942\n",
      "Epoch: 3193 , Loss: 0.6938925\n",
      "Epoch: 3194 , Loss: 0.69389075\n",
      "Epoch: 3195 , Loss: 0.69388896\n",
      "Epoch: 3196 , Loss: 0.6938873\n",
      "Epoch: 3197 , Loss: 0.69388556\n",
      "Epoch: 3198 , Loss: 0.6938839\n",
      "Epoch: 3199 , Loss: 0.69388217\n",
      "Epoch: 3200 , Loss: 0.6938805\n",
      "Epoch: 3201 , Loss: 0.69387877\n",
      "Epoch: 3202 , Loss: 0.69387704\n",
      "Epoch: 3203 , Loss: 0.6938754\n",
      "Epoch: 3204 , Loss: 0.6938737\n",
      "Epoch: 3205 , Loss: 0.69387203\n",
      "Epoch: 3206 , Loss: 0.69387037\n",
      "Epoch: 3207 , Loss: 0.6938687\n",
      "Epoch: 3208 , Loss: 0.693867\n",
      "Epoch: 3209 , Loss: 0.6938653\n",
      "Epoch: 3210 , Loss: 0.69386363\n",
      "Epoch: 3211 , Loss: 0.69386196\n",
      "Epoch: 3212 , Loss: 0.69386035\n",
      "Epoch: 3213 , Loss: 0.6938587\n",
      "Epoch: 3214 , Loss: 0.69385695\n",
      "Epoch: 3215 , Loss: 0.6938554\n",
      "Epoch: 3216 , Loss: 0.6938537\n",
      "Epoch: 3217 , Loss: 0.69385207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3218 , Loss: 0.69385046\n",
      "Epoch: 3219 , Loss: 0.6938487\n",
      "Epoch: 3220 , Loss: 0.6938472\n",
      "Epoch: 3221 , Loss: 0.69384557\n",
      "Epoch: 3222 , Loss: 0.6938439\n",
      "Epoch: 3223 , Loss: 0.69384235\n",
      "Epoch: 3224 , Loss: 0.6938407\n",
      "Epoch: 3225 , Loss: 0.6938391\n",
      "Epoch: 3226 , Loss: 0.69383746\n",
      "Epoch: 3227 , Loss: 0.69383585\n",
      "Epoch: 3228 , Loss: 0.69383425\n",
      "Epoch: 3229 , Loss: 0.6938327\n",
      "Epoch: 3230 , Loss: 0.6938311\n",
      "Epoch: 3231 , Loss: 0.69382954\n",
      "Epoch: 3232 , Loss: 0.69382787\n",
      "Epoch: 3233 , Loss: 0.6938263\n",
      "Epoch: 3234 , Loss: 0.69382465\n",
      "Epoch: 3235 , Loss: 0.69382304\n",
      "Epoch: 3236 , Loss: 0.69382167\n",
      "Epoch: 3237 , Loss: 0.69381994\n",
      "Epoch: 3238 , Loss: 0.69381845\n",
      "Epoch: 3239 , Loss: 0.693817\n",
      "Epoch: 3240 , Loss: 0.69381535\n",
      "Epoch: 3241 , Loss: 0.6938138\n",
      "Epoch: 3242 , Loss: 0.6938122\n",
      "Epoch: 3243 , Loss: 0.6938107\n",
      "Epoch: 3244 , Loss: 0.6938091\n",
      "Epoch: 3245 , Loss: 0.69380754\n",
      "Epoch: 3246 , Loss: 0.69380605\n",
      "Epoch: 3247 , Loss: 0.6938045\n",
      "Epoch: 3248 , Loss: 0.69380295\n",
      "Epoch: 3249 , Loss: 0.6938014\n",
      "Epoch: 3250 , Loss: 0.6937999\n",
      "=============================================\n",
      "4 correctly classified among 100\n",
      "Accuracy as of 3250 epochs: 4.0\n",
      "=============================================\n",
      "Epoch: 3251 , Loss: 0.6937983\n",
      "Epoch: 3252 , Loss: 0.6937967\n",
      "Epoch: 3253 , Loss: 0.69379526\n",
      "Epoch: 3254 , Loss: 0.6937937\n",
      "Epoch: 3255 , Loss: 0.6937922\n",
      "Epoch: 3256 , Loss: 0.69379073\n",
      "Epoch: 3257 , Loss: 0.6937891\n",
      "Epoch: 3258 , Loss: 0.69378775\n",
      "Epoch: 3259 , Loss: 0.6937862\n",
      "Epoch: 3260 , Loss: 0.69378465\n",
      "Epoch: 3261 , Loss: 0.69378316\n",
      "Epoch: 3262 , Loss: 0.6937816\n",
      "Epoch: 3263 , Loss: 0.69378024\n",
      "Epoch: 3264 , Loss: 0.69377875\n",
      "Epoch: 3265 , Loss: 0.69377726\n",
      "Epoch: 3266 , Loss: 0.69377583\n",
      "Epoch: 3267 , Loss: 0.69377434\n",
      "Epoch: 3268 , Loss: 0.6937728\n",
      "Epoch: 3269 , Loss: 0.6937714\n",
      "Epoch: 3270 , Loss: 0.6937699\n",
      "Epoch: 3271 , Loss: 0.69376844\n",
      "Epoch: 3272 , Loss: 0.69376695\n",
      "Epoch: 3273 , Loss: 0.6937655\n",
      "Epoch: 3274 , Loss: 0.69376403\n",
      "Epoch: 3275 , Loss: 0.69376266\n",
      "Epoch: 3276 , Loss: 0.6937612\n",
      "Epoch: 3277 , Loss: 0.69375974\n",
      "Epoch: 3278 , Loss: 0.6937583\n",
      "Epoch: 3279 , Loss: 0.6937569\n",
      "Epoch: 3280 , Loss: 0.69375545\n",
      "Epoch: 3281 , Loss: 0.69375396\n",
      "Epoch: 3282 , Loss: 0.6937526\n",
      "Epoch: 3283 , Loss: 0.6937511\n",
      "Epoch: 3284 , Loss: 0.6937497\n",
      "Epoch: 3285 , Loss: 0.6937484\n",
      "Epoch: 3286 , Loss: 0.6937469\n",
      "Epoch: 3287 , Loss: 0.6937455\n",
      "Epoch: 3288 , Loss: 0.6937441\n",
      "Epoch: 3289 , Loss: 0.6937427\n",
      "Epoch: 3290 , Loss: 0.6937412\n",
      "Epoch: 3291 , Loss: 0.6937399\n",
      "Epoch: 3292 , Loss: 0.69373846\n",
      "Epoch: 3293 , Loss: 0.6937371\n",
      "Epoch: 3294 , Loss: 0.69373566\n",
      "Epoch: 3295 , Loss: 0.6937343\n",
      "Epoch: 3296 , Loss: 0.6937329\n",
      "Epoch: 3297 , Loss: 0.69373155\n",
      "Epoch: 3298 , Loss: 0.6937301\n",
      "Epoch: 3299 , Loss: 0.6937288\n",
      "Epoch: 3300 , Loss: 0.69372743\n",
      "Epoch: 3301 , Loss: 0.693726\n",
      "Epoch: 3302 , Loss: 0.6937247\n",
      "Epoch: 3303 , Loss: 0.6937233\n",
      "Epoch: 3304 , Loss: 0.693722\n",
      "Epoch: 3305 , Loss: 0.6937206\n",
      "Epoch: 3306 , Loss: 0.6937192\n",
      "Epoch: 3307 , Loss: 0.6937179\n",
      "Epoch: 3308 , Loss: 0.6937165\n",
      "Epoch: 3309 , Loss: 0.6937151\n",
      "Epoch: 3310 , Loss: 0.69371384\n",
      "Epoch: 3311 , Loss: 0.69371253\n",
      "Epoch: 3312 , Loss: 0.69371116\n",
      "Epoch: 3313 , Loss: 0.69370985\n",
      "Epoch: 3314 , Loss: 0.69370854\n",
      "Epoch: 3315 , Loss: 0.69370717\n",
      "Epoch: 3316 , Loss: 0.6937058\n",
      "Epoch: 3317 , Loss: 0.6937045\n",
      "Epoch: 3318 , Loss: 0.6937032\n",
      "Epoch: 3319 , Loss: 0.69370186\n",
      "Epoch: 3320 , Loss: 0.69370055\n",
      "Epoch: 3321 , Loss: 0.69369924\n",
      "Epoch: 3322 , Loss: 0.6936979\n",
      "Epoch: 3323 , Loss: 0.6936966\n",
      "Epoch: 3324 , Loss: 0.6936953\n",
      "Epoch: 3325 , Loss: 0.69369406\n",
      "Epoch: 3326 , Loss: 0.69369274\n",
      "Epoch: 3327 , Loss: 0.69369143\n",
      "Epoch: 3328 , Loss: 0.6936902\n",
      "Epoch: 3329 , Loss: 0.69368887\n",
      "Epoch: 3330 , Loss: 0.69368756\n",
      "Epoch: 3331 , Loss: 0.6936862\n",
      "Epoch: 3332 , Loss: 0.693685\n",
      "Epoch: 3333 , Loss: 0.6936837\n",
      "Epoch: 3334 , Loss: 0.69368243\n",
      "Epoch: 3335 , Loss: 0.6936812\n",
      "Epoch: 3336 , Loss: 0.69367987\n",
      "Epoch: 3337 , Loss: 0.6936786\n",
      "Epoch: 3338 , Loss: 0.69367737\n",
      "Epoch: 3339 , Loss: 0.6936761\n",
      "Epoch: 3340 , Loss: 0.6936749\n",
      "Epoch: 3341 , Loss: 0.6936736\n",
      "Epoch: 3342 , Loss: 0.69367236\n",
      "Epoch: 3343 , Loss: 0.6936711\n",
      "Epoch: 3344 , Loss: 0.69366986\n",
      "Epoch: 3345 , Loss: 0.69366854\n",
      "Epoch: 3346 , Loss: 0.6936673\n",
      "Epoch: 3347 , Loss: 0.6936661\n",
      "Epoch: 3348 , Loss: 0.69366485\n",
      "Epoch: 3349 , Loss: 0.6936636\n",
      "Epoch: 3350 , Loss: 0.6936624\n",
      "Epoch: 3351 , Loss: 0.69366115\n",
      "Epoch: 3352 , Loss: 0.69365996\n",
      "Epoch: 3353 , Loss: 0.6936587\n",
      "Epoch: 3354 , Loss: 0.6936575\n",
      "Epoch: 3355 , Loss: 0.69365627\n",
      "Epoch: 3356 , Loss: 0.6936551\n",
      "Epoch: 3357 , Loss: 0.6936539\n",
      "Epoch: 3358 , Loss: 0.69365263\n",
      "Epoch: 3359 , Loss: 0.69365144\n",
      "Epoch: 3360 , Loss: 0.6936502\n",
      "Epoch: 3361 , Loss: 0.693649\n",
      "Epoch: 3362 , Loss: 0.6936478\n",
      "Epoch: 3363 , Loss: 0.6936466\n",
      "Epoch: 3364 , Loss: 0.6936454\n",
      "Epoch: 3365 , Loss: 0.6936442\n",
      "Epoch: 3366 , Loss: 0.69364303\n",
      "Epoch: 3367 , Loss: 0.69364184\n",
      "Epoch: 3368 , Loss: 0.69364065\n",
      "Epoch: 3369 , Loss: 0.69363946\n",
      "Epoch: 3370 , Loss: 0.6936383\n",
      "Epoch: 3371 , Loss: 0.69363713\n",
      "Epoch: 3372 , Loss: 0.69363594\n",
      "Epoch: 3373 , Loss: 0.6936348\n",
      "Epoch: 3374 , Loss: 0.6936336\n",
      "Epoch: 3375 , Loss: 0.6936325\n",
      "Epoch: 3376 , Loss: 0.6936313\n",
      "Epoch: 3377 , Loss: 0.6936301\n",
      "Epoch: 3378 , Loss: 0.6936289\n",
      "Epoch: 3379 , Loss: 0.69362783\n",
      "Epoch: 3380 , Loss: 0.69362664\n",
      "Epoch: 3381 , Loss: 0.6936254\n",
      "Epoch: 3382 , Loss: 0.6936243\n",
      "Epoch: 3383 , Loss: 0.6936232\n",
      "Epoch: 3384 , Loss: 0.69362205\n",
      "Epoch: 3385 , Loss: 0.6936209\n",
      "Epoch: 3386 , Loss: 0.6936198\n",
      "Epoch: 3387 , Loss: 0.69361866\n",
      "Epoch: 3388 , Loss: 0.6936175\n",
      "Epoch: 3389 , Loss: 0.6936164\n",
      "Epoch: 3390 , Loss: 0.69361526\n",
      "Epoch: 3391 , Loss: 0.6936141\n",
      "Epoch: 3392 , Loss: 0.693613\n",
      "Epoch: 3393 , Loss: 0.69361186\n",
      "Epoch: 3394 , Loss: 0.6936107\n",
      "Epoch: 3395 , Loss: 0.6936096\n",
      "Epoch: 3396 , Loss: 0.6936084\n",
      "Epoch: 3397 , Loss: 0.69360733\n",
      "Epoch: 3398 , Loss: 0.6936062\n",
      "Epoch: 3399 , Loss: 0.69360507\n",
      "Epoch: 3400 , Loss: 0.693604\n",
      "Epoch: 3401 , Loss: 0.6936029\n",
      "Epoch: 3402 , Loss: 0.6936017\n",
      "Epoch: 3403 , Loss: 0.6936007\n",
      "Epoch: 3404 , Loss: 0.6935996\n",
      "Epoch: 3405 , Loss: 0.6935985\n",
      "Epoch: 3406 , Loss: 0.69359744\n",
      "Epoch: 3407 , Loss: 0.69359636\n",
      "Epoch: 3408 , Loss: 0.69359523\n",
      "Epoch: 3409 , Loss: 0.69359416\n",
      "Epoch: 3410 , Loss: 0.6935931\n",
      "Epoch: 3411 , Loss: 0.693592\n",
      "Epoch: 3412 , Loss: 0.69359094\n",
      "Epoch: 3413 , Loss: 0.69358987\n",
      "Epoch: 3414 , Loss: 0.6935888\n",
      "Epoch: 3415 , Loss: 0.6935877\n",
      "Epoch: 3416 , Loss: 0.6935867\n",
      "Epoch: 3417 , Loss: 0.6935856\n",
      "Epoch: 3418 , Loss: 0.6935845\n",
      "Epoch: 3419 , Loss: 0.6935834\n",
      "Epoch: 3420 , Loss: 0.69358236\n",
      "Epoch: 3421 , Loss: 0.69358134\n",
      "Epoch: 3422 , Loss: 0.69358027\n",
      "Epoch: 3423 , Loss: 0.69357926\n",
      "Epoch: 3424 , Loss: 0.6935782\n",
      "Epoch: 3425 , Loss: 0.6935772\n",
      "Epoch: 3426 , Loss: 0.6935761\n",
      "Epoch: 3427 , Loss: 0.6935751\n",
      "Epoch: 3428 , Loss: 0.693574\n",
      "Epoch: 3429 , Loss: 0.693573\n",
      "Epoch: 3430 , Loss: 0.693572\n",
      "Epoch: 3431 , Loss: 0.6935709\n",
      "Epoch: 3432 , Loss: 0.6935699\n",
      "Epoch: 3433 , Loss: 0.6935689\n",
      "Epoch: 3434 , Loss: 0.6935679\n",
      "Epoch: 3435 , Loss: 0.69356686\n",
      "Epoch: 3436 , Loss: 0.6935658\n",
      "Epoch: 3437 , Loss: 0.6935648\n",
      "Epoch: 3438 , Loss: 0.69356376\n",
      "Epoch: 3439 , Loss: 0.69356275\n",
      "Epoch: 3440 , Loss: 0.6935618\n",
      "Epoch: 3441 , Loss: 0.6935607\n",
      "Epoch: 3442 , Loss: 0.6935597\n",
      "Epoch: 3443 , Loss: 0.6935587\n",
      "Epoch: 3444 , Loss: 0.6935577\n",
      "Epoch: 3445 , Loss: 0.69355667\n",
      "Epoch: 3446 , Loss: 0.6935557\n",
      "Epoch: 3447 , Loss: 0.6935547\n",
      "Epoch: 3448 , Loss: 0.6935537\n",
      "Epoch: 3449 , Loss: 0.69355273\n",
      "Epoch: 3450 , Loss: 0.6935517\n",
      "Epoch: 3451 , Loss: 0.69355077\n",
      "Epoch: 3452 , Loss: 0.69354975\n",
      "Epoch: 3453 , Loss: 0.6935488\n",
      "Epoch: 3454 , Loss: 0.6935478\n",
      "Epoch: 3455 , Loss: 0.69354683\n",
      "Epoch: 3456 , Loss: 0.6935458\n",
      "Epoch: 3457 , Loss: 0.69354486\n",
      "Epoch: 3458 , Loss: 0.6935439\n",
      "Epoch: 3459 , Loss: 0.69354296\n",
      "Epoch: 3460 , Loss: 0.69354194\n",
      "Epoch: 3461 , Loss: 0.693541\n",
      "Epoch: 3462 , Loss: 0.69354004\n",
      "Epoch: 3463 , Loss: 0.6935391\n",
      "Epoch: 3464 , Loss: 0.6935381\n",
      "Epoch: 3465 , Loss: 0.6935372\n",
      "Epoch: 3466 , Loss: 0.6935362\n",
      "Epoch: 3467 , Loss: 0.6935352\n",
      "Epoch: 3468 , Loss: 0.69353426\n",
      "Epoch: 3469 , Loss: 0.6935333\n",
      "Epoch: 3470 , Loss: 0.69353235\n",
      "Epoch: 3471 , Loss: 0.6935314\n",
      "Epoch: 3472 , Loss: 0.6935305\n",
      "Epoch: 3473 , Loss: 0.69352955\n",
      "Epoch: 3474 , Loss: 0.6935286\n",
      "Epoch: 3475 , Loss: 0.6935277\n",
      "Epoch: 3476 , Loss: 0.69352674\n",
      "Epoch: 3477 , Loss: 0.6935258\n",
      "Epoch: 3478 , Loss: 0.6935249\n",
      "Epoch: 3479 , Loss: 0.69352394\n",
      "Epoch: 3480 , Loss: 0.69352305\n",
      "Epoch: 3481 , Loss: 0.6935221\n",
      "Epoch: 3482 , Loss: 0.6935212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3483 , Loss: 0.69352025\n",
      "Epoch: 3484 , Loss: 0.69351935\n",
      "Epoch: 3485 , Loss: 0.69351846\n",
      "Epoch: 3486 , Loss: 0.6935175\n",
      "Epoch: 3487 , Loss: 0.6935166\n",
      "Epoch: 3488 , Loss: 0.6935157\n",
      "Epoch: 3489 , Loss: 0.6935148\n",
      "Epoch: 3490 , Loss: 0.69351393\n",
      "Epoch: 3491 , Loss: 0.693513\n",
      "Epoch: 3492 , Loss: 0.6935121\n",
      "Epoch: 3493 , Loss: 0.6935111\n",
      "Epoch: 3494 , Loss: 0.6935103\n",
      "Epoch: 3495 , Loss: 0.6935094\n",
      "Epoch: 3496 , Loss: 0.6935085\n",
      "Epoch: 3497 , Loss: 0.6935076\n",
      "Epoch: 3498 , Loss: 0.6935067\n",
      "Epoch: 3499 , Loss: 0.6935058\n",
      "Epoch: 3500 , Loss: 0.6935049\n",
      "=============================================\n",
      "9 correctly classified among 100\n",
      "Accuracy as of 3500 epochs: 9.0\n",
      "=============================================\n",
      "Epoch: 3501 , Loss: 0.69350404\n",
      "Epoch: 3502 , Loss: 0.69350314\n",
      "Epoch: 3503 , Loss: 0.69350225\n",
      "Epoch: 3504 , Loss: 0.6935014\n",
      "Epoch: 3505 , Loss: 0.6935005\n",
      "Epoch: 3506 , Loss: 0.6934996\n",
      "Epoch: 3507 , Loss: 0.6934988\n",
      "Epoch: 3508 , Loss: 0.6934979\n",
      "Epoch: 3509 , Loss: 0.69349706\n",
      "Epoch: 3510 , Loss: 0.69349617\n",
      "Epoch: 3511 , Loss: 0.69349533\n",
      "Epoch: 3512 , Loss: 0.69349444\n",
      "Epoch: 3513 , Loss: 0.6934936\n",
      "Epoch: 3514 , Loss: 0.69349277\n",
      "Epoch: 3515 , Loss: 0.6934919\n",
      "Epoch: 3516 , Loss: 0.69349104\n",
      "Epoch: 3517 , Loss: 0.6934902\n",
      "Epoch: 3518 , Loss: 0.6934893\n",
      "Epoch: 3519 , Loss: 0.6934885\n",
      "Epoch: 3520 , Loss: 0.69348764\n",
      "Epoch: 3521 , Loss: 0.6934868\n",
      "Epoch: 3522 , Loss: 0.693486\n",
      "Epoch: 3523 , Loss: 0.69348514\n",
      "Epoch: 3524 , Loss: 0.6934843\n",
      "Epoch: 3525 , Loss: 0.6934835\n",
      "Epoch: 3526 , Loss: 0.69348264\n",
      "Epoch: 3527 , Loss: 0.6934818\n",
      "Epoch: 3528 , Loss: 0.69348097\n",
      "Epoch: 3529 , Loss: 0.69348013\n",
      "Epoch: 3530 , Loss: 0.6934793\n",
      "Epoch: 3531 , Loss: 0.69347847\n",
      "Epoch: 3532 , Loss: 0.69347763\n",
      "Epoch: 3533 , Loss: 0.69347686\n",
      "Epoch: 3534 , Loss: 0.693476\n",
      "Epoch: 3535 , Loss: 0.6934752\n",
      "Epoch: 3536 , Loss: 0.6934743\n",
      "Epoch: 3537 , Loss: 0.6934735\n",
      "Epoch: 3538 , Loss: 0.6934727\n",
      "Epoch: 3539 , Loss: 0.6934719\n",
      "Epoch: 3540 , Loss: 0.6934711\n",
      "Epoch: 3541 , Loss: 0.69347024\n",
      "Epoch: 3542 , Loss: 0.69346946\n",
      "Epoch: 3543 , Loss: 0.6934687\n",
      "Epoch: 3544 , Loss: 0.69346786\n",
      "Epoch: 3545 , Loss: 0.6934671\n",
      "Epoch: 3546 , Loss: 0.69346625\n",
      "Epoch: 3547 , Loss: 0.6934655\n",
      "Epoch: 3548 , Loss: 0.6934647\n",
      "Epoch: 3549 , Loss: 0.69346386\n",
      "Epoch: 3550 , Loss: 0.6934631\n",
      "Epoch: 3551 , Loss: 0.6934623\n",
      "Epoch: 3552 , Loss: 0.69346154\n",
      "Epoch: 3553 , Loss: 0.69346076\n",
      "Epoch: 3554 , Loss: 0.6934599\n",
      "Epoch: 3555 , Loss: 0.69345915\n",
      "Epoch: 3556 , Loss: 0.6934584\n",
      "Epoch: 3557 , Loss: 0.6934576\n",
      "Epoch: 3558 , Loss: 0.6934568\n",
      "Epoch: 3559 , Loss: 0.69345605\n",
      "Epoch: 3560 , Loss: 0.6934553\n",
      "Epoch: 3561 , Loss: 0.6934545\n",
      "Epoch: 3562 , Loss: 0.6934537\n",
      "Epoch: 3563 , Loss: 0.693453\n",
      "Epoch: 3564 , Loss: 0.69345224\n",
      "Epoch: 3565 , Loss: 0.69345146\n",
      "Epoch: 3566 , Loss: 0.6934507\n",
      "Epoch: 3567 , Loss: 0.6934499\n",
      "Epoch: 3568 , Loss: 0.6934492\n",
      "Epoch: 3569 , Loss: 0.6934484\n",
      "Epoch: 3570 , Loss: 0.69344765\n",
      "Epoch: 3571 , Loss: 0.69344693\n",
      "Epoch: 3572 , Loss: 0.69344616\n",
      "Epoch: 3573 , Loss: 0.6934454\n",
      "Epoch: 3574 , Loss: 0.69344467\n",
      "Epoch: 3575 , Loss: 0.6934439\n",
      "Epoch: 3576 , Loss: 0.6934432\n",
      "Epoch: 3577 , Loss: 0.6934424\n",
      "Epoch: 3578 , Loss: 0.6934417\n",
      "Epoch: 3579 , Loss: 0.693441\n",
      "Epoch: 3580 , Loss: 0.6934402\n",
      "Epoch: 3581 , Loss: 0.6934395\n",
      "Epoch: 3582 , Loss: 0.69343865\n",
      "Epoch: 3583 , Loss: 0.69343793\n",
      "Epoch: 3584 , Loss: 0.6934372\n",
      "Epoch: 3585 , Loss: 0.6934365\n",
      "Epoch: 3586 , Loss: 0.6934357\n",
      "Epoch: 3587 , Loss: 0.693435\n",
      "Epoch: 3588 , Loss: 0.6934343\n",
      "Epoch: 3589 , Loss: 0.6934336\n",
      "Epoch: 3590 , Loss: 0.69343287\n",
      "Epoch: 3591 , Loss: 0.69343215\n",
      "Epoch: 3592 , Loss: 0.69343144\n",
      "Epoch: 3593 , Loss: 0.6934307\n",
      "Epoch: 3594 , Loss: 0.69343\n",
      "Epoch: 3595 , Loss: 0.6934293\n",
      "Epoch: 3596 , Loss: 0.6934286\n",
      "Epoch: 3597 , Loss: 0.69342786\n",
      "Epoch: 3598 , Loss: 0.69342715\n",
      "Epoch: 3599 , Loss: 0.69342643\n",
      "Epoch: 3600 , Loss: 0.6934257\n",
      "Epoch: 3601 , Loss: 0.69342506\n",
      "Epoch: 3602 , Loss: 0.69342434\n",
      "Epoch: 3603 , Loss: 0.6934236\n",
      "Epoch: 3604 , Loss: 0.6934229\n",
      "Epoch: 3605 , Loss: 0.69342226\n",
      "Epoch: 3606 , Loss: 0.69342154\n",
      "Epoch: 3607 , Loss: 0.6934208\n",
      "Epoch: 3608 , Loss: 0.6934202\n",
      "Epoch: 3609 , Loss: 0.69341946\n",
      "Epoch: 3610 , Loss: 0.6934188\n",
      "Epoch: 3611 , Loss: 0.6934181\n",
      "Epoch: 3612 , Loss: 0.69341743\n",
      "Epoch: 3613 , Loss: 0.6934167\n",
      "Epoch: 3614 , Loss: 0.69341606\n",
      "Epoch: 3615 , Loss: 0.69341534\n",
      "Epoch: 3616 , Loss: 0.6934147\n",
      "Epoch: 3617 , Loss: 0.693414\n",
      "Epoch: 3618 , Loss: 0.6934133\n",
      "Epoch: 3619 , Loss: 0.69341266\n",
      "Epoch: 3620 , Loss: 0.69341195\n",
      "Epoch: 3621 , Loss: 0.6934113\n",
      "Epoch: 3622 , Loss: 0.69341063\n",
      "Epoch: 3623 , Loss: 0.69341\n",
      "Epoch: 3624 , Loss: 0.6934093\n",
      "Epoch: 3625 , Loss: 0.6934086\n",
      "Epoch: 3626 , Loss: 0.69340795\n",
      "Epoch: 3627 , Loss: 0.6934073\n",
      "Epoch: 3628 , Loss: 0.69340664\n",
      "Epoch: 3629 , Loss: 0.693406\n",
      "Epoch: 3630 , Loss: 0.69340533\n",
      "Epoch: 3631 , Loss: 0.6934047\n",
      "Epoch: 3632 , Loss: 0.693404\n",
      "Epoch: 3633 , Loss: 0.69340336\n",
      "Epoch: 3634 , Loss: 0.6934027\n",
      "Epoch: 3635 , Loss: 0.69340205\n",
      "Epoch: 3636 , Loss: 0.6934014\n",
      "Epoch: 3637 , Loss: 0.69340074\n",
      "Epoch: 3638 , Loss: 0.6934001\n",
      "Epoch: 3639 , Loss: 0.6933995\n",
      "Epoch: 3640 , Loss: 0.69339883\n",
      "Epoch: 3641 , Loss: 0.6933982\n",
      "Epoch: 3642 , Loss: 0.6933975\n",
      "Epoch: 3643 , Loss: 0.69339687\n",
      "Epoch: 3644 , Loss: 0.6933962\n",
      "Epoch: 3645 , Loss: 0.69339556\n",
      "Epoch: 3646 , Loss: 0.69339496\n",
      "Epoch: 3647 , Loss: 0.6933943\n",
      "Epoch: 3648 , Loss: 0.69339365\n",
      "Epoch: 3649 , Loss: 0.69339305\n",
      "Epoch: 3650 , Loss: 0.6933924\n",
      "Epoch: 3651 , Loss: 0.6933918\n",
      "Epoch: 3652 , Loss: 0.69339114\n",
      "Epoch: 3653 , Loss: 0.69339055\n",
      "Epoch: 3654 , Loss: 0.6933899\n",
      "Epoch: 3655 , Loss: 0.6933893\n",
      "Epoch: 3656 , Loss: 0.6933887\n",
      "Epoch: 3657 , Loss: 0.69338804\n",
      "Epoch: 3658 , Loss: 0.69338745\n",
      "Epoch: 3659 , Loss: 0.69338685\n",
      "Epoch: 3660 , Loss: 0.6933862\n",
      "Epoch: 3661 , Loss: 0.6933856\n",
      "Epoch: 3662 , Loss: 0.693385\n",
      "Epoch: 3663 , Loss: 0.6933844\n",
      "Epoch: 3664 , Loss: 0.69338375\n",
      "Epoch: 3665 , Loss: 0.69338316\n",
      "Epoch: 3666 , Loss: 0.69338256\n",
      "Epoch: 3667 , Loss: 0.69338197\n",
      "Epoch: 3668 , Loss: 0.69338137\n",
      "Epoch: 3669 , Loss: 0.6933808\n",
      "Epoch: 3670 , Loss: 0.6933802\n",
      "Epoch: 3671 , Loss: 0.6933796\n",
      "Epoch: 3672 , Loss: 0.693379\n",
      "Epoch: 3673 , Loss: 0.6933784\n",
      "Epoch: 3674 , Loss: 0.6933778\n",
      "Epoch: 3675 , Loss: 0.6933772\n",
      "Epoch: 3676 , Loss: 0.6933766\n",
      "Epoch: 3677 , Loss: 0.693376\n",
      "Epoch: 3678 , Loss: 0.6933754\n",
      "Epoch: 3679 , Loss: 0.6933748\n",
      "Epoch: 3680 , Loss: 0.6933742\n",
      "Epoch: 3681 , Loss: 0.6933737\n",
      "Epoch: 3682 , Loss: 0.6933731\n",
      "Epoch: 3683 , Loss: 0.6933725\n",
      "Epoch: 3684 , Loss: 0.6933719\n",
      "Epoch: 3685 , Loss: 0.69337136\n",
      "Epoch: 3686 , Loss: 0.69337076\n",
      "Epoch: 3687 , Loss: 0.69337016\n",
      "Epoch: 3688 , Loss: 0.6933696\n",
      "Epoch: 3689 , Loss: 0.69336903\n",
      "Epoch: 3690 , Loss: 0.69336843\n",
      "Epoch: 3691 , Loss: 0.6933679\n",
      "Epoch: 3692 , Loss: 0.6933673\n",
      "Epoch: 3693 , Loss: 0.69336677\n",
      "Epoch: 3694 , Loss: 0.69336617\n",
      "Epoch: 3695 , Loss: 0.69336563\n",
      "Epoch: 3696 , Loss: 0.69336504\n",
      "Epoch: 3697 , Loss: 0.6933645\n",
      "Epoch: 3698 , Loss: 0.6933639\n",
      "Epoch: 3699 , Loss: 0.69336337\n",
      "Epoch: 3700 , Loss: 0.69336283\n",
      "Epoch: 3701 , Loss: 0.69336224\n",
      "Epoch: 3702 , Loss: 0.6933617\n",
      "Epoch: 3703 , Loss: 0.69336116\n",
      "Epoch: 3704 , Loss: 0.69336057\n",
      "Epoch: 3705 , Loss: 0.69336003\n",
      "Epoch: 3706 , Loss: 0.6933595\n",
      "Epoch: 3707 , Loss: 0.69335896\n",
      "Epoch: 3708 , Loss: 0.69335836\n",
      "Epoch: 3709 , Loss: 0.6933578\n",
      "Epoch: 3710 , Loss: 0.6933573\n",
      "Epoch: 3711 , Loss: 0.69335675\n",
      "Epoch: 3712 , Loss: 0.6933562\n",
      "Epoch: 3713 , Loss: 0.6933557\n",
      "Epoch: 3714 , Loss: 0.69335514\n",
      "Epoch: 3715 , Loss: 0.6933546\n",
      "Epoch: 3716 , Loss: 0.69335407\n",
      "Epoch: 3717 , Loss: 0.6933535\n",
      "Epoch: 3718 , Loss: 0.693353\n",
      "Epoch: 3719 , Loss: 0.69335246\n",
      "Epoch: 3720 , Loss: 0.6933519\n",
      "Epoch: 3721 , Loss: 0.6933514\n",
      "Epoch: 3722 , Loss: 0.69335085\n",
      "Epoch: 3723 , Loss: 0.6933503\n",
      "Epoch: 3724 , Loss: 0.6933498\n",
      "Epoch: 3725 , Loss: 0.69334924\n",
      "Epoch: 3726 , Loss: 0.6933487\n",
      "Epoch: 3727 , Loss: 0.6933482\n",
      "Epoch: 3728 , Loss: 0.6933477\n",
      "Epoch: 3729 , Loss: 0.69334716\n",
      "Epoch: 3730 , Loss: 0.6933466\n",
      "Epoch: 3731 , Loss: 0.69334614\n",
      "Epoch: 3732 , Loss: 0.6933456\n",
      "Epoch: 3733 , Loss: 0.69334507\n",
      "Epoch: 3734 , Loss: 0.6933446\n",
      "Epoch: 3735 , Loss: 0.693344\n",
      "Epoch: 3736 , Loss: 0.69334346\n",
      "Epoch: 3737 , Loss: 0.693343\n",
      "Epoch: 3738 , Loss: 0.69334245\n",
      "Epoch: 3739 , Loss: 0.693342\n",
      "Epoch: 3740 , Loss: 0.69334143\n",
      "Epoch: 3741 , Loss: 0.69334096\n",
      "Epoch: 3742 , Loss: 0.6933404\n",
      "Epoch: 3743 , Loss: 0.69333994\n",
      "Epoch: 3744 , Loss: 0.6933394\n",
      "Epoch: 3745 , Loss: 0.69333893\n",
      "Epoch: 3746 , Loss: 0.6933384\n",
      "Epoch: 3747 , Loss: 0.6933379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3748 , Loss: 0.69333744\n",
      "Epoch: 3749 , Loss: 0.6933369\n",
      "Epoch: 3750 , Loss: 0.6933364\n",
      "=============================================\n",
      "100 correctly classified among 100\n",
      "Accuracy as of 3750 epochs: 100.0\n",
      "=============================================\n",
      "Achieved more than 90% Accuracy\n",
      "Epoch: 3751 , Loss: 0.69333595\n",
      "Epoch: 3752 , Loss: 0.6933354\n",
      "Epoch: 3753 , Loss: 0.69333494\n",
      "Epoch: 3754 , Loss: 0.69333446\n",
      "Epoch: 3755 , Loss: 0.693334\n",
      "Epoch: 3756 , Loss: 0.69333345\n",
      "Epoch: 3757 , Loss: 0.69333297\n",
      "Epoch: 3758 , Loss: 0.6933325\n",
      "Epoch: 3759 , Loss: 0.693332\n",
      "Epoch: 3760 , Loss: 0.69333154\n",
      "Epoch: 3761 , Loss: 0.69333106\n",
      "Epoch: 3762 , Loss: 0.6933306\n",
      "Epoch: 3763 , Loss: 0.69333005\n",
      "Epoch: 3764 , Loss: 0.6933296\n",
      "Epoch: 3765 , Loss: 0.6933291\n",
      "Epoch: 3766 , Loss: 0.6933286\n",
      "Epoch: 3767 , Loss: 0.69332814\n",
      "Epoch: 3768 , Loss: 0.69332767\n",
      "Epoch: 3769 , Loss: 0.6933272\n",
      "Epoch: 3770 , Loss: 0.6933267\n",
      "Epoch: 3771 , Loss: 0.6933263\n",
      "Epoch: 3772 , Loss: 0.6933258\n",
      "Epoch: 3773 , Loss: 0.69332534\n",
      "Epoch: 3774 , Loss: 0.69332486\n",
      "Epoch: 3775 , Loss: 0.6933244\n",
      "Epoch: 3776 , Loss: 0.6933239\n",
      "Epoch: 3777 , Loss: 0.69332343\n",
      "Epoch: 3778 , Loss: 0.693323\n",
      "Epoch: 3779 , Loss: 0.69332254\n",
      "Epoch: 3780 , Loss: 0.69332206\n",
      "Epoch: 3781 , Loss: 0.6933216\n",
      "Epoch: 3782 , Loss: 0.69332117\n",
      "Epoch: 3783 , Loss: 0.6933207\n",
      "Epoch: 3784 , Loss: 0.6933202\n",
      "Epoch: 3785 , Loss: 0.6933198\n",
      "Epoch: 3786 , Loss: 0.6933193\n",
      "Epoch: 3787 , Loss: 0.69331884\n",
      "Epoch: 3788 , Loss: 0.6933184\n",
      "Epoch: 3789 , Loss: 0.69331795\n",
      "Epoch: 3790 , Loss: 0.69331753\n",
      "Epoch: 3791 , Loss: 0.69331706\n",
      "Epoch: 3792 , Loss: 0.69331664\n",
      "Epoch: 3793 , Loss: 0.69331616\n",
      "Epoch: 3794 , Loss: 0.69331574\n",
      "Epoch: 3795 , Loss: 0.69331527\n",
      "Epoch: 3796 , Loss: 0.69331485\n",
      "Epoch: 3797 , Loss: 0.6933144\n",
      "Epoch: 3798 , Loss: 0.69331396\n",
      "Epoch: 3799 , Loss: 0.6933135\n",
      "Epoch: 3800 , Loss: 0.69331306\n",
      "Epoch: 3801 , Loss: 0.69331264\n",
      "Epoch: 3802 , Loss: 0.69331217\n",
      "Epoch: 3803 , Loss: 0.69331175\n",
      "Epoch: 3804 , Loss: 0.69331133\n",
      "Epoch: 3805 , Loss: 0.69331086\n",
      "Epoch: 3806 , Loss: 0.69331044\n",
      "Epoch: 3807 , Loss: 0.69331\n",
      "Epoch: 3808 , Loss: 0.69330955\n",
      "Epoch: 3809 , Loss: 0.6933091\n",
      "Epoch: 3810 , Loss: 0.6933087\n",
      "Epoch: 3811 , Loss: 0.6933083\n",
      "Epoch: 3812 , Loss: 0.6933079\n",
      "Epoch: 3813 , Loss: 0.69330746\n",
      "Epoch: 3814 , Loss: 0.693307\n",
      "Epoch: 3815 , Loss: 0.69330657\n",
      "Epoch: 3816 , Loss: 0.69330615\n",
      "Epoch: 3817 , Loss: 0.69330573\n",
      "Epoch: 3818 , Loss: 0.6933053\n",
      "Epoch: 3819 , Loss: 0.6933049\n",
      "Epoch: 3820 , Loss: 0.6933045\n",
      "Epoch: 3821 , Loss: 0.69330406\n",
      "Epoch: 3822 , Loss: 0.69330364\n",
      "Epoch: 3823 , Loss: 0.6933032\n",
      "Epoch: 3824 , Loss: 0.6933028\n",
      "Epoch: 3825 , Loss: 0.6933024\n",
      "Epoch: 3826 , Loss: 0.693302\n",
      "Epoch: 3827 , Loss: 0.69330156\n",
      "Epoch: 3828 , Loss: 0.69330114\n",
      "Epoch: 3829 , Loss: 0.6933007\n",
      "Epoch: 3830 , Loss: 0.69330037\n",
      "Epoch: 3831 , Loss: 0.69329995\n",
      "Epoch: 3832 , Loss: 0.69329953\n",
      "Epoch: 3833 , Loss: 0.6932991\n",
      "Epoch: 3834 , Loss: 0.6932987\n",
      "Epoch: 3835 , Loss: 0.6932983\n",
      "Epoch: 3836 , Loss: 0.6932979\n",
      "Epoch: 3837 , Loss: 0.6932975\n",
      "Epoch: 3838 , Loss: 0.6932971\n",
      "Epoch: 3839 , Loss: 0.6932967\n",
      "Epoch: 3840 , Loss: 0.6932963\n",
      "Epoch: 3841 , Loss: 0.6932959\n",
      "Epoch: 3842 , Loss: 0.6932955\n",
      "Epoch: 3843 , Loss: 0.6932951\n",
      "Epoch: 3844 , Loss: 0.6932947\n",
      "Epoch: 3845 , Loss: 0.69329435\n",
      "Epoch: 3846 , Loss: 0.6932939\n",
      "Epoch: 3847 , Loss: 0.6932935\n",
      "Epoch: 3848 , Loss: 0.69329315\n",
      "Epoch: 3849 , Loss: 0.69329274\n",
      "Epoch: 3850 , Loss: 0.6932924\n",
      "Epoch: 3851 , Loss: 0.69329196\n",
      "Epoch: 3852 , Loss: 0.6932916\n",
      "Epoch: 3853 , Loss: 0.6932912\n",
      "Epoch: 3854 , Loss: 0.6932908\n",
      "Epoch: 3855 , Loss: 0.6932904\n",
      "Epoch: 3856 , Loss: 0.69329005\n",
      "Epoch: 3857 , Loss: 0.69328964\n",
      "Epoch: 3858 , Loss: 0.6932893\n",
      "Epoch: 3859 , Loss: 0.6932889\n",
      "Epoch: 3860 , Loss: 0.6932885\n",
      "Epoch: 3861 , Loss: 0.69328815\n",
      "Epoch: 3862 , Loss: 0.69328773\n",
      "Epoch: 3863 , Loss: 0.6932874\n",
      "Epoch: 3864 , Loss: 0.693287\n",
      "Epoch: 3865 , Loss: 0.69328666\n",
      "Epoch: 3866 , Loss: 0.69328624\n",
      "Epoch: 3867 , Loss: 0.6932859\n",
      "Epoch: 3868 , Loss: 0.6932855\n",
      "Epoch: 3869 , Loss: 0.6932851\n",
      "Epoch: 3870 , Loss: 0.69328475\n",
      "Epoch: 3871 , Loss: 0.6932844\n",
      "Epoch: 3872 , Loss: 0.69328403\n",
      "Epoch: 3873 , Loss: 0.6932837\n",
      "Epoch: 3874 , Loss: 0.69328326\n",
      "Epoch: 3875 , Loss: 0.6932829\n",
      "Epoch: 3876 , Loss: 0.69328254\n",
      "Epoch: 3877 , Loss: 0.6932822\n",
      "Epoch: 3878 , Loss: 0.6932818\n",
      "Epoch: 3879 , Loss: 0.6932815\n",
      "Epoch: 3880 , Loss: 0.6932811\n",
      "Epoch: 3881 , Loss: 0.69328076\n",
      "Epoch: 3882 , Loss: 0.6932804\n",
      "Epoch: 3883 , Loss: 0.69328004\n",
      "Epoch: 3884 , Loss: 0.6932797\n",
      "Epoch: 3885 , Loss: 0.6932793\n",
      "Epoch: 3886 , Loss: 0.69327897\n",
      "Epoch: 3887 , Loss: 0.6932786\n",
      "Epoch: 3888 , Loss: 0.69327825\n",
      "Epoch: 3889 , Loss: 0.6932779\n",
      "Epoch: 3890 , Loss: 0.69327754\n",
      "Epoch: 3891 , Loss: 0.6932772\n",
      "Epoch: 3892 , Loss: 0.6932768\n",
      "Epoch: 3893 , Loss: 0.69327646\n",
      "Epoch: 3894 , Loss: 0.6932761\n",
      "Epoch: 3895 , Loss: 0.6932758\n",
      "Epoch: 3896 , Loss: 0.69327545\n",
      "Epoch: 3897 , Loss: 0.6932751\n",
      "Epoch: 3898 , Loss: 0.69327474\n",
      "Epoch: 3899 , Loss: 0.6932744\n",
      "Epoch: 3900 , Loss: 0.6932741\n",
      "Epoch: 3901 , Loss: 0.6932737\n",
      "Epoch: 3902 , Loss: 0.69327337\n",
      "Epoch: 3903 , Loss: 0.693273\n",
      "Epoch: 3904 , Loss: 0.6932727\n",
      "Epoch: 3905 , Loss: 0.69327235\n",
      "Epoch: 3906 , Loss: 0.693272\n",
      "Epoch: 3907 , Loss: 0.69327164\n",
      "Epoch: 3908 , Loss: 0.69327134\n",
      "Epoch: 3909 , Loss: 0.693271\n",
      "Epoch: 3910 , Loss: 0.6932707\n",
      "Epoch: 3911 , Loss: 0.6932703\n",
      "Epoch: 3912 , Loss: 0.69326997\n",
      "Epoch: 3913 , Loss: 0.69326967\n",
      "Epoch: 3914 , Loss: 0.6932693\n",
      "Epoch: 3915 , Loss: 0.693269\n",
      "Epoch: 3916 , Loss: 0.69326866\n",
      "Epoch: 3917 , Loss: 0.6932683\n",
      "Epoch: 3918 , Loss: 0.693268\n",
      "Epoch: 3919 , Loss: 0.69326764\n",
      "Epoch: 3920 , Loss: 0.69326735\n",
      "Epoch: 3921 , Loss: 0.693267\n",
      "Epoch: 3922 , Loss: 0.6932667\n",
      "Epoch: 3923 , Loss: 0.6932664\n",
      "Epoch: 3924 , Loss: 0.69326603\n",
      "Epoch: 3925 , Loss: 0.69326574\n",
      "Epoch: 3926 , Loss: 0.6932654\n",
      "Epoch: 3927 , Loss: 0.693265\n",
      "Epoch: 3928 , Loss: 0.69326466\n",
      "Epoch: 3929 , Loss: 0.69326437\n",
      "Epoch: 3930 , Loss: 0.69326407\n",
      "Epoch: 3931 , Loss: 0.6932637\n",
      "Epoch: 3932 , Loss: 0.6932634\n",
      "Epoch: 3933 , Loss: 0.6932631\n",
      "Epoch: 3934 , Loss: 0.69326276\n",
      "Epoch: 3935 , Loss: 0.69326246\n",
      "Epoch: 3936 , Loss: 0.69326216\n",
      "Epoch: 3937 , Loss: 0.69326186\n",
      "Epoch: 3938 , Loss: 0.6932615\n",
      "Epoch: 3939 , Loss: 0.6932612\n",
      "Epoch: 3940 , Loss: 0.6932609\n",
      "Epoch: 3941 , Loss: 0.6932606\n",
      "Epoch: 3942 , Loss: 0.69326025\n",
      "Epoch: 3943 , Loss: 0.69325995\n",
      "Epoch: 3944 , Loss: 0.69325966\n",
      "Epoch: 3945 , Loss: 0.69325936\n",
      "Epoch: 3946 , Loss: 0.69325906\n",
      "Epoch: 3947 , Loss: 0.69325876\n",
      "Epoch: 3948 , Loss: 0.69325846\n",
      "Epoch: 3949 , Loss: 0.6932581\n",
      "Epoch: 3950 , Loss: 0.6932578\n",
      "Epoch: 3951 , Loss: 0.6932575\n",
      "Epoch: 3952 , Loss: 0.6932572\n",
      "Epoch: 3953 , Loss: 0.6932569\n",
      "Epoch: 3954 , Loss: 0.6932566\n",
      "Epoch: 3955 , Loss: 0.6932563\n",
      "Epoch: 3956 , Loss: 0.693256\n",
      "Epoch: 3957 , Loss: 0.6932557\n",
      "Epoch: 3958 , Loss: 0.6932554\n",
      "Epoch: 3959 , Loss: 0.6932551\n",
      "Epoch: 3960 , Loss: 0.6932548\n",
      "Epoch: 3961 , Loss: 0.69325453\n",
      "Epoch: 3962 , Loss: 0.69325423\n",
      "Epoch: 3963 , Loss: 0.69325393\n",
      "Epoch: 3964 , Loss: 0.69325364\n",
      "Epoch: 3965 , Loss: 0.69325334\n",
      "Epoch: 3966 , Loss: 0.6932531\n",
      "Epoch: 3967 , Loss: 0.6932528\n",
      "Epoch: 3968 , Loss: 0.6932525\n",
      "Epoch: 3969 , Loss: 0.6932522\n",
      "Epoch: 3970 , Loss: 0.6932519\n",
      "Epoch: 3971 , Loss: 0.6932516\n",
      "Epoch: 3972 , Loss: 0.6932513\n",
      "Epoch: 3973 , Loss: 0.6932511\n",
      "Epoch: 3974 , Loss: 0.6932508\n",
      "Epoch: 3975 , Loss: 0.6932505\n",
      "Epoch: 3976 , Loss: 0.6932502\n",
      "Epoch: 3977 , Loss: 0.69324994\n",
      "Epoch: 3978 , Loss: 0.69324964\n",
      "Epoch: 3979 , Loss: 0.69324934\n",
      "Epoch: 3980 , Loss: 0.69324905\n",
      "Epoch: 3981 , Loss: 0.6932488\n",
      "Epoch: 3982 , Loss: 0.6932485\n",
      "Epoch: 3983 , Loss: 0.6932482\n",
      "Epoch: 3984 , Loss: 0.693248\n",
      "Epoch: 3985 , Loss: 0.6932477\n",
      "Epoch: 3986 , Loss: 0.6932474\n",
      "Epoch: 3987 , Loss: 0.69324714\n",
      "Epoch: 3988 , Loss: 0.69324684\n",
      "Epoch: 3989 , Loss: 0.69324654\n",
      "Epoch: 3990 , Loss: 0.6932463\n",
      "Epoch: 3991 , Loss: 0.693246\n",
      "Epoch: 3992 , Loss: 0.69324577\n",
      "Epoch: 3993 , Loss: 0.6932455\n",
      "Epoch: 3994 , Loss: 0.6932452\n",
      "Epoch: 3995 , Loss: 0.69324493\n",
      "Epoch: 3996 , Loss: 0.69324464\n",
      "Epoch: 3997 , Loss: 0.6932444\n",
      "Epoch: 3998 , Loss: 0.6932441\n",
      "Epoch: 3999 , Loss: 0.69324386\n",
      "Epoch: 4000 , Loss: 0.69324356\n",
      "=============================================\n",
      "100 correctly classified among 100\n",
      "Accuracy as of 4000 epochs: 100.0\n",
      "=============================================\n",
      "Achieved more than 90% Accuracy\n",
      "Epoch: 4001 , Loss: 0.6932433\n",
      "Epoch: 4002 , Loss: 0.693243\n",
      "Epoch: 4003 , Loss: 0.6932428\n",
      "Epoch: 4004 , Loss: 0.69324255\n",
      "Epoch: 4005 , Loss: 0.69324225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4006 , Loss: 0.693242\n",
      "Epoch: 4007 , Loss: 0.6932417\n",
      "Epoch: 4008 , Loss: 0.6932415\n",
      "Epoch: 4009 , Loss: 0.6932412\n",
      "Epoch: 4010 , Loss: 0.69324094\n",
      "Epoch: 4011 , Loss: 0.6932407\n",
      "Epoch: 4012 , Loss: 0.6932404\n",
      "Epoch: 4013 , Loss: 0.69324017\n",
      "Epoch: 4014 , Loss: 0.6932399\n",
      "Epoch: 4015 , Loss: 0.6932396\n",
      "Epoch: 4016 , Loss: 0.6932394\n",
      "Epoch: 4017 , Loss: 0.69323915\n",
      "Epoch: 4018 , Loss: 0.6932389\n",
      "Epoch: 4019 , Loss: 0.6932386\n",
      "Epoch: 4020 , Loss: 0.6932384\n",
      "Epoch: 4021 , Loss: 0.69323814\n",
      "Epoch: 4022 , Loss: 0.6932379\n",
      "Epoch: 4023 , Loss: 0.6932376\n",
      "Epoch: 4024 , Loss: 0.69323736\n",
      "Epoch: 4025 , Loss: 0.6932371\n",
      "Epoch: 4026 , Loss: 0.6932369\n",
      "Epoch: 4027 , Loss: 0.6932366\n",
      "Epoch: 4028 , Loss: 0.69323635\n",
      "Epoch: 4029 , Loss: 0.6932361\n",
      "Epoch: 4030 , Loss: 0.6932359\n",
      "Epoch: 4031 , Loss: 0.69323564\n",
      "Epoch: 4032 , Loss: 0.6932354\n",
      "Epoch: 4033 , Loss: 0.69323516\n",
      "Epoch: 4034 , Loss: 0.69323486\n",
      "Epoch: 4035 , Loss: 0.6932346\n",
      "Epoch: 4036 , Loss: 0.6932344\n",
      "Epoch: 4037 , Loss: 0.69323415\n",
      "Epoch: 4038 , Loss: 0.6932339\n",
      "Epoch: 4039 , Loss: 0.69323367\n",
      "Epoch: 4040 , Loss: 0.69323343\n",
      "Epoch: 4041 , Loss: 0.6932332\n",
      "Epoch: 4042 , Loss: 0.69323295\n",
      "Epoch: 4043 , Loss: 0.6932327\n",
      "Epoch: 4044 , Loss: 0.6932325\n",
      "Epoch: 4045 , Loss: 0.69323224\n",
      "Epoch: 4046 , Loss: 0.693232\n",
      "Epoch: 4047 , Loss: 0.69323176\n",
      "Epoch: 4048 , Loss: 0.6932315\n",
      "Epoch: 4049 , Loss: 0.6932313\n",
      "Epoch: 4050 , Loss: 0.69323105\n",
      "Epoch: 4051 , Loss: 0.6932308\n",
      "Epoch: 4052 , Loss: 0.69323057\n",
      "Epoch: 4053 , Loss: 0.69323033\n",
      "Epoch: 4054 , Loss: 0.6932301\n",
      "Epoch: 4055 , Loss: 0.6932299\n",
      "Epoch: 4056 , Loss: 0.6932297\n",
      "Epoch: 4057 , Loss: 0.69322944\n",
      "Epoch: 4058 , Loss: 0.6932292\n",
      "Epoch: 4059 , Loss: 0.69322896\n",
      "Epoch: 4060 , Loss: 0.6932287\n",
      "Epoch: 4061 , Loss: 0.6932285\n",
      "Epoch: 4062 , Loss: 0.6932283\n",
      "Epoch: 4063 , Loss: 0.69322807\n"
     ]
    }
   ],
   "source": [
    "\n",
    "epochs = 5000\n",
    "n_way = 10\n",
    "n_val = 100\n",
    "batch_size = 64\n",
    "\n",
    "loss_list=[]\n",
    "accuracy_list=[]\n",
    "for epoch in range(1,epochs):\n",
    "    batch_x, batch_y = get_batch(batch_size)#, call_type=\"train\")\n",
    "    loss = siamese_net.train_on_batch(batch_x, batch_y)\n",
    "    loss_list.append((epoch,loss))\n",
    "    print('Epoch:', epoch, ', Loss:',loss)\n",
    "    if epoch%250 == 0:\n",
    "        print(\"=============================================\")\n",
    "        accuracy = nway_one_shot(model, n_way, n_val)\n",
    "        accuracy_list.append((epoch, accuracy))\n",
    "        print('Accuracy as of', epoch, 'epochs:', accuracy)\n",
    "        print(\"=============================================\")\n",
    "        if(accuracy>99):\n",
    "            print(\"Achieved more than 90% Accuracy\")\n",
    "            #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranging-cherry",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
